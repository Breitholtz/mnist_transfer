{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc, re, copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.layers import deserialize, serialize\n",
    "from tensorflow.python.keras.saving import saving_utils\n",
    "\n",
    "# Project imports \n",
    "from data import mnist_m as mnistm\n",
    "from data import mnist\n",
    "from data.label_shift import label_shift_linear, plot_labeldist, plot_splitbars\n",
    "from data.tasks import load_task\n",
    "from experiments.training import *\n",
    "from bounds.bounds import *\n",
    "from util.kl import *\n",
    "from util.misc import *\n",
    "from util.batch import *\n",
    "# \n",
    "# Hyper-parameters\n",
    "task = 7\n",
    "seeds = [1]#[1,2,3,4,5]#[1,2,3,4,5]#1,2,3,4,5,6\n",
    "image_size=64\n",
    "batch_size=32\n",
    "n_classifiers = 5\n",
    "delta=0.05 ## what would this be?   \n",
    "binary=True\n",
    "bound='germain'\n",
    "architecture=\"resnet\"\n",
    "#epsilons=[0.1]\n",
    "alphas=[0.3]#[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "#[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "sigmas=[[3,3],[3,4]]\n",
    "\n",
    "#project_folder = \"/cephyr/users/adambre/Alvis/\"\n",
    "project_folder=\"/cephyr/NOBACKUP/groups/snic2021-23-538/mnist_transfer/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alvis params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'SNIC2022-5-244'\n",
    "username = 'adambre'\n",
    "job = 'batch_bound_array.sbatch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "          436812_1     alvis paramete  adambre  R       3:35      1 alvis2-02\r\n",
      "          436812_2     alvis paramete  adambre  R       3:35      1 alvis2-02\r\n",
      "          436812_3     alvis paramete  adambre  R       3:35      1 alvis2-02\r\n",
      "          436812_4     alvis paramete  adambre  R       3:35      1 alvis2-02\r\n",
      "          436812_5     alvis paramete  adambre  R       3:35      1 alvis2-02\r\n",
      "          436812_6     alvis paramete  adambre  R       3:35      1 alvis2-02\r\n",
      "          436812_7     alvis paramete  adambre  R       3:35      1 alvis2-02\r\n",
      "          436812_8     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "          436812_9     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "         436812_10     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "         436812_11     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "         436812_12     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "         436812_13     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "         436812_14     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "         436812_15     alvis paramete  adambre  R       3:35      1 alvis2-03\r\n",
      "         436812_16     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_17     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_18     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_19     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_20     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_21     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_22     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_23     alvis paramete  adambre  R       3:35      1 alvis2-04\r\n",
      "         436812_24     alvis paramete  adambre  R       3:35      1 alvis2-05\r\n",
      "         436812_25     alvis paramete  adambre  R       3:35      1 alvis2-05\r\n",
      "         436812_26     alvis paramete  adambre  R       3:35      1 alvis2-05\r\n",
      "         436812_27     alvis paramete  adambre  R       3:35      1 alvis2-05\r\n",
      "         436812_28     alvis paramete  adambre  R       3:35      1 alvis2-05\r\n",
      "         436812_29     alvis paramete  adambre  R       3:35      1 alvis2-05\r\n",
      "            435145     alvis     bash  adambre  R 4-06:12:10      1 alvis2-01\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u adambre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/bash\r\n",
      "\r\n",
      "#SBATCH -t 1-00:00:00\r\n",
      "#SBATCH -N 1 --gpus-per-node=T4:1\r\n",
      "#SBATCH -p alvis \r\n",
      "num_parameter_combos=$1\r\n",
      "\r\n",
      "eval `head -n $SLURM_ARRAY_TASK_ID $num_parameter_combos | tail -1`\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "if [ -z \"$task\" ]\r\n",
      "then\r\n",
      "    task=2\r\n",
      "fi\r\n",
      "if [ -z \"$seed\" ]\r\n",
      "then \r\n",
      "    seed=69105\r\n",
      "fi\r\n",
      "if [ -z \"$alpha\" ]\r\n",
      "then \r\n",
      "    alpha=0.0\r\n",
      "fi\r\n",
      "if [ -z \"$sigma\" ]\r\n",
      "then \r\n",
      "    sigma='3,3'\r\n",
      "fi\r\n",
      "if [ -z \"$delta\" ]\r\n",
      "then \r\n",
      "    delta=0.05\r\n",
      "fi\r\n",
      "if [ -z \"$binary\" ]\r\n",
      "then \r\n",
      "    binary=0\r\n",
      "fi\r\n",
      "if [ -z \"$n_classifiers\" ]\r\n",
      "then \r\n",
      "    n_classifiers=2\r\n",
      "fi\r\n",
      "if [ -z \"$bound\" ]\r\n",
      "then \r\n",
      "    bound='germain'\r\n",
      "fi\r\n",
      "if [ -z \"$prior_path\" ]\r\n",
      "then \r\n",
      "    prior_path=''\r\n",
      "fi\r\n",
      "if [ -z \"$posterior_path\" ]\r\n",
      "then \r\n",
      "    posterior_path=''\r\n",
      "fi\r\n",
      "if [ -z \"$architecture\" ]\r\n",
      "then \r\n",
      "    architecture='lenet'\r\n",
      "fi\r\n",
      "if [ -z \"$image_size\" ]\r\n",
      "then \r\n",
      "    image_size=32\r\n",
      "fi\r\n",
      "if [ -z \"$batch_size\" ]\r\n",
      "then \r\n",
      "    batch_size=128\r\n",
      "fi\r\n",
      ". load_modules.sh\r\n",
      "\r\n",
      "python batch_bound_single.py -t $task -r $seed -a $alpha -s $sigma -d $delta -b $binary -n $n_classifiers -B $bound -p $prior_path -P $posterior_path -A $architecture -I $image_size -F $batch_size \r\n"
     ]
    }
   ],
   "source": [
    "!cat $job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over experiments...\n",
      "\n",
      "alpha:0.3\n",
      "    sigma:[3, 3]\n",
      "    sigma:[3, 4]\n"
     ]
    }
   ],
   "source": [
    "print('Iterating over experiments...\\n')\n",
    "\n",
    "fids = []\n",
    "\n",
    "os.makedirs(project_folder+'logs', exist_ok=True)\n",
    "logdir=project_folder+'logs'\n",
    "parameter_set_name=\"parameter_sets\"\n",
    "experiments=1\n",
    "\n",
    "with open(parameter_set_name, 'w') as input_file:\n",
    "  # all the same loops as before\n",
    "    for seed in seeds:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        for alpha in alphas:\n",
    "\n",
    "            print(\"alpha:\"+str(alpha))\n",
    "\n",
    "            for sigma in sigmas:    \n",
    "                print(\"    sigma:\"+str(sigma))\n",
    "                arg_list = get_job_args(task, bound=bound, alpha=alpha, sigma=sigma,\n",
    "                                        binary=binary, n_classifiers=n_classifiers,architecture=architecture,\n",
    "                                        seed=seed,image_size=image_size, batch_size=batch_size)\n",
    "                for a in arg_list:   \n",
    "\n",
    "                    ckpt = os.path.splitext(os.path.basename(a['posterior_path']))[0]\n",
    "                    fid = project_folder+'logs/batch_t-%d_r-%d_a-%.4f_s-%d%d_d-%.4f_b-%d_n-%d_B-%s_c-%s_A-%s_I-%d_F-%d' % \\\n",
    "                        (task, seed, alpha, sigma[0], sigma[1], delta, binary, n_classifiers, bound, ckpt, architecture,image_size,batch_size)\n",
    "\n",
    "                    sigstr = '\"%d.%d\"' % (sigma[0], sigma[1])\n",
    "                    exp = 'task=%d,seed=%d,alpha=%.4f,sigma=\"%s\",delta=%.4f,'% (task, seed, alpha, sigstr, delta)\\\n",
    "                            +'binary=%d,nclassifiers=%d,bound=%s,prior=%s,posterior=%s,architecture=%s,image_size=%d,batch_size=%d' % (binary, n_classifiers, bound, a['prior_path'], a['posterior_path'],architecture,image_size,batch_size)\n",
    "\n",
    "                    prior_path = '\"%s\"' % a['prior_path']\n",
    "                    posterior_path = '\"%s\"' % a['posterior_path']\n",
    "                    if binary:\n",
    "                        binary=1\n",
    "                    else:\n",
    "                        binary=0\n",
    "                    #architecture = '\"%s\"' % architecture\n",
    "                    #bound = '\"%s\"' % bound\n",
    "                    \n",
    "                    input_file.write(f'task={task} seed={seed} alpha={alpha:.4f} sigma={sigstr} delta={delta:.4f} binary={binary} n_classifiers={n_classifiers} bound={bound} prior_path={prior_path} posterior_path={posterior_path} architecture={architecture} image_size={image_size} batch_size={batch_size}\\n')  # space separated for bash\n",
    "                    \n",
    "                    experiments += 1\n",
    "# print(experiments)                                     \n",
    "# print(input_file)\n",
    "                                                     \n",
    "output = !sbatch --array 1-$experiments -J \"$parameter_set_name\" -o \"$logdir\"/\"$parameter_set_name\".%A_%a.out -A $project batch_bound_array.sbatch $parameter_set_name \n",
    "jobid = int(output[0].split(' ')[-1])       \n",
    "\n",
    "\n",
    "#### OLD WAY\n",
    "# for seed in seeds:\n",
    "#     np.random.seed(seed)\n",
    "\n",
    "#     for alpha in alphas:\n",
    "\n",
    "#         print(\"alpha:\"+str(alpha))\n",
    "\n",
    "#         for sigma in sigmas:    \n",
    "#             print(\"    sigma:\"+str(sigma))\n",
    "#             arg_list = get_job_args(task, bound=bound, alpha=alpha, sigma=sigma,\n",
    "#                                     binary=binary, n_classifiers=n_classifiers,architecture=architecture,\n",
    "#                                     seed=seed,image_size=image_size, batch_size=batch_size)\n",
    "#             for a in arg_list:   \n",
    "\n",
    "#                 ckpt = os.path.splitext(os.path.basename(a['posterior_path']))[0]\n",
    "#                 fid = project_folder+'logs/batch_t-%d_r-%d_a-%.4f_s-%d%d_d-%.4f_b-%d_n-%d_B-%s_c-%s_A-%s_I-%d_F-%d' % \\\n",
    "#                     (task, seed, alpha, sigma[0], sigma[1], delta, binary, n_classifiers, bound, ckpt, architecture,image_size,batch_size)\n",
    "\n",
    "#                 sigstr = '\"%d.%d\"' % (sigma[0], sigma[1])\n",
    "#                 exp = 'task=%d,seed=%d,alpha=%.4f,sigma=\"%s\",delta=%.4f,'% (task, seed, alpha, sigstr, delta)\\\n",
    "#                         +'binary=%d,nclassifiers=%d,bound=%s,prior=%s,posterior=%s,architecture=%s,image_size=%d,batch_size=%d' % (binary, n_classifiers, bound, a['prior_path'], a['posterior_path'],architecture,image_size,batch_size)\n",
    "\n",
    "#                 prior_path = a['prior_path']\n",
    "#                 output = !sbatch -o \"$fid\"-%j.out -e \"$fid\"-%j.err -A $project --export=\"$exp\" $job\n",
    "\n",
    "#                 jobid = int(output[0].split(' ')[-1])\n",
    "#                 fid = fid+'-%s' % jobid\n",
    "\n",
    "#                 fids.append(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.61GiB deviceMemoryBandwidth: 298.08GiB/s\r\n",
      "2022-06-21 16:39:37.318663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n",
      "2022-06-21 16:39:37.318725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
      "2022-06-21 16:39:37.318742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n",
      "2022-06-21 16:39:37.318757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n",
      "2022-06-21 16:39:37.324071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13693 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:06:00.0, compute capability: 7.5)\r\n",
      "2022-06-21 16:39:37.344545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\n",
      "pciBusID: 0000:06:00.0 name: Tesla T4 computeCapability: 7.5\r\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.61GiB deviceMemoryBandwidth: 298.08GiB/s\r\n",
      "2022-06-21 16:39:37.351304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n",
      "2022-06-21 16:39:37.351330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
      "2022-06-21 16:39:37.351337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n",
      "2022-06-21 16:39:37.351342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n",
      "2022-06-21 16:39:37.412889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13693 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:06:00.0, compute capability: 7.5)\r\n",
      "2022-06-21 16:39:43.649951: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n",
      "2022-06-21 16:39:43.739490: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2900000000 Hz\r\n",
      "2022-06-21 16:39:44.950158: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n",
      "2022-06-21 16:39:45.452519: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\r\n",
      "2022-06-21 16:39:46.226568: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n",
      "2022-06-21 16:39:46.706714: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n"
     ]
    }
   ],
   "source": [
    "#print(fids)\n",
    "#print(output)\n",
    "!tail -n 20 \"$logdir\"/\"$parameter_set_name\".\"$jobid\"_1.out\n",
    "#pd.read_pickle(\"/cephyr/NOBACKUP/groups/snic2021-23-538/mnist_transfer/results/task6/Binary/fc/32_0_32_4_1_0_results.pkl\")\n",
    "#\"$jobid\"_1.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "            435145     alvis     bash  adambre  R 4-23:48:45      1 alvis2-01\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nto remove all jobs queued\\nbash_jobid=214746\\nsqueue -u adambre | awk '{if ($1!=JOBID && $1!=bash_jobid) {print $1}}' | tail -n +2 |xargs scancel\\n\\n\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!squeue -u $username\n",
    "\n",
    "\"\"\"\n",
    "to remove all jobs queued\n",
    "bash_jobid=214746\n",
    "squeue -u adambre | awk '{if ($1!=JOBID && $1!=bash_jobid) {print $1}}' | tail -n +2 |xargs scancel\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#!squeue -u adambre | awk '{if ($1!=JOBID && $1!=373627) {print $1}}' | tail -n +2 |xargs scancel\n",
    "#!scancel 398381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for fid in fids: \n",
    "    print('------')\n",
    "    print(fid)\n",
    "    !tail -n 10 \"$fid\".out\n",
    "    !tail -n 5 \"$fid\".err\n",
    "    print(' \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
