{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#### Keras implementation of NN's which we will look at MNIST with\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras as keras \n",
    "import tensorflow as tf\n",
    "#import scipy\n",
    "#import h5py\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "#svhn_path=\"../Datasets/svhn\"#\"/Home/Adam/Research/Datasets/svhn\"\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "## where did you put mnist_transfer\n",
    "path_to_root_file=\"/home/adam/Code/\"\n",
    "### making sure that we have the GPU to work on\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "  # I do not know why I have to do this but gpu does not work otherwise.\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, variance 0.36348352 70.18035\n",
      "---------------Load MNIST----------------\n",
      "Training set (60000, 32, 32, 3) (60000, 10)\n",
      "Test set (10000, 32, 32, 3) (10000, 10)\n",
      "\n",
      "\n",
      "mean, variance 1.1809415 74.36859\n",
      "---------------Load MNIST-M----------------\n",
      "Training set (60000, 32, 32, 3) (60000, 10)\n",
      "Test set (10000, 32, 32, 3) (10000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAHOCAYAAABzf7grAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJPElEQVR4nO3de3yMZ/7/8feIZIJmhIagq4jzoTEq1GERDVUlDq1GT5bdditV39Vq1aFVQ1epta3dVhXttnWqQ76qDqtbQrIlTmkbqrtVGimqKoKZREiZ3L8/fDM/00kwhCH36/l43I8211zXdX/uScjbfV/3PRbDMAwBAACUceUCXQAAAMD1QOgBAACmQOgBAACmQOgBAACmQOgBAACmQOgBAACmQOgBAACmQOgBAACmQOgBAACmQOgBAqxu3bqyWCxeW926dUt1HxfO7XA4SnVuSUpJSfHaR0pKylXNFxoaWmK92dnZqlevnu67774rnj8rK0sOh+Oq65wyZYrCw8O1ceNGT9uQIUOu2ffx1y51HP/5z39UvXp1PfXUU9e0DuBmQegBAiwrK0sXfhqMYRjKysoq1X0YhuH1i7m0xcbGyjAMTZgwoVTmO3PmTIn1njp1Sj///LP2799/xfNnZWVp4sSJVx16Dhw4IKfTqaNHj3raPvjgAxmGoTp16lzV3JfjUsdx8uRJHT9+vNR/noCbVflAFwAA/qhbt64OHTqkChUqBLoUzZw5U+PHj1etWrUCXUqxOnTooMOHD6tKlSqBLgW4IRB6ANx0qlatGugSJEnlypW7YQNPkerVqwe6BOCGweUt4Ca1ceNG/eEPf1CTJk1UsWJFhYeHq3v37tqwYcMlx65du1bt27dXpUqVVLVqVT366KP68ccfi+27ZcsW9e7dW1WrVlVoaKiaN2+uV199VQUFBaVyHGfOnNG4ceN0++23KzQ0VE2aNNHf/vY3r0t+RRwOh9faoV/btm2b+vTpo1q1aqlSpUpq3ry5hg4dqs8//9zTp27duurataskaeLEiT7rbxITE73ajh49qsGDB6t69eoqV66cZ83S5a6TOnLkiAYNGqRq1aqpQoUKatu2rVavXu3V58J1XRfOlZSUVOLxXuo4Lmdt0erVq3X33XercuXKqlChgux2u/72t7/J7XZ71X9hDR988IHmzZunZs2ayWq1qm7dupoxY0aJxw/cUAwANwRJhj9/JJs3b27Y7XZj+/btxunTp42srCxj+PDhRrly5YyVK1f69N+4caMhyejcubPRu3dvY9++fcbp06eNlStXGuHh4cbtt99uHDlyxGvMRx99ZAQFBRk9e/Y09u/fb+Tn5xuLFi0yKlSoYHTv3t1wu91e/SdMmGBIMjZu3HhZx1BYWGj06NHDkGRMmzbNcDqdxtGjR43Ro0cbXbt2NSQZEyZM8BnXpUsXn/cqPT3dCA4ONh566CEjKyvLOH36tJGWlmY0bdrUqFOnTrHvRXFzF6lTp45Ro0YNIzY21vjkk08Ml8tlrFixwuv4LjZPnTp1jMjISKNz587GmjVrjDNnzhjfffedcffddxsWi8VYuHDhZddU3PH6cxy/Pn7DMIypU6cakoynn37a+Omnn4zc3Fxj9uzZRvny5Y0+ffr4fG/ff/99Q5LRrVs3409/+pPx448/GocPHzYGDhxoSDKWLVtWYg3AjYLQA9wg/A09DzzwgLFjxw6f9latWhktWrTwaS/6BXnLLbcYJ0+e9Hpt7ty5hiTj97//vaftp59+MipVqmSEhYUZJ06c8Oo/fvx4Q5IxZ84cr3Z/Q88HH3xgSDIeffRRn9c6dOjgVwh49tlnDUnG119/7dW+fv36Kw49koz58+d7tf/xj380vvnmm0vOUzT+H//4h1d7Tk6OERYWZlSuXNlwuVyXVVNph54vv/zSKFeunNG+fXuf/mPGjDEkGW+++aZXe1HoiY6O9mo/cuSIIcno27dviTUANwoubwE3qaSkJMXExPi0t2jRQrt375bL5Sp2XM+ePVW5cmWvtoSEBFksFi1evFi//PKLJGnevHk6deqUBgwYoPDwcK/+Dz30kKTzdypdjXnz5nnNd6FHHnnEr7mKLv8sXbrU69JYly5dlJqaekX1WSwWDRgwwKttzpw5atas2WXPMXDgQK+vq1atqu7du8vpdOqTTz65orqu1pw5c1RYWKiHH37Y57WitrfffrvYsX369PH6OjIyUlWrVtXevXtLv1CglBF6gJvU0aNHNWrUKDVv3ly33HKLZ83F/PnzJUknTpwodtztt9/u02az2VSjRg2dPn1a3333nSRp+/btkiS73e7Tv3bt2pKkL7/8UoWFhVd8DF999ZUkqXHjxpdV58U8/vjjCgsL0yuvvKKmTZvqz3/+s/773/+qfPnyV3z7eLVq1RQaGnpFYyXp1ltvVcWKFX3ai443IyPjiue+Gjt27JAkNWnSxOe1orb//ve/OnXqlM/rxS3cvuWWW5Sfn1/KVQKlj9AD3ISys7N15513aubMmRo3bpwOHDgg4/zlag0ePFiSil0ILJ3/BVWcSpUqSZKcTqfXf0eMGOHz8ESbzSbp/CLkks4oXY6isUX7vlBYWJhfczVr1kwZGRn64x//qMOHD2v8+PFq1qyZOnTo4Alw/rra2+Iv972+3or2W9z7HhISovLlz9/Ye/LkSZ/Xi3tPLBZLiT9vwI2E0APchObOnasff/xRiYmJevTRR/26hTsvL6/Y9qJ/1Rdd+iq6pDV37lxPoCpu+/WlL38U7au4Mwq5ubl+zxcVFaU5c+bo6NGj+t///V/16NFDW7ZsUZcuXbRv374rrvNKXe57Lcnn7qwLlfZZlKLvWXHv+y+//KJz58559QPKCkIPcJNYu3atHnzwQUnyPGG3YcOGPv1Onz590XkOHDjg0+Z0OnXkyBFVrFjRc+nlrrvu8trXr3333XdX/UTjO++8U5L07bffXladF/Pll196ag0NDdX999+vTz/9VI8//rjOnDnjdZv4xQJGacrJySk2WBQdb6tWrTxtRWdQiutf0uMErvQ42rZtK+n8JaxfK2pr3rx5sWeCgJsZoQe4Sfz888+etRhF61127drl1efs2bOXvJSzdu1an8sqRYt/H3nkEQUHB0uSfve73+mWW27RwoULPf/yL+J2u5WQkOBZiHylii7FLVmyxOe1RYsW+TXX3//+d82aNcunvXnz5pK8L8sUPaH4zJkznv+2aNFCycnJfu3zcvz62I4fP65169apSpUq6tu3r6e9QYMGslgs2rNnj1f/7du36/Dhw8XOfaXHMXToUJUrV06LFy/2ea2ojc/rQllE6AECzOVyea2dOHnyZLHbhZc4hgwZovDwcL333nt677335HQ6deDAAf3+97/XDz/8cNH91a5dW4888oi+//57FRQUaPXq1XrhhRdUp04dvfrqq55+1atX1/vvv69Dhw6pT58+2rlzp/Lz8/Wf//xHCQkJOnHihCZOnHhVx/7oo4/qvvvu08KFCzV9+nS5XC7l5ORozJgxxa4nuZS33npLCxYs0PHjx5Wfn6/U1FTNmDFDtWrV8pwlk84HjPDwcKWlpSkvL0+LFi3St99+W+ofEFqlShXNmDFDa9euVUFBgfbt26eEhASdOnVKb7/9ttean6pVq+ree+/Vp59+qiVLlig3N1fp6ekaN26cWrRoUez8V3oc0dHReu2117RlyxYNHz5cP//8s06dOqW5c+fqr3/9q/r06UPoQdkUkBvlAXgUPc/lcrYLn7fy3XffGQ888IBRo0YNIyQkxGjcuLExadIk4+GHH/b079Kli2EYhtccEyZMMObNm2fY7XYjNDTUCA8PNx555BHj0KFDxda3fft2o2/fvkbVqlWN0NBQo0GDBsb//M//ePUvel7Mr7fLcfr0aePFF180ateubYSEhBj16tUzxo8fb/zrX//ymmvLli2e5wBduBUd4759+4zx48cbrVu3NiIiIowKFSoYDRs29DxI79c++eQTo2nTpkZoaKhRr149Y+7cuYZhGMXuo7hjKa7Pxo0bjcGDB3t9v/bs2WP07dvXqFKlimG1Wo02bdoYq1evLva9OHr0qJGQkGDYbDajUqVKxn333Wfs27fP85weSUavXr0u6zgurKNoGzx4sNfYNWvWGF27djXCwsKM0NBQo2XLlsaMGTOMc+fOXfJYS3qvLvbMICDQLIbBknsAAFD2cXkLAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYQvlAF3CjKCws1OHDhxUWFnbdHlEPAACujmEYys3NVa1atVSu3MXP5RB6/s/hw4dVu3btQJcBAACuwMGDB/Wb3/zmon0IPf8nLCxM0vk3zWazBbgaAABwOVwul2rXru35PX4xhJ7/U3RJy2azEXoAALjJXM7SFBYyAwAAUyD0AAAAUyD0AAAAUyD0AAAAU2Ah8xVyu906e/ZsoMsA/BYUFKTg4OBAlwEA1x2hx0+GYejIkSNyOp0yDCPQ5QBXxGq1KiIigjsVAZgKocdPTqdTJ0+eVLVq1VSpUiWe3oybimEYOnv2rJxOp3788UdJIvgAMA1Cjx8Mw9DRo0dls9kUERER6HKAK1KhQgWFhYXp0KFDOnbsGKEHgGmwkNkPbrdbbrebXxK46VksFlWuXFkFBQWsTQNgGoQeP5w7d06SVL48J8hw8ytazOx2uwNcCQBcH4SeK8A6HpQF/BwDMBtCDwAAMAVCDy5L165dVaNGjas+OzB16lQ1bdpULVu2VJMmTZSUlFRKFf5/WVlZstvtuuWWWxQbG1vq8wMAbk4sTikldcesCXQJkqSsqb2uybwbN26Uw+HQxIkTL9n34MGDat26tV5++WUNHz7c0/7JJ59o3Lhx2r17t5o1a6bp06dr9+7dysvLkyQNGTKkVGqtW7euMjIyrjrwOBwOxcbG3lTB6WasGQCuF0IPSp3ValWdOnVUtWpVr/aUlBRVr15dzZo1kySNHDlShYWF6tatm6TSCz2lpSjg3UwB4masGQCuF0IPSl316tW1Y8cOn/YTJ04oNDTU83W5cuVUrhxXWAHgZlAaVzSu1dWIy8VvHEiSvvvuO/Xr1092u12tWrVSmzZt5HA4lJ+f79M3IyND9957rxo3bqxmzZppzZr//wdh27ZtstvtCgkJ8Zy5OX36tOx2u1auXKnDhw/LbrfLbrcrNTVVdrtd6enpSk9P97RPnTrVM9+ePXvUr18/1alTRw0aNFCnTp20ceNGn5qSkpLUtGlT1a5dWx06dNDChQuv+L3YuHGj7Ha7JOmdd97x1LV+/XpJ589Y9evXT61atfJsb731lgoLCz1zjBo1Sg0aNJDFYtHy5cs1ePBgxcTEKDg4WP369ZMkFRYWyuFwqFatWmrcuLE6d+6s1NRUWSwW1ahRQ127dvXM53K5NHz4cNWtW1dNmjRR8+bN9fbbb192zQAAzvTg//Tq1UuPPfaYVqxYIUnasmWLunbtqiFDhqhu3bpefWfNmqVVq1YpODhYI0eO1MMPP6wDBw4oPDxcd911lzIyMrzGVKhQQRkZGRoyZIhSUlKUkZHhee3CtTcpKSle+9m/f786dOige+65R99//73Kly+vN998Uz169NCGDRv029/+VpKUmpqqhIQETZo0SS+99JIMw9ALL7ygb775Rs2bN/f7vejatasyMjJksViUmJgoh8Ph9frixYvVsGFDLV++XOXKldOhQ4cUGxsrt9utESNGSJL+8pe/qFevXuratasmT57sGfPBBx943uM///nPmjJliv75z38qLi5Oubm5GjhwoCR57ffs2bPq3r278vLytH37dlWvXl3btm1T165dlZubq9GjR1+yZgAAZ3og6dixY9q3b58aNGjgaWvfvr0mT55c7NOnn3zySc+D7R5++GHl5uYWeznrajkcDjmdTr3++uueB0IOHz5ct99+uyZMmODpN378eEVGRmrs2LGSzj9/ZuLEiSooKCj1miRp3LhxmjhxoufS3G9+8xsNGDBAs2fPLrb/gAED1LBhQ0nn36+ZM2fK6XRq+vTp6tOnj+Li4iRJYWFhGjdunM/4BQsWaPv27XI4HKpevbok6a677tLDDz+syZMnF3s2DgDgi9AD3XrrrbLb7Ro6dKieffZZbd26VYWFhXruued8FiNLUpMmTbzGStKRI0dKva7PPvtM9evXV82aNT1tFotFLVq00KZNm3T27Fm53W5t3bpVrVq1UlBQkKdfxYoVVb9+/VKvSTr/AZ2TJ0/WXXfdpTvuuEN2u10ffPCBvv/++2L7t2jRwvP/VqtVt912m3bt2qXc3Fy1adPGq+8dd9zhM/6zzz6TJM+ZrQv7XqvACQBlEZe3IIvFopSUFE2fPl0ffvihZsyYodtuu03PPfecnnnmGZ9n81SqVMnz/0VnO67FRxkcO3ZMubm5nrUqRZxOp6pUqaITJ054PjW8SpUqPuMrV65c6jUZhqE+ffrop59+0qeffuoJVhe7nT8sLMyn7fDhw5LkU3dxNR87dkyS1LNnT6/206dPKzIyUidOnPD/QADAhAg9kHT+l+0rr7yiSZMm6fPPP9e0adM0cuRI2Ww2Pf744wGpKSIiQjVq1NBXX31VYh+3263g4GAdP37c57WTJ08qPDy8VGvat2+fPv/8c/3lL3+5qjNJtWrVkiSfuk+ePOnTNyIiQtL5tUvXIsgBgFlweQs6evSoZwGuxWJR586d9cknnyg8PFw7d+685vsPDg6WYRiSpFOnTmnlypWSpB49emjfvn2ehxcWSUtL07BhwyRJQUFBateunb766ivPB8JKUn5+vjIzM6+qrvLly3vq+uGHH5SWluZZJ/TrW+1/+uknv+aOjo5WWFiYz6Wpr7/+2qdvjx49JMkn/DmdTt1///1ewam4mgEA51330HPo0CHdc889fNjhDSQ/P1+zZs1Samqqp+2LL75Qbm6u58GB11K9evX0448/yjAMbdq0Sc8884yk85eMrFarnnnmGZ09e1bS+XDx9NNPex5wKEmvvPKKjh496rnV3TAMjR8/3usW8iLr1q2TxWLRxx9/fFl1HTp0SNL528DfffddNWnSRA0bNtS7776ro0ePSpJ2796txYsX+3XMlStX1vPPP69Vq1Zpw4YNkqTc3Fy9+eabPn0fffRRtW/fXi+88IJnn6dPn9aIESNUrlw5r3VXxdUMADjP78tbZ86ckcPh0Mcffyyr1aqQkBC9/PLL6tOnzyXHLly4UGPHjvV6QN2vZWVlqVGjRl6/1IocOnRItWrV0q5duzxtISEhxfYdO3as5/ZfXFxkZKRefPFFjRw50rM2p3z58nr//fc939f+/ftry5YtkiS73a4333xTP//8s15++WVJ0ssvv6wvv/xSjz76qIYOHarDhw9r5cqVnufxdOnSRQcOHFBeXp7sdruaN2/ueZbO888/r4yMDDVr1sxzW7p0/uMktmzZorFjx6pevXqqVq2agoODNXz4cK9Lbl26dNGyZcs0fvx4vfPOO6pRo4aGDBmimJgYz/N//vd//1f169dXZmamLBaLWrZsecn3Zfr06Xr22WfVsmVLVapUSfPmzVP58uW1atUqPfPMM4qOjlaDBg1Uu3Zt9evXT/PmzZPdbtf06dO1bds2vf/++5KkJ554QuHh4UpPT/eav+j2+scee0w2m0233Xabpk2bpmXLlnn9oyA4OFj/+te/NH78eLVt21ZhYWEKCgpSz549ve5iK6lmAMB5FqPoXPhlevDBB7V79259/vnnioiI0KpVq9S/f3+tWLFCvXv3LnGc0+lUfHy8PvjgA02aNEkffvihitt1VlaWYmNjlZWV5fPaHXfcoUGDBumFF17wtNWtW7fYvv5yuVyqXLmynE5nsbdpS+cD3/79+1WvXr2LBjfcmNxut9q2bav69etr6dKlgS6nWMePH9ett96q6dOn67nnnrum++LnGYA/btQnMl/O7+8ifl3eSk1NVVJSkhwOh2dxZXx8vLp166YRI0YUG2KKhIWFKSUlRVFRURfdR7Vq1TRjxgyf9rS0NO3du1d/+MMf/CkZ8PjrX/+qqlWr6r333gt0KZLOX34qurRVpGhNT6tWrQJREgCUaX6FnqJ/HRc9TK1IXFycMjMzfU7fe+3oMj9nqVKlSp7H9F9o9uzZGjBggCdsAf565pln9K9//avYW8gDISsrSw6HQ7m5uZLOfzbZSy+9pLvuusvrIygAAKXDr9CTkZEhm83mEzyKbt29Vnf6nDhxQkuXLtVTTz3l81p+fr6GDRumdu3aqVGjRurevbuWLVt2yTkLCgrkcrm8NpRtISEhN9QHnN53332qXLmyWrdurRYtWshut6tp06Zau3YtC/0B4BrwayFzdnZ2sdfLitqys7NLp6pfmTdvnho2bKiOHTv6vGa1WnXvvfdq5syZOnfunN5//30NHDhQu3bt0iuvvFLinFOmTCnxYXLA9dC5c2d17tw50GUAgGncOP/svYg5c+YUe5ZHkg4ePKg+ffrIYrEoODhYTz75pB544AFNmTLFc+tuccaOHSun0+nZDh48eK3KBwAANwC/Qk9ERESxl4GK2qpVq1Y6VV3g888/14EDB/TYY49d9pj27dvL7XZr27ZtJfaxWq2y2WxeGwAAKLv8Cj12u10ul0s5OTle7UVPvr2cZ5/4a/bs2XrssceKXXyal5fn87ReSZ4Pnizu4XSlwc+7/IEbEj/HAMzGr9CTkJAgSUpOTvZqT05OVlRUlGJiYiSdfx5K0ZNjr0ZOTo6SkpJKvLQ1ffp0jRw50qc9PT1dFotFrVu3vuoaLlS+/PklUBd+3AFwsyp6yvWFn04PAGWZX6EnNjZWAwYMkMPh8Hzy85o1a7Ru3TrNmDHDc8fJsGHDVLNmzav+3J8PP/xQrVu3VnR0dIl9PvroI6/LWCtXrtTixYs1dOjQSz4TyF9BQUEKCgriTi/c9AzDkNPplNVqVXBwcKDLAYDrwu+PoZg/f74cDoc6duzo+Qtz+fLlio+P9/SJjIxUeHi4zzqZxMREbd26VQcOHJB0/nKZJH322WeqXr26z77mzJmjl156qcRaBg8erLNnz+qpp57SuXPnlJeXJ5vNptdff11PP/20v4d2SRaLRdWrV9dPP/0kq9WqSpUqcWsxbiqGYejs2bNyOp3Ky8vTbbfdFuiSAOC68ftjKMqqy32MtWEYOnLkiJxOJ2sicNOyWq2KiIhgAT+Ay1YWPobC7zM9ZmexWFSzZk1Vr17dsyYCuJkEBQVxSQuAKRF6rlDR+h4AAHBzuCkeTggAAHC1CD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUCD0AAMAUyge6AAAAzKDumDVXPUfW1F6lUIl5caYHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYwnUPPYcOHdI999wji8VyvXcNAABMrLy/A86cOSOHw6GPP/5YVqtVISEhevnll9WnT59Ljl24cKHGjh2r0NDQi/YbMmSINm3apFtuucWrvXnz5lq4cGGp1QMAuHnUHbPmqsZnTe1VSpXgZuV36Bk0aJB2796tzZs3KyIiQqtWrVL//v21YsUK9e7du8RxTqdTs2fPVkpKiiZNmqS9e/dedD/vvvuuYmNjr1k9AADAXPy6vJWamqqkpCQ5HA5FRERIkuLj49WtWzeNGDFChmGUODYsLEwpKSmKioq6uopLqR4AAGAufoWepUuXSpLi4uK82uPi4pSZman09PSSd1SunMqVK90lRFdTDwAAMBe/UkhGRoZsNpvnrEqR+vXrS5J27txZaoUtXLhQXbp0UYsWLXTnnXdq3LhxcjqdpVZPQUGBXC6X1wYAAMouv0JPdna2bDabT3tRW3Z2dqkUFRYWpgoVKmjVqlXavXu33n//fSUlJalDhw7Kzc0tlXqmTJmiypUre7batWuXSu0AAODGdEM+p+fNN9/U3//+d094admypd544w395z//0cyZM0tlH2PHjpXT6fRsBw8eLJV5AQDAjcmv0BMREVHsZaCitmrVqpVOVcVo3769JGnz5s2lUo/VapXNZvPaAABA2eVX6LHb7XK5XMrJyfFqz8zMlHT+jMzVcrvdxV6WCgoKkiQVFhZe13oAAEDZ4FfoSUhIkCQlJyd7tScnJysqKkoxMTGSzgeXo0ePXlFBBw8eVJ06deR2u73ai+7EatOmjd/1AAAA+BV6YmNjNWDAADkcDh07dkyStGbNGq1bt04zZszwfLTEsGHDVLNmTaWlpV1RUadPn9b48eM9wefw4cN6/vnnVbt2bQ0fPtzvegAAAPx+IvP8+fPlcDjUsWNHWa1WBQcHa/ny5YqPj/f0iYyMVHh4uM86mcTERG3dulUHDhyQdP7ylCR99tlnql69uiSpVq1amjt3rpYtW6bo6GgZhqH8/Hx169ZNkyZN8rk9/XLqAQAAsBg8tljS+cXPlStXltPpZFEzANyAbvbP3rra+qXAHsONWr8/v79vyFvWAQAAShuhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmMJ1Dz2HDh3SPffcI4vFcr13DQAATMzv0HPmzBmNGTNGjRs3VnR0tGJiYrRy5crLGrtw4UJ16NBBWVlZJfY5e/asli1bpp49e6px48Zq0aKFWrRoIYfDodzcXJ/+ISEhstvtPtuSJUv8PTQAAFCGlfd3wKBBg7R7925t3rxZERERWrVqlfr3768VK1aod+/eJY5zOp2aPXu2UlJSNGnSJO3du7fYfl988YUSEhI0a9YsJSYmSpJ27typu+++W2vXrlVaWpqCgoI8/WvVqqWMjAx/DwMAAJiMX2d6UlNTlZSUJIfDoYiICElSfHy8unXrphEjRsgwjBLHhoWFKSUlRVFRUZfcT3R0tCfwSFLLli2VmJio7du3KzU11Z+SAQAAJPl5pmfp0qWSpLi4OK/2uLg4/etf/1J6erratGlT7Nhy5S4vX911111KT0/3af/Nb34jSTpx4oQ/JQMAJNUds+aq58ia2qsUKgECx68zPRkZGbLZbJ6zPEXq168v6fxlqKtlsVgUHBzs075nzx5ZrVZ17NjRqz0/P1/Dhg1Tu3bt1KhRI3Xv3l3Lli275H4KCgrkcrm8NgAAUHb5FXqys7Nls9l82ovasrOzS6eqX3E6nVq0aJFGjRqlGjVqeL1mtVp17733asuWLfrmm2/04IMPauDAgRo/fvxF55wyZYoqV67s2WrXrn1NagcAADeGG/45PYZhaOjQoWrTpo0mTJjg8/rBgwfVp08fzxmiJ598Ug888ICmTJmiQ4cOlTjv2LFj5XQ6PdvBgwev5WEAAIAA8yv0REREFHsZqKitWrVqpVPVBf70pz8pJydHSUlJKl/+8pYgtW/fXm63W9u2bSuxj9Vqlc1m89oAAEDZ5VfosdvtcrlcysnJ8WrPzMyUdP4uq9JiGIYSExOVlZWl1atXq0KFCj598vLylJeX59NedEt7YWFhqdUDAABubn6FnoSEBElScnKyV3tycrKioqIUExMjSXK73Tp69OgVF+V2uzV48GAdP35cy5cvl9VqlSTNmTNHc+bM8fSbPn26Ro4c6TM+PT1dFotFrVu3vuIaAABA2eJX6ImNjdWAAQPkcDh07NgxSdKaNWu0bt06zZgxw/PREsOGDVPNmjWVlpbmd0Fnz57VQw89pNTUVPXq1UtLlizRggULtGDBAn366ac6fPiwV/+PPvrI6zLWypUrtXjxYg0dOvSyngkEAADMwe8nMs+fP18Oh0MdO3aU1WpVcHCwli9frvj4eE+fyMhIhYeH+6yTSUxM1NatW3XgwAFJ5y+XSdJnn32m6tWrS5LWrl2rpKQkSdKQIUN89h8dHe35/8GDB+vs2bN66qmndO7cOeXl5clms+n111/X008/7e+hAQCAMsxiXOwxyibicrlUuXJlOZ1OFjUDKHPKwsMJr/YYbvb6pcAew41avz+/v2/4W9YBAABKA6EHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYAqEHAACYwnUPPYcOHdI999wji8VyvXcNAABMzO/Qc+bMGY0ZM0aNGzdWdHS0YmJitHLlyssau3DhQnXo0EFZWVmX7JuWlqbOnTurefPmatSokYYOHaqTJ0/69CssLNS0adPUrFkzRUdHKzo6Wu+9956fRwUAAMo6v0PPoEGD9Mknn2jz5s3atWuXJkyYoPvvv1+rV6++6Din06nZs2crJSVFHTp0uGjfL774QnFxcUpISNA333yjjIwMffvtt+rZs6fcbrdX39GjR+uvf/2rVq9erV27dukf//iHhg8frrffftvfQwMAAGWYX6EnNTVVSUlJcjgcioiIkCTFx8erW7duGjFihAzDKHFsWFiYUlJSFBUVdcn9PP/886pbt66GDx8uSapYsaJee+01bd26VQsXLvT0+/777/XGG29o5MiRnnljYmI0ePBgjR07Vnl5ef4cHgAAKMP8Cj1Lly6VJMXFxXm1x8XFKTMzU+np6SXvqFw5lSt36d39/PPPSk1N9dlH27ZtFRYWpiVLlnjali9fLrfbXWw9LpdLa9euveT+AACAOfgVejIyMmSz2TxneYrUr19fkrRz586rLmjXrl0yDMMzZ5Fy5cqpbt26XvvIyMjw2v+1qAcAAJQN5f3pnJ2dLZvN5tNe1JadnX3VBRXNUdJ+9uzZc8m+l1NPQUGBCgoKPF+7XK4rLxoAANzwTPucnilTpqhy5cqerXbt2oEuCQAAXEN+nemJiIjQN99849NedJakWrVqV11Q0aWz4s68uFwur31c2LdKlSp+1TN27FiNHDnSawzBB0BJ6o5Zc9VzZE3tVQqVALhSfp3psdvtcrlcysnJ8WrPzMyUJLVs2fKqC2rZsqUsFotnziKFhYXKysry2ofdbvfavz/1WK1W2Ww2rw0AAJRdfoWehIQESVJycrJXe3JysqKiohQTEyNJcrvdOnr06BUVFBkZqc6dO/vsY8eOHcrNzfXUIEkPPPCAgoKCiq3HZrPp3nvvvaIaAABA2eNX6ImNjdWAAQPkcDh07NgxSdKaNWu0bt06zZgxw/PREsOGDVPNmjWVlpZ2RUVNnz5d+/fv9zxgMD8/X2PGjFG7du302GOPefrVr19fzz77rF5//XXt379f0vkHG3744Yd69dVXFRYWdkX7BwAAZY9fa3okaf78+XI4HOrYsaOsVquCg4O1fPlyxcfHe/pERkYqPDzc55JRYmKitm7dqgMHDkj6/5enPvvsM1WvXt3TLyYmRsnJyRo9erRmzpyps2fPKjY2VtOmTVNQUJDXnK+99poiIiJ03333KTg4WIZh6M0339Tjjz/u76EBAIAyzGJc7DHKJuJyuVS5cmU5nU7W9wDwcbMvZL7Z65eu/hhu9volfoaK48/vb9Pesg4AAMyF0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyhfKALAGAON+onNAMwD870AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyD0AAAAUyjv74AzZ87I4XDo448/ltVqVUhIiF5++WX16dPnkmNPnjypMWPGaMOGDQoODlbVqlX12muvqUOHDp4+WVlZatSokZo1a+Yz/tChQ6pVq5Z27drlaQsJCSm279ixYzVw4EB/Dw8AAJRRfoeeQYMGaffu3dq8ebMiIiK0atUq9e/fXytWrFDv3r1LHOd2u9WzZ0+FhIQoIyNDFStW1FtvvaW4uDht2rRJrVu39vStVauWMjIyfOa444479Nhjj3m1ldQXAADgQn5d3kpNTVVSUpIcDociIiIkSfHx8erWrZtGjBghwzBKHLtgwQJt3bpV06ZNU8WKFSVJw4cPV506dTRq1ChPv2rVqmnGjBk+49PS0rR371794Q9/8KdkAAAASX6GnqVLl0qS4uLivNrj4uKUmZmp9PT0i44NCwtT27ZtfcampKTo6NGjkqRKlSqpX79+PuNnz56tAQMGeMIWAACAP/wKPRkZGbLZbD7Bo379+pKknTt3XnRsvXr1ZLFYfMYahuG1TufXTpw4oaVLl+qpp57yeS0/P1/Dhg1Tu3bt1KhRI3Xv3l3Lli275LEUFBTI5XJ5bQAAoOzya01Pdna2bDabT3tRW3Z29kXHRkVFXdHYefPmqWHDhurYsaPPa1arVffee69mzpypc+fO6f3339fAgQO1a9cuvfLKKyXOOWXKFE2cOLHE14EbTd0xa656jqypvUqhEgC4Od0Ut6zPmTOn2LM8knTw4EH16dNHFotFwcHBevLJJ/XAAw9oypQpOnToUIlzjh07Vk6n07MdPHjwWpUPAABuAH6FnoiIiGIvAxW1VatWrdTHfv755zpw4IDPXVsX0759e7ndbm3btq3EPlarVTabzWsDAABll1+hx263y+VyKScnx6s9MzNTktSyZcuLjs3KyvK5wyszM1MWi0XR0dHFjps9e7Yee+wxhYWF+byWl5envLw8n/agoCBJUmFh4cUPCAAAmIZfoSchIUGSlJyc7NWenJysqKgoxcTESDr/TJ6iu7EuHOtyubRjxw6v9g0bNqhLly6qXr26z/5ycnKUlJRU4qWt6dOna+TIkT7t6enpslgsXs/+AQAA5uZX6ImNjdWAAQPkcDh07NgxSdKaNWu0bt06zZgxw3Nn1rBhw1SzZk2lpaV5xg4aNEjt2rXT6NGjlZ+fL0maNWuW9u/fr+nTpxe7vw8//FCtW7cu8SyQJH300Udel7FWrlypxYsXa+jQocUunAYAAObk9xOZ58+fL4fDoY4dO8pqtSo4OFjLly9XfHy8p09kZKTCw8O91skEBQVp7dq1Gj16tOx2u+djKNavX1/iGZk5c+bopZdeKrGWwYMH6+zZs3rqqad07tw55eXlyWaz6fXXX9fTTz/t76EBAIAyzO/QExoaqqlTp2rq1Kkl9pk0aZImTZrk0x4eHq7Zs2df9r6+/fbbi75er149TZ48WZMnT77sOQEAgDndFLesAwAAXC1CDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMAVCDwAAMIXygS4AuB7qjllz1XNkTe1VCpUAAAKFMz0AAMAUCD0AAMAUCD0AAMAU/A49Z86c0ZgxY9S4cWNFR0crJiZGK1euvKyxJ0+eVGJioho1aqTmzZurU6dOSktL8+k3ZMgQNWjQQHa73Wt79NFHS7UeAABgHn4vZB40aJB2796tzZs3KyIiQqtWrVL//v21YsUK9e7du8RxbrdbPXv2VEhIiDIyMlSxYkW99dZbiouL06ZNm9S6dWuv/u+++65iY2OvWT0AAMBc/DrTk5qaqqSkJDkcDkVEREiS4uPj1a1bN40YMUKGYZQ4dsGCBdq6daumTZumihUrSpKGDx+uOnXqaNSoUVdU/NXUAwAAzMWv0LN06VJJUlxcnFd7XFycMjMzlZ6eftGxYWFhatu2rc/YlJQUHT161J9SrroeAABgLn6FnoyMDNlsNs9ZlSL169eXJO3cufOiY+vVqyeLxeIz1jAM7dq1y6t94cKF6tKli1q0aKE777xT48aNk9PpLLV6CgoK5HK5vDYAAFB2+RV6srOzZbPZfNqL2rKzs0tlbFhYmCpUqKBVq1Zp9+7dev/995WUlKQOHTooNze3VOqZMmWKKleu7Nlq165dYl8AAHDzuyFvWX/zzTf197//3RNeWrZsqTfeeEP/+c9/NHPmzFLZx9ixY+V0Oj3bwYMHS2VeAABwY/Ir9ERERBR7GaiorVq1atdkrCS1b99ekrR58+ZSmdNqtcpms3ltAACg7PIr9NjtdrlcLuXk5Hi1Z2ZmSjp/RuZiY7OysnzuqMrMzJTFYlF0dLSk87e2F3dZKigoSJJUWFhYKvUAAABz8Sv0JCQkSJKSk5O92pOTkxUVFaWYmBhJ54PLr+/GSkhIkMvl0o4dO7zaN2zYoC5duqh69eqSpIMHD6pOnTpyu91e/YruxGrTpo3f9QAAAPgVemJjYzVgwAA5HA4dO3ZMkrRmzRqtW7dOM2bM8NyZNWzYMNWsWdPracuDBg1Su3btNHr0aOXn50uSZs2apf3792v69Ole+zl9+rTGjx/vCT6HDx/W888/r9q1a2v48OF+1wMAAOD3E5nnz58vh8Ohjh07ymq1Kjg4WMuXL1d8fLynT2RkpMLDw73WyQQFBWnt2rUaPXq07Ha7goODVbVqVa1fv97racy1atXS3LlztWzZMkVHR8swDOXn56tbt26aNGmSz+3pl1MPAACA36EnNDRUU6dO1dSpU0vsM2nSJE2aNMmnPTw8XLNnz77o/CEhIXriiSf0xBNPlFo9AAAAN+Qt6wAAAKWN0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEyB0AMAAEzB7ycyw5zqjllz1XNkTe1VCpUAAHBlONMDAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMwe/Qc+bMGY0ZM0aNGzdWdHS0YmJitHLlyssae/LkSSUmJqpRo0Zq3ry5OnXqpLS0NK8+Z8+e1bJly9SzZ081btxYLVq0UIsWLeRwOJSbm+szZ0hIiOx2u8+2ZMkSfw8NAACUYeX9HTBo0CDt3r1bmzdvVkREhFatWqX+/ftrxYoV6t27d4nj3G63evbsqZCQEGVkZKhixYp66623FBcXp02bNql169aSpC+++EIJCQmaNWuWEhMTJUk7d+7U3XffrbVr1yotLU1BQUGeeWvVqqWMjAx/DwMAAJiMX2d6UlNTlZSUJIfDoYiICElSfHy8unXrphEjRsgwjBLHLliwQFu3btW0adNUsWJFSdLw4cNVp04djRo1yqtvdHS0J/BIUsuWLZWYmKjt27crNTXVn5IBAAAk+Rl6li5dKkmKi4vzao+Li1NmZqbS09MvOjYsLExt27b1GZuSkqKjR49Kku66665i5/nNb34jSTpx4oQ/JQMAAEjyM/RkZGTIZrN5zvIUqV+/vqTzl6EuNrZevXqyWCw+Yw3D0K5duyRJFotFwcHBPuP37Nkjq9Wqjh07erXn5+dr2LBhateunRo1aqTu3btr2bJllzyWgoICuVwurw0AAJRdfoWe7Oxs2Ww2n/aituzs7Gsy1ul0atGiRRo1apRq1Kjh9ZrVatW9996rLVu26JtvvtGDDz6ogQMHavz48Rc9lilTpqhy5cqerXbt2hftDwAAbm43/C3rhmFo6NChatOmjSZMmODz+sGDB9WnTx/PGaInn3xSDzzwgKZMmaJDhw6VOO/YsWPldDo928GDB6/lYQAAgADzK/REREQUexmoqK1atWqlPvZPf/qTcnJylJSUpPLlL+9ms/bt28vtdmvbtm0l9rFarbLZbF4bAAAou/wKPXa7XS6XSzk5OV7tmZmZks7fZXWxsVlZWT53eGVmZspisSg6Otqr3TAMJSYmKisrS6tXr1aFChV85szLy1NeXp5Pe9Et7YWFhZd3YAAAoMzzK/QkJCRIkpKTk73ak5OTFRUVpZiYGEnnn8lTdDfWhWNdLpd27Njh1b5hwwZ16dJF1atX97S53W4NHjxYx48f1/Lly2W1WiVJc+bM0Zw5czz9pk+frpEjR/rUmZ6eLovF4nn2DwAAgF+hJzY2VgMGDJDD4dCxY8ckSWvWrNG6des0Y8YMz51Zw4YNU82aNb2etjxo0CC1a9dOo0ePVn5+viRp1qxZ2r9/v6ZPn+7pd/bsWT300ENKTU1Vr169tGTJEi1YsEALFizQp59+qsOHD3vV9NFHH3ldxlq5cqUWL16soUOHKioqys+3AwAAlFV+P5F5/vz5cjgc6tixo6xWq4KDg7V8+XLFx8d7+kRGRio8PNxrnUxQUJDWrl2r0aNHy263Kzg4WFWrVtX69eu9zsisXbtWSUlJkqQhQ4b47P/Cy2CDBw/W2bNn9dRTT+ncuXPKy8uTzWbT66+/rqefftrfQwMAAGWY36EnNDRUU6dO1dSpU0vsM2nSJE2aNMmnPTw8XLNnz77o/H369Lnok50vVK9ePU2ePFmTJ0++rP4AAMC8bvhb1gEAAEoDoQcAAJgCoQcAAJgCoQcAAJgCoQcAAJgCoQcAAJiC37es48rUHbPmqufImtqrFCoBAMCcONMDAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMgdADAABMwe/Qc+bMGY0ZM0aNGzdWdHS0YmJitHLlyssae/LkSSUmJqpRo0Zq3ry5OnXqpLS0tGL7pqWlqXPnzmrevLkaNWqkoUOH6uTJkz79CgsLNW3aNDVr1kzR0dGKjo7We++95+9hAQCAMq68vwMGDRqk3bt3a/PmzYqIiNCqVavUv39/rVixQr179y5xnNvtVs+ePRUSEqKMjAxVrFhRb731luLi4rRp0ya1bt3a0/eLL75QXFyc/vKXv2j48OHKz89Xz5491bNnT23atElBQUGevqNHj9a8efO0ZcsWRUVFKT09XZ06dVJBQYGGDRvm7+EBAIAyyq8zPampqUpKSpLD4VBERIQkKT4+Xt26ddOIESNkGEaJYxcsWKCtW7dq2rRpqlixoiRp+PDhqlOnjkaNGuXV9/nnn1fdunU1fPhwSVLFihX12muvaevWrVq4cKGn3/fff6833nhDI0eOVFRUlCQpJiZGgwcP1tixY5WXl+fP4QEAgDLMr9CzdOlSSVJcXJxXe1xcnDIzM5Wenn7RsWFhYWrbtq3P2JSUFB09elSS9PPPPys1NdVnH23btlVYWJiWLFniaVu+fLncbnex9bhcLq1du9afwwMAAGWYX6EnIyNDNpvNc5anSP369SVJO3fuvOjYevXqyWKx+Iw1DEO7du2SJO3atUuGYXjm9BRarpzq1q3rtY+MjAyv/ftTDwAAMBe/1vRkZ2fLZrP5tBe1ZWdnX3Rs0SWoi40t+m9J+9mzZ4/XnMX1vZx6CgoKVFBQ4Pna6XRKklwuV4ljrkZhQf5Vz3Gtarsc1B/Y+qWb/xion/qv1tUew81ev8TP0MXmvNgSmyJ+L2QuK6ZMmaKJEyf6tNeuXTsA1VyeyjMCXcHVof7Au9mPgfoDi/oD72Y/hmtZf25uripXrnzRPn6FnoiICH3zzTc+7UUpq1q1ahcdW1zC+/XYoktnJfW9cB8X9q1SpYpf9YwdO1YjR470fF1YWKjjx4/r1ltv9bkEd625XC7Vrl1bBw8eLPYMF649vgeBxfsfeHwPAov3/8oZhqHc3FzVqlXrkn39Cj12u11btmxRTk6Obr31Vk97ZmamJKlly5YXHbt582YZhuEVKjIzM2WxWBQdHe2Zw2KxeOYsUlhYqKysLHXq1Mlrzo8++kiZmZlet7xfTj1Wq1VWq9WrLTw8vMT+14PNZuOHPcD4HgQW73/g8T0ILN7/K3OpMzxF/FrInJCQIElKTk72ak9OTlZUVJRiYmIknX8mT9HdWBeOdblc2rFjh1f7hg0b1KVLF1WvXl2SFBkZqc6dO/vsY8eOHcrNzfXUIEkPPPCAgoKCiq3HZrPp3nvv9efwAABAWWb4acCAAUbTpk2N7OxswzAMY/Xq1UZQUJCxcuVKT58nn3zSKFeunLF582ZP27lz54x27doZsbGxxqlTpwzDMIy3337bCA0NNdLT0732sWPHDiM0NNSYOXOmYRiGcerUKSM2NtZo166dce7cOa++zz//vBEZGWlkZmYahmEY6enpRoUKFYy33nrL30MLGKfTaUgynE5noEsxLb4HgcX7H3h8DwKL9//68Hsh8/z58+VwONSxY0dZrVYFBwdr+fLlio+P9/SJjIxUeHi41ym6oKAgrV27VqNHj5bdbldwcLCqVq2q9evXe12aks4/YDA5OVmjR4/WzJkzdfbsWcXGxmratGleT2OWpNdee00RERG67777FBwcLMMw9Oabb+rxxx/399ACxmq1asKECT6X23D98D0ILN7/wON7EFi8/9eHxTAu4x4vAACAmxyfsg4AAEyB0AMAAEyB0AMAAEyB0APghjF79mxZLBY5HI5AlwKgDCL0BNCZM2c0ZswYNW7cWNHR0YqJidHKlSsDXZZpZGZmasyYMbrjjjvUokULNWnSRD179tTnn38e6NJM6cSJE3rxxRcDXYYpffrpp4qLi1Pr1q3VsGFDNWvWTOPGjQt0WaaQkZGhvn37qmnTpoqOjlZ0dLSmT5+uc+fOBbq0sinAt8yb2oABA4wmTZp4nnm0cuVKIygoyFi1alWAKzOHHj16GK1atTJ+/PFHwzAM45dffjESExMNi8VirFixIsDVmc/TTz9t9O3b15BkTJgwIdDlmMbcuXON22+/3di9e7en7c9//rNRv379AFZlDj/88IMRHh5uPPzww0ZBQYFhGIaxbds2IzQ01HjhhRcCXF3ZROgJkJSUFEOSsXjxYq/2Hj16GFFRUUZhYWGAKjOPHj16GMuXL/dqy8/PN8qXL2906tQpQFWZ086dO40aNWoYX331FaHnOjp48KBRoUIFIykpyav91KlTxtq1awNUlXm8/fbbhiTjiy++8GqPj483atasGaCqyjYubwXI0qVLJUlxcXFe7XFxccrMzFR6enogyjKVVatWqV+/fl5tFSpUUNWqVXXixInAFGVSf/rTnzRp0qSAf/6d2cybN08FBQW67777vNorVqzIx/hcB0UP2/31payzZ8/K7XYHoqQyj9ATIBkZGbLZbJ5Pii9Sv359SdLOnTsDUZapBAcHe334rSQdP35c2dnZuvvuuwNUlfksWbJELpfrpnqKelmxadMm1ahRQ9u2bdM999yjZs2aqVWrVpo4caIKCgoCXV6Z9/DDD6t58+ZyOBw6efKkJGnNmjVav369nnvuucAWV0b5/TEUKB3Z2dnFfpJuUVt2dvb1LgmS3nnnHUVERGjs2LGBLsUU8vPz9cILL2jRokUqV45/g11vBw4cUE5Ojp566il98sknatSokdLS0hQfH6/t27drzZo1gS6xTAsLC9OGDRv0xBNPKCIiQhERETp37pzeffddDR48ONDllUn8LQP8ny+//FJ/+ctftGTJEtWoUSPQ5ZjClClT9Nvf/lYdO3YMdCmmdObMGRUUFOjFF19Uo0aNJEkdOnTQ8OHD9c9//lP//ve/A1xh2bZ37161adNGwcHBys7O1pEjR7RmzRq99NJLevXVVwNdXplE6AmQiIgIuVwun/aitmrVql3vkkztv//9r/r166f58+era9eugS7HFPbv369Zs2Zp2rRpgS7FtMLCwiRJdrvdq71Vq1aSpO3bt1/vkkzlpZde0sGDBzV37lxVqVJFknTXXXfpueee04svvqjNmzcHuMKyh9ATIHa7XS6XSzk5OV7tmZmZkqSWLVsGoixTysjIUM+ePfXee++pd+/egS7HNNavX69KlSqpV69estvtstvtngW177zzjux2uwYOHBjgKsu2Zs2aSZIKCwu92osW2P66HaVr165dqlatmqpWrerV3rhxY0nSli1bAlFWmUboCZCEhARJUnJysld7cnKyoqKiFBMTE4iyTGfbtm3q27ev5s+fr+7du3vaef+vvT/+8Y/64YcflJGR4dn++c9/SpISExOVkZGhJUuWBLjKsq1v376Szv/yvdDu3bslSW3btr3uNZlJZGSkcnJylJeX59WelZUlSbr11lsDUFXZZjEMwwh0EWb14IMP6ptvvtG///1vRUREaM2aNerbt68+/vhjxcfHB7q8Mu/f//63evfurSFDhvj85T5o0CDxR+P6y8rKUr169TRhwgQ+iuI6KCwsVJcuXZSTk6MNGzaoRo0a2rt3r7p06aJWrVqxkPkaW7Fihe6//349/vjjevvttxUcHKzMzEx169ZNbrdbX3/9dbE3vODKEXoC6MyZM3I4HPr4449ltVoVHBysCRMmqE+fPoEuzRTuvPNOffXVVyW+zh+N6+fkyZOKjY3VL7/8ov/+97+KjIxUjRo1NHLkSP3ud78LdHllmsvl0ksvvaRPPvlEFStWlNvt1kMPPaQXX3xRVqs10OWVeSkpKZo6dar279+vkJAQnTt3Tt26ddO4ceNUs2bNQJdX5hB6AACAKbCmBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhBwAAmAKhB0CZ8uyzz6pBgwayWCxKSUm56vn27Nkju92uW265RbGxsVc9H4DAIfQACKjTp0/LbrerRo0aslgsatasmcaMGXPF873xxht69913S62+xo0bKyMjgw+hBcoAQg+AgKpQoYIyMjKUmJgoSfrnP/+pqVOnBrgqAGURoQcAAJgCoQfATSMjI0OPPPKIWrZsqVatWqlly5aaOHGiCgoKiu1/7NgxPfLII7Lb7apataoGDRqk48ePe/X55Zdf9NJLL6l+/fpq2rSpGjVqpFdeeUVut/uS9SxatEgxMTG68847FR0drd69e2vFihWlcagAroHygS4AAC7Xp59+KsMwtGPHDoWEhOj48ePq3bu3Tp48qTfeeMOn/yuvvKJly5apUaNGOnDggDp16qQHH3xQycnJnj4PPfSQtmzZos8//1wNGjTQ3r171blzZx0+fFizZs0qsZZNmzbp97//vb7++ms1atRIbrdbzz//vGbMmKF+/fpdi8MHcJU40wPgpjFkyBDNmjVLISEhkqSqVavqd7/7nebMmSPDMHz6P/jgg2rUqJEk6fbbb9dzzz2nDRs2aMOGDZKkjRs36uOPP9bIkSPVoEEDSVLDhg01bNgwzZ49Wz/88EOJtWzdulWhoaGqXbu2JCkoKEgvvPCCBgwYUKrHDKD0EHoA3DTCw8M1Z84cdejQQXfccYfsdrteffVV5efn68iRIz79o6Ojvb5u27atJCktLU2S9Nlnn0mSfvvb33r1u+OOO2QYxkVvee/SpYvy8/PVunVrvfXWWzp06JBq1qyp4cOHX80hAriGuLwF4KbxxBNPaO3atVq/fr1atWolSfrggw/0+9//vth1PTabzevrqlWrSpJ+/PFHSefX/EjS448/7jl7JJ1f5xMZGSmXy1ViLW3atFFaWpqmT5+uUaNG6X/+53/UqVMnTZ8+3ROuANxYCD0Abnhut1v5+flavHixEhMTPYHnUpxOp9fXOTk5kqTbbrtNkhQRESFJ+uijj9SyZUu/62rTpo2WLFmi3NxcLV26VA6HQ927d1dWVpaqVKni93wAri0ubwG44c2fP19DhgyR2+1WuXLef2399NNPJY77+uuvvb7evn27JKlDhw6SpB49ekiSvvrqK69+brdbjz76qL799tsS5160aJFWrlwpSQoLC9Pjjz+uv/3tb3K5XNq/f/9lHhmA64nQA+CmEBYWptjYWC1ZskSZmZmSpIMHD+qdd94pccwHH3yg7777TpJ04MABvf7667r77rt19913S5JiY2M1YMAAvfLKK/r+++8lSefOndPLL7+svXv3ehZBF+e7777TlClTdOLECUlSYWGh/v3vf6tWrVpq1qxZqRwzgNLF5S0AAZWfn69mzZrp5MmTks4vKi5f3vuvpry8PPXu3VuLFi3SM888o44dO6pOnTqKjIzU/fffrxkzZui+++7TmDFj9NVXX2nVqlWSpPHjx2vUqFHav3+/Dh06pF69eulvf/ub19yLFi3S5MmT1aNHD4WEhCgkJEQdOnTQp59+qnLlymnPnj0aOHCg9u3bJ0my2+1asWKF+vfvr6ysLHXs2FEhISE6d+6cGjVqpPXr1ys0NPTav3EA/GYxirvPEwAAoIzh8hYAADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADAFQg8AADCF/wechE0GWA7BlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "### load module, and also MNIST/MNIST-M\n",
    "from importlib.machinery import SourceFileLoader\n",
    "mymodule = SourceFileLoader('mnistm', path_to_root_file+'mnist_transfer/data/mnist_m.py').load_module()\n",
    "mymodule2 = SourceFileLoader('mnist', path_to_root_file+'mnist_transfer/data/mnist.py').load_module()\n",
    "import mnistm\n",
    "import mnist\n",
    "x_train, y_train, x_test, y_test = mnist.load_mnist()\n",
    "x_train_m, y_train_m, x_test_m, y_test_m = mnistm.load_mnistm(y_train,y_test)\n",
    "\n",
    "\n",
    "### load module\n",
    "mymodule = SourceFileLoader('label_shift', path_to_root_file+'mnist_transfer/data/label_shift.py').load_module()\n",
    "\n",
    "from label_shift import *\n",
    "    \n",
    "######### Here we use the functions from label_shift ################\n",
    "\n",
    "###### Add train and test together and shift the distributions to create source and target distributions\n",
    "### MNIST all data\n",
    "x_full=np.append(x_train,x_test, axis=0)\n",
    "y_full=np.append(y_train,y_test, axis=0)\n",
    "### MNIST-M all data\n",
    "x_full_m=np.append(x_train_m,x_test_m, axis=0)\n",
    "y_full_m=np.append(y_train_m,y_test_m, axis=0)\n",
    "#x_shift,y_shift,x_shift_target,y_shift_target =label_shift(x_train,y_train,1/2,7)\n",
    "x_shift, y_shift, x_shift_target, y_shift_target =label_shift_linear(x_full,y_full,1/12,[0,1,2,3,4,5,6,7,8,9])\n",
    "x_shift_m, y_shift_m,x_shift_target_m, y_shift_target_m=label_shift_linear(x_full_m,y_full_m,1/12,[0,1,2,3,4,5,6,7,8,9],decreasing=False)\n",
    "\n",
    "plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_shift_target,\"shifted, target\")\n",
    "plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_shift,\"shifted, source\")\n",
    "plot_splitbars([0,1,2,3,4,5,6,7,8,9],y_shift,y_shift_m,\"MNIST, source\",\"MNIST-M, source\")\n",
    "plot_splitbars([0,1,2,3,4,5,6,7,8,9],y_shift_target,y_shift_target_m,\"MNIST, target\",\"MNIST-M, target\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 10) and (None, 32, 32, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0ce2126437d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#print(x_full.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#keras.utils.plot_model(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_full_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_full_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;31m#model.score(x_full_m,y_full_m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_usps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/losses.py:1643 categorical_crossentropy\n        return backend.categorical_crossentropy(\n    /usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 10) and (None, 32, 32, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "def init_resnet_model(Binary=True):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    model = Sequential()\n",
    "    ## no top as we want 10 classes for mnist etc\n",
    "    model.add(ResNet50(include_top = False, pooling = 'avg', weights = None))\n",
    "    if Binary:\n",
    "        model.add(Dense(2, activation = 'softmax'))\n",
    "    else:\n",
    "        model.add(Dense(10, activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "# model=init_resnet_model(Binary=False)\n",
    "# model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(x_full, y_full,\n",
    "#            batch_size=batch_size,\n",
    "#            epochs=10,\n",
    "#            verbose=1,\n",
    "#            validation_data=(x_full_m, y_full_m),\n",
    "#           )\n",
    "\n",
    "\n",
    "\n",
    "def init_FC_model(Binary=True):\n",
    "    ### same as Dziugaite, to compare with rivasplata et al. in their case\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024,input_shape=(32,32,3), activation = 'relu'))\n",
    "    model.add(Dense(600, activation = 'relu'))\n",
    "    model.add(Dense(600, activation = 'relu'))\n",
    "    if Binary:\n",
    "        model.add(Dense(2, activation = 'softmax'))\n",
    "    else:\n",
    "        model.add(Dense(10, activation = 'softmax'))\n",
    "    return model\n",
    "model=init_FC_model(Binary=False)\n",
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "#print(x_full.shape)\n",
    "#keras.utils.plot_model(model)\n",
    "model.fit(x_full, y_full,batch_size=256,epochs=10,verbose=1,validation_data=(x_full_m, y_full_m))\n",
    "#model.score(x_full_m,y_full_m)\n",
    "def load_usps():\n",
    "    import gzip\n",
    "    import pickle\n",
    "    ## copied and changed from https://github.com/JingWang18/Discriminative-Feature-Alignment/\n",
    "    f = gzip.open('/home/adam/Code/Datasets/usps/usps_28x28.pkl', 'rb')\n",
    "    data_set = pickle.load(f, encoding=\"bytes\")\n",
    "    f.close()\n",
    "    img_train = data_set[0][0]\n",
    "    label_train = data_set[0][1]\n",
    "    img_test = data_set[1][0]\n",
    "    label_test = data_set[1][1]\n",
    "    ### do we need this??\n",
    "    #inds = np.random.permutation(img_train.shape[0])\n",
    "  \n",
    "    #img_train = img_train[inds][:6562]\n",
    "    #label_train = label_train[inds][:6562]\n",
    "    \n",
    "    img_train = img_train * 255\n",
    "    img_test = img_test * 255\n",
    "    img_train = img_train.reshape((img_train.shape[0], 28, 28, 1))\n",
    "    img_test = img_test.reshape((img_test.shape[0], 28, 28, 1))\n",
    "\n",
    "    #### test this part!!!\n",
    "    img_train = np.pad(img_train,((0,0),(2,2),(2,2),(0,0))) #padding to make images 32x32 and not 28x28\n",
    "    img_test = np.pad(img_test,((0,0),(2,2),(2,2),(0,0))) \n",
    "    \n",
    "    ## normalising to unit variance\n",
    "    sigma=np.std(img_train)\n",
    "    img_train /= sigma \n",
    "    img_test /= sigma\n",
    "\n",
    "    ## mean subtraction\n",
    "    mu=np.mean(img_train)\n",
    "    img_train -= mu\n",
    "    img_test -= mu\n",
    "    print('mean, variance', mu, sigma)\n",
    "    \n",
    "    ## expand to (N,32,32,3) so that we can compare the two datasets\n",
    " \n",
    "    img_train=np.concatenate((img_train,img_train,img_train),axis=3)\n",
    "    img_test=np.concatenate((img_test,img_test,img_test),axis=3) \n",
    "    print(\"---------------Load USPS----------------\")\n",
    "    print('Training set', img_train.shape, label_train.shape)\n",
    "    #print('Validation set', x_val.shape, y_val.shape)\n",
    "    print('Test set', img_test.shape, label_test.shape)\n",
    "    print(\"\\n\")\n",
    "    return img_train, label_train, img_test, label_test\n",
    "\n",
    "#img_train, label_train, img_test, label_test = load_usps()\n",
    "\n",
    "def train_and_eval_LR(x_train,y_train,x_test,y_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    LR = LogisticRegression()\n",
    "    LR.fit(x_train,y_train)\n",
    "    score = LR.score(x_test, y_test)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Add the label shifted datasets to each other creating the source and target domain for task 2\n",
    "\n",
    "##### calculate the label densities here\n",
    "densities=[]\n",
    "densities.append(np.sum(y_shift,axis=0))\n",
    "densities.append(np.sum(y_shift_m,axis=0))\n",
    "densities.append(np.sum(y_shift_target,axis=0))\n",
    "densities.append(np.sum(y_shift_target_m,axis=0))\n",
    "# mnist source, mnist-m source, mnist target,  mnist-m target\n",
    "#print(densities)\n",
    "TASK=2\n",
    "if TASK==1:\n",
    "    ###### label density shifted mnist\n",
    "    x_source=x_shift\n",
    "    y_source=y_shift\n",
    "    x_target=x_shift_target\n",
    "    y_target=y_shift_target\n",
    "elif TASK==2:\n",
    "    #### MIXED MNIST and MNIST-m\n",
    "    L=len(densities[0])\n",
    "    interdomain_densities = [[] for x in range(2)]\n",
    "    for i in range(L):\n",
    "        ## all densities are # in mnist over # in mnist-m\n",
    "        interdomain_densities[0].append(densities[0][i]/densities[1][i])\n",
    "        interdomain_densities[1].append(densities[2][i]/densities[3][i])\n",
    "    print(interdomain_densities)\n",
    "    x_source=np.append(x_shift,x_shift_m, axis=0)\n",
    "    y_source=np.append(y_shift,y_shift_m, axis=0)\n",
    "    x_target=np.append(x_shift_target,x_shift_target_m, axis=0)\n",
    "    y_target=np.append(y_shift_target,y_shift_target_m, axis=0)\n",
    "elif TASK==3:\n",
    "    #### MNIST -> MNIST-m\n",
    "    x_source=x_full\n",
    "    y_source=y_full\n",
    "    x_target=x_full_m\n",
    "    y_target=y_full_m\n",
    "elif TASK==4:\n",
    "    #### MNIST->USPS\n",
    "    x_source=x_full\n",
    "    y_source=y_full\n",
    "    x_target=x_usps\n",
    "    y_target=y_usps\n",
    "elif TASK==5:\n",
    "    #### MNIST -> SVHN\n",
    "    x_source=x_full\n",
    "    y_source=y_full\n",
    "    x_target=x_svhn\n",
    "    y_target=y_svhn\n",
    "elif TASK==6:\n",
    "    x_source=x_chexpert\n",
    "    y_source=y_chexpert\n",
    "    x_source=x_chest14\n",
    "    y_source=y_chest14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## testing images and such\n",
    "\n",
    "\n",
    "\n",
    "#print(X_test)\n",
    "#print(\"----------------------------------------------------\")\n",
    "#print(x_test)\n",
    "\n",
    "#print(make_mnist_binary(y_train))\n",
    "#plt.imshow(x_test_m[605]) \n",
    "#print(x_test_m[303])\n",
    "#print(y_test_m[605])\n",
    "#plt.imshow(x_test[605]) \n",
    "#print(x_test[303])\n",
    "#print(y_test[605])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "def mmd_rbf_linear(x,y,sigma_square):\n",
    "    from sklearn import metrics\n",
    "    \"\"\"\n",
    "    Here we want to compute the unbiased estimate of the MMD in linear time using the formula\n",
    "    MMD^2_k(p,q)=2/n_s for i=1 to n_s/2 g_k(z_i)\n",
    "    ,where z_i=(x^s_2i-1,x^s_2i,x^t_2i-1,x^t_2i) and\n",
    "    g_k(z_i)= k(x^s_2i-1,x^s_2i)+k(x^t_2i-1,x^t_2i)-k(x^s_2i-1,x^t_2i)-k(x^s_2i,x^t_2i-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_s=len(x)\n",
    "    n=int(np.floor(n_s/2.0))\n",
    "    \n",
    "    ### make the data into a form which we can compute with, i.e on Nx1 vector form\n",
    "    if x.ndim==1 or y.ndim==1:\n",
    "        x=x.reshape(-1, 1)\n",
    "        y=y.reshape(-1, 1)\n",
    "    \n",
    "    ##take out odd and even entries for the two vectors\n",
    "    x_even=x[:n_s:2]\n",
    "    x_odd=x[1:n_s:2]\n",
    "    y_even=y[:n_s:2]\n",
    "    y_odd=y[1:n_s:2]\n",
    "    \n",
    "    A=[]\n",
    "    B=[]\n",
    "    C=[]\n",
    "    D=[]\n",
    "    \n",
    "    \n",
    "    #### here we should do pairwise computation of the one off diagonal\n",
    "    for i in range(n_s-1):\n",
    "            A.append(kernel_scalar(x[i+1],x[i],sigma_square)[0])\n",
    "            B.append(kernel_scalar(y[i+1],y[i],sigma_square)[0])\n",
    "            C.append(-1*kernel_scalar(x[i],y[i+1],sigma_square)[0])\n",
    "            D.append(-1*kernel_scalar(y[i+1],x[i],sigma_square)[0])\n",
    "    A=np.array(A)\n",
    "    B=np.array(B)\n",
    "    C=np.array(C)\n",
    "    D=np.array(D)\n",
    "    #*(1/n) not needed?\n",
    "\n",
    "    #print(\"A=\"+str(A))\n",
    "    #print(\"B=\"+str(B))\n",
    "    #print(\"C=\"+str(C))\n",
    "    #print(\"D=\"+str(D))\n",
    "    \n",
    "    return (A+B+C+D).mean()\n",
    "def mmd_rbf(x,y,sigma_square):\n",
    "    from sklearn import metrics\n",
    "    #### if needed for one dimensional data\n",
    "    if x.ndim==1 or y.ndim==1:\n",
    "        x=x.reshape(-1, 1)\n",
    "        y=y.reshape(-1, 1)\n",
    "    XX = metrics.pairwise.rbf_kernel(x, x, 1/sigma_square)\n",
    "    YY = metrics.pairwise.rbf_kernel(y, y, 1/sigma_square)\n",
    "    XY = metrics.pairwise.rbf_kernel(x, y, 1/sigma_square)\n",
    "    A=np.diag(XX,1)\n",
    "    B=np.diag(YY,1)\n",
    "    C=-np.diag(XY,1)\n",
    "    D=-np.diag(XY,1)\n",
    "    #print(\"A=\"+str(A))\n",
    "    #print(\"B=\"+str(B))\n",
    "    #print(\"C=\"+str(C))\n",
    "    #print(\"D=\"+str(D))\n",
    "    \n",
    "    return (np.diag(XX,1)+np.diag(YY,1)-np.diag(XY,1)-np.diag(XY,1)).mean()#XX.mean() + YY.mean() - 2 * XY.mean()\n",
    "\n",
    "  \n",
    "def kernel_scalar(x,y,sigma_square):\n",
    "    return np.exp(-(1/(sigma_square)) * ((x - y) ** 2))\n",
    "def kernel(x,y,sigma_square):\n",
    "    return np.exp(-(1/(sigma_square)) * ((x - y) ** 2).sum(axis=1))\n",
    "def kernel2(x,y,sigma_square):\n",
    "    return np.exp(-np.sum(np.square(x-y),axis=1)/(sigma_square))\n",
    "'''\n",
    "#Test cases\n",
    "A=np.ones(4)\n",
    "B=np.linspace(1,4,4)\n",
    "print(mmd_rbf_linear(A,B,1))\n",
    "print(mmd_rbf(A.reshape(-1, 1),B.reshape(-1, 1),1))\n",
    "print(\"------------------------------\")\n",
    "A=np.ones(9)\n",
    "B=np.ones(9)+ [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "print(mmd_rbf_linear(A,B,1))\n",
    "print(mmd_rbf(A.reshape(-1, 1),B.reshape(-1, 1),1))\n",
    "\n",
    "\n",
    "#### test with normal dist. data we should see that the \n",
    "#### normal dist should be centered at about 0.17-0.2 on the x-axis\n",
    "MMDsq=[]\n",
    "MMDsq2=[]\n",
    "for i in range(2000):\n",
    "    samples = np.random.normal(0, 1, 200);\n",
    "    samples2= np.random.normal(0,3*np.sqrt(2), 200);\n",
    "    #MMDsq.append(mmd_rbf(mnist_flat,mnistm_flat,0.5))\n",
    "    #mmds=[]\n",
    "    #for sigma in sigmas:\n",
    "            #mmds.append(mmd_rbf_linear(samples,samples2,sigma))\n",
    "    MMDsq.append(mmd_rbf_linear(samples,samples2,0.5))\n",
    "    MMDsq2.append(mmd_rbf(samples,samples2,0.5))\n",
    "    #MMDsq.append(np.sum(mmds))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "\n",
    "print(np.mean(MMDsq))\n",
    "print(np.mean(MMDsq2))\n",
    "plt.hist(MMDsq,bins=20)\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_images(x_train,x_train_m):\n",
    "    ### flatten images into vectors to be able to compute MMD\n",
    "    mnist_flat=[None]*len(x_train)\n",
    "    mnistm_flat=[None]*len(x_train)\n",
    "    for i in range(len(x_train)):\n",
    "        mnist_flat[i]=tf.reshape(x_train[i],[-1])\n",
    "        mnistm_flat[i]=tf.reshape(x_train_m[i],[-1])\n",
    "    #print(np.array(mnist_flat).shape)\n",
    "    #print(np.array(mnistm_flat).shape)\n",
    "    return np.array(mnist_flat), np.array(mnistm_flat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## flatten the mnist and mnist-m images and use the MMD to compute a metric between them\n",
    "mnist_flat, mnistm_flat=flatten_images(x_train,x_train_m)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### do this for a range of sigma and sum the results for an estimation of the true MMD\n",
    "\n",
    "sigmas = [\n",
    "      1e-6, 1e-5, \n",
    "      1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100,\n",
    "      1e3, 1e4, 1e5, 1e6\n",
    "  ]\n",
    "\n",
    "mmdlist=[]\n",
    "\n",
    "for sigma in sigmas:\n",
    "    mmdlist.append(mmd_rbf(mnist_flat[:1000],mnistm_flat[:1000],sigma))\n",
    "print(mmdlist)\n",
    "finalmmd=np.sqrt(np.mean(mmdlist))\n",
    "print(finalmmd)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "### load module\n",
    "mymodule = SourceFileLoader('train', path_to_root_file+'mnist_transfer/experiments/training.py').load_module()\n",
    "mymodule2 = SourceFileLoader('kl', path_to_root_file+'mnist_transfer/util/kl.py').load_module()\n",
    "mymodule3 = SourceFileLoader('util', path_to_root_file+'mnist_transfer/util/misc.py').load_module()\n",
    "mymodule4 = SourceFileLoader('SL', path_to_root_file+'mnist_transfer/experiments/SL_bound.py').load_module()\n",
    "from kl import *\n",
    "from train import *\n",
    "from util import *\n",
    "from SL import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import gc\n",
    "import re\n",
    "\n",
    "def read_weights(model,w_a,x_bound,y_bound,x_target,y_target,sigma,epsilon,alpha,Binary=False,Task=TASK):\n",
    "    batch_size=128\n",
    "    batches_per_epoch=np.ceil(len(y_target)/batch_size) ## should be 547\n",
    "    epoch=1\n",
    "    \n",
    "    KLs=[]\n",
    "    errors=[]\n",
    "    targeterrors=[]\n",
    "    epochs=[]\n",
    "    \n",
    "    sigma=sigma[0]*10**(-1*sigma[1])    \n",
    "    \n",
    "    ### Here we do something more intelligent to not have to hardcode the epoch amounts. \n",
    "    ### we parse the filenames and sort them in numerical order and then load the weights\n",
    "    if Binary:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "    else:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "        \n",
    "    #epochs = [] #list of \n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    dirFiles = os.listdir(path) #list of directory files\n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non checkpoints\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            ### if it has a one it goes in one list and if it starts with a two it goes in the other\n",
    "            if (name[0]==\"1\"):\n",
    "                list1.append(name)\n",
    "            elif (name[0]==\"2\"):\n",
    "                list2.append(name)\n",
    "            #epochs.append(name)\n",
    "    #epochs.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    num_batchweights=len(list1)\n",
    "    list2.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.extend(list2)\n",
    "    Ws=list1 ## vector of checkpoint filenames\n",
    "    \n",
    "    weight_updates=[]\n",
    "    for i in Ws:\n",
    "        #print(i)\n",
    "        if i[0]==\"1\":\n",
    "            if i[1]==\"_\":\n",
    "                weight_updates.append(int(i[2:]))\n",
    "    for i in list2:\n",
    "        weight_updates.append((int(i[2:])+1)*batches_per_epoch)\n",
    "   \n",
    "    ### load the model and the weights\n",
    "    for checkpoint in Ws:\n",
    "        if Binary:\n",
    "            model=init_MNIST_model_binary()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        else:\n",
    "            model=init_MNIST_model()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        model.load_weights(path+\"/\"+str(checkpoint)+\".ckpt\").expect_partial()\n",
    "        w_s=model.get_weights()\n",
    "        \n",
    "        ##### draw classifiers that are samples from the gaussian dists which define our posterior\n",
    "        \n",
    "        t = time.time()\n",
    "        ## do some draws of the posterior\n",
    "        w_s_draws=draw_classifier(w_s,sigma,num_classifiers=2)\n",
    "       \n",
    "        ## do some draws of the prior\n",
    "        #if w_a is not None:\n",
    "        #    w_a_draws=draw_classifier(w_a,sigma,num_classifiers=2)\n",
    "        #else:\n",
    "        #    print(\"Error: No prior weights were supplied!\")\n",
    "        #    sys.exit(-1)\n",
    "          \n",
    "        elapsed = time.time() - t\n",
    "        print(\"Time spent drawing the classifiers: \"+str(elapsed)+\"\\n\")\n",
    "   \n",
    "    \n",
    "        \n",
    "        ###### for each pair of drawn prior and posterior we calculate the necessary parts of the bound \n",
    "        ###### and then average the result and return that\n",
    "        k=0\n",
    "        errorsum=0\n",
    "        target_errorsum=0\n",
    "        KLsum=0\n",
    "        \n",
    "        for i in w_s_draws:\n",
    "            model.set_weights(i)\n",
    "            errorsum+=((1-model.evaluate(x_bound,y_bound,verbose=0)[1]))#+errorsum*k)/(k+1)\n",
    "            target_errorsum+=((1-model.evaluate(x_target,y_target,verbose=0)[1]))#+target_errorsum*k)/(k+1)\n",
    "            #k+=1\n",
    "        errorsum/=len(w_s_draws)\n",
    "        target_errorsum/=len(w_s_draws)\n",
    "        KLsum=estimate_KL(w_a,w_s,sigma)\n",
    "        \n",
    "        print(\"Iteration done with sigma:\"+str(sigma)+\" and epsilon:\"+str(epsilon))\n",
    "        KLs.append(KLsum)\n",
    "        targeterrors.append(target_errorsum)\n",
    "        errors.append(errorsum)\n",
    "        ## this is needed because keras is bad and leaks memory; Or I am dumb and cannot see what I am doing wrong\n",
    "        del model\n",
    "        _ = gc.collect()\n",
    "    \n",
    "    #print(\"we made it here!!!!\")\n",
    "    #sys.exit(-1)\n",
    "    \n",
    "    return KLs,errors,targeterrors,Ws,Xvector\n",
    "\n",
    "class stop_callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='accuracy', value=0.001, verbose=0):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy')> self.value): # select the accuracy\n",
    "            print(\"\\n !!! training error threshold reached, no further training !!!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "class fast_checkpoints(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,checkpoint_path,save_freq):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.save_freq=save_freq\n",
    "        self.filepath=checkpoint_path\n",
    "        self.verbose=1\n",
    "        self.save_best_only=False\n",
    "        self.save_weights_only=True\n",
    "    def on_train_batch_begin(self, batch, epoch, logs=None):\n",
    "         if batch%self.save_freq==0:\n",
    "            self.model.save_weights(self.filepath+\"/1_\"+str(batch)+\".ckpt\")\n",
    "            print(\"\\n Saved weights at the start of batch\"+str(batch)+\"\\n\")\n",
    "            self.model.save_weights(self.filepath+\"/1_\"+str(batch)+\".ckpt\")\n",
    "            \n",
    "def train_posterior(alpha,x_train,y_train,prior_weights=None,x_test=[],y_test=[],save=True,epsilon=0.01,Task=2,Binary=False):\n",
    "        \n",
    "        TASK=Task\n",
    "        batch_size=128\n",
    "        \n",
    "        ### x_test should be the whole of S for early stopping purposes\n",
    "    \n",
    "        checkpoint_path = \"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "        if Binary:\n",
    "            checkpoint_path = \"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "        \n",
    "        \n",
    "        # Create a callback that saves the model's weights every epoch\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        save_freq=547,   ### 547 = ceiling(70000/128) i.e training set for MNIST/MNIST-M,\n",
    "        filepath=checkpoint_path+\"/2_{epoch:0d}.ckpt\", \n",
    "        verbose=1,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True,\n",
    "            ## tune when to save as needed for plots\n",
    "        )\n",
    "        fast_cp_callback =fast_checkpoints(checkpoint_path,45)\n",
    "        stopping_callback=stop_callback(monitor='val_acc',value=1-epsilon)\n",
    "    \n",
    "        if Binary:\n",
    "            M=init_MNIST_model_binary()\n",
    "        else:\n",
    "            M=init_MNIST_model()\n",
    "\n",
    "        \n",
    "            \n",
    "        ## choose loss function, optimiser etc. and train\n",
    "        \n",
    "        M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        ### load the prior weights\n",
    "        if prior_weights is not None:\n",
    "            M.set_weights(prior_weights)\n",
    "        elif(alpha==0):\n",
    "            ### save the rand. init as the prior\n",
    "            prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "            M.save_weights(prior_path)\n",
    "        else:\n",
    "            if Binary:\n",
    "                prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "                M.load_weights(prior_path).expect_partial()\n",
    "            else:\n",
    "                prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "                M.load_weights(prior_path).expect_partial()\n",
    "        \n",
    "    \n",
    "        if save:\n",
    "            CALLBACK=[fast_cp_callback,stopping_callback]\n",
    "        else:\n",
    "            CALLBACK=[stopping_callback]\n",
    "        ### train for one epoch with more checkpoints to be able to plot more there\n",
    "        fit_info = M.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=1, \n",
    "           callbacks=CALLBACK,\n",
    "           validation_data=(x_test, y_test),\n",
    "           verbose=1,\n",
    "                        )\n",
    "        \n",
    "        \n",
    "        if save:\n",
    "            CALLBACK=[cp_callback,stopping_callback]\n",
    "        else:\n",
    "            CALLBACK=[stopping_callback]\n",
    "            \n",
    "        fit_info = M.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=2000, # we should have done early stopping before this completes\n",
    "           callbacks=CALLBACK,\n",
    "           validation_data=(x_test, y_test),\n",
    "           verbose=1,\n",
    "                        )\n",
    "        \n",
    "        \n",
    "         #### save the last posterior weights to disk\n",
    "        epochs_trained=len(fit_info.history['loss'])\n",
    "        if save:\n",
    "            M.save_weights(checkpoint_path+\"/2_\"+str(epochs_trained)) ###### check if we need this; TODO!!!!!!\n",
    "            \n",
    "        #### save textfile with parameters, i.e. alpha ,epochs trained and epsilon\n",
    "        if Binary:\n",
    "            with open('posteriors/'+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'w') as f:\n",
    "                f.write('\\n'.join([str(alpha), str(epsilon), str(epochs_trained)]))     \n",
    "            f.close()\n",
    "        else:\n",
    "            with open('posteriors/'+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'w') as f:\n",
    "                f.write('\\n'.join([str(alpha), str(epsilon), str(epochs_trained)]))     \n",
    "            f.close()\n",
    "        W=M.get_weights()\n",
    "        return W\n",
    "    \n",
    "def train_prior(alpha,total_epochs,x_train=[],y_train=[],x_target=[],y_target=[],save=True,Task=2,Binary=False):\n",
    "    TASK=Task\n",
    "    checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))\n",
    "    \n",
    "    if Binary:\n",
    "        M=init_MNIST_model_binary()\n",
    "        checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))#+\"/prior.ckpt\"\n",
    "    else:\n",
    "        M=init_MNIST_model()\n",
    "        \n",
    "    fast_cp_callback =fast_checkpoints(checkpoint_path,10)\n",
    "    if save:\n",
    "            CALLBACK=[fast_cp_callback]\n",
    "    else:\n",
    "            CALLBACK=[]\n",
    "            \n",
    "            \n",
    "    ## choose loss function, optimiser etc. and train\n",
    "    M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "    fit_info = M.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           callbacks=CALLBACK,\n",
    "           epochs=total_epochs,\n",
    "           verbose=1,\n",
    "                        )\n",
    "    #### save the final prior weights to disk\n",
    "    if save:\n",
    "        M.save_weights(checkpoint_path+\"/prior.ckpt\")\n",
    "    \n",
    " \n",
    "    \n",
    "    list1=[]\n",
    "    \n",
    "    dirFiles = os.listdir(checkpoint_path) #list of directory files\n",
    "    \n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non weights\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            if (name[0]==\"1\"):\n",
    "                list1.append(name)\n",
    "        \n",
    "    list1.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.append(\"prior\")    ## add the final weights which has no number\n",
    "    \n",
    "    Ws=list1\n",
    "    weight_updates=[]\n",
    "    for i in Ws:\n",
    "        if i[0]==\"1\":\n",
    "            if i[1]==\"_\":\n",
    "                weight_updates.append(int(i[2:]))\n",
    "    weight_updates.append(int(np.ceil(len(y_train)/batch_size)))\n",
    "    \n",
    "    error=[]\n",
    "    target_error=[]\n",
    "    for checkpoint in Ws:\n",
    "        if Binary:\n",
    "            model=init_MNIST_model_binary()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        else:\n",
    "            model=init_MNIST_model()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "            \n",
    "        model.load_weights(checkpoint_path+\"/\"+str(checkpoint)+\".ckpt\").expect_partial()\n",
    "        target_error.append(1-model.evaluate(x_target,y_target,verbose=0)[1])\n",
    "        error.append(1-model.evaluate(x_train,y_train,verbose=0)[1])\n",
    "    \n",
    "    if save:\n",
    "        results=pd.DataFrame({'Weightupdates': weight_updates,\n",
    "            'Trainerror': error,\n",
    "            'targeterror':target_error,\n",
    "            })\n",
    "        with open(path_to_root_file+'mnist_transfer/'+checkpoint_path+\"/results.pkl\",'wb') as f:\n",
    "            pickle.dump(results,f)\n",
    "        f.close()\n",
    "    \n",
    "    return model.get_weights()\n",
    "    \n",
    "def read_and_prepare_results(alpha,x_bound,y_bound,x_target,y_target,sigma,delta,N,epsilon,Binary=False,Task=TASK):\n",
    "    \n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    \n",
    "    ## read params.txt for the desired alpha and get the parameters\n",
    "    if Binary:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "    else:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "        \n",
    "    epsilon=float(params[1])\n",
    "    epochs_trained=int(params[2])\n",
    "    \n",
    "    # initialise model\n",
    "    if Binary:\n",
    "        M=init_MNIST_model_binary()\n",
    "    else:\n",
    "        M=init_MNIST_model()\n",
    "    M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "    ### load the prior weights if there are any\n",
    "    if alpha==0:\n",
    "        ### do nothing, i.e take the random init\n",
    "        w_a=M.get_weights()\n",
    "    else:\n",
    "        M.load_weights(prior_path).expect_partial()\n",
    "        w_a=M.get_weights()\n",
    "    \n",
    "    # read the weights and calculate what is needed for the bound\n",
    "    [KLs,errors,targeterrors,Ws,weight_updates]=read_weights(M,w_a,x_bound,y_bound,x_target,y_target,epochs_trained,sigma_tmp,epsilon,alpha,Binary=Binary,Task=TASK)    \n",
    "    \n",
    "    #print(KLs)\n",
    "    #print(errors)\n",
    "    #print(targeterrors)\n",
    "    #print(Ws)\n",
    "   \n",
    "    bound=[]\n",
    "    ### calculate the bound\n",
    "    for i in range(len(weight_updates)):\n",
    "        bound.append(calculate_bound(KLs[i],alpha,delta,N,errors[i]))\n",
    "    \n",
    "    \n",
    "    #save the results to a pickled dataframe in results\n",
    "    results=pd.DataFrame({'Weightupdates': weight_updates,\n",
    "        'Trainerror': errors,\n",
    "        'targeterror':targeterrors,\n",
    "        'KL': KLs,\n",
    "        'Bound': bound})\n",
    "    with open(path_to_root_file+'mnist_transfer/'+result_path+str(sigma_tmp[0])+str(sigma_tmp[1])+\"_results.pkl\",'wb') as f:#int(sigma*10**8)\n",
    "        pickle.dump(results,f)\n",
    "    f.close()\n",
    "    return results\n",
    "\n",
    "def plot_result_file(epsilon,alpha,sigma,Binary=False,Task=TASK):\n",
    "    import pandas as pd\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    \n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(\"Binary: \"+r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "    \n",
    "    ### do the plots\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"Bound\"],'r*-')\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"Trainerror\"],'m^-')\n",
    "    \n",
    "    plt.xlabel(\"Weight updates\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    \n",
    "    plt.legend([\"Bound\",\"Empirical error\"])\n",
    "    plt.show()\n",
    "\n",
    "def find_optimal_sigma(sigmas,epsilon, alpha,Binary=False,Task=TASK):\n",
    "    #### to find the optimal sigma just do a search through all the results \n",
    "    #### and save the one for each parameter which has the minimal bound\n",
    "    #### Do we do this per epoch or for some other value? The sigma which yields the lowest bound overall for some epoch?\n",
    "    optimal=[0,1]\n",
    "    # search through all epochs and pick the sigma which yields the smallest bound during the whole training process\n",
    "    for sigma in sigmas:\n",
    "        sigma_tmp=sigma\n",
    "        sigma=sigma[0]*10**(-1*sigma[1])\n",
    "        if Binary:\n",
    "            result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        else:\n",
    "            result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "        MIN=np.min(results[\"Bound\"])\n",
    "        if (MIN<optimal[1]):\n",
    "            optimal[1]=MIN\n",
    "            optimal[0]=sigma\n",
    "    print(\"The optimal sigma is {} with bound value {}\".format(optimal[0],optimal[1]))\n",
    "\n",
    "   \n",
    "#### find the optimal sigma for every combination of parameters\n",
    "\n",
    "#### use the optimal sigmas to calculate the bound 50 times(with different data orders and initialisation)\n",
    "#### (Note: also delta=13*delta_0) for every combination and save the mean and std for plotting into a result file\n",
    "#for i in range(50):\n",
    "    ## take in the data and split with a new seed\n",
    " #   x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source,test_size=alpha,random_state=(69105+i))\n",
    "#### \n",
    "def read_prior(alpha,TASK=2,Binary=True):\n",
    "    checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))\n",
    "    if Binary:\n",
    "        checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))\n",
    "    result_path=path_to_root_file+'mnist_transfer/'+checkpoint_path+\"/results.pkl\"\n",
    "    results=pd.read_pickle(result_path)\n",
    "    plt.title(r\"$\\alpha$=\"+str(alpha))\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"Trainerror\"],'m^-')\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"targeterror\"],'k^-')\n",
    "    plt.legend([\"Training error\",\"Target error\"])\n",
    "    \n",
    "def plot_prior_and_posterior(alpha,epsilon,sigma,TASK=2,Binary=True):\n",
    "    ### load in the prior data\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))\n",
    "    if Binary:\n",
    "        checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))\n",
    "    result_path=path_to_root_file+'mnist_transfer/'+checkpoint_path+\"/results.pkl\"\n",
    "    results=pd.read_pickle(result_path)\n",
    "    result_path_post=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    results2=pd.read_pickle(result_path_post+\"_results.pkl\")\n",
    "    \n",
    "    \n",
    "    ### remove/ignore the last entry of the prior data \n",
    "    ### as it should be a duplication of the first one from the posterior results\n",
    "    \n",
    "    ### training error\n",
    "    A=list(results2[\"Weightupdates\"]+list(results[\"Weightupdates\"])[-1])\n",
    "    B=list(results[\"Weightupdates\"])[:-1]\n",
    "    B.extend(A)\n",
    "    C=list(results[\"Trainerror\"])[:-1]\n",
    "    C.extend(list(results2[\"train_germain\"]))\n",
    "    plt.plot(B,C,'-m^')\n",
    "    \n",
    "    ## target error\n",
    "    D=list(results[\"targeterror\"])[:-1]\n",
    "    D.extend(list(results2[\"target_germain\"]))\n",
    "    plt.plot(B,D,'-k*')\n",
    "    \n",
    "    ### bound\n",
    "    E=results2[\"germain_bound\"]\n",
    "    plt.plot(A,E,'-D')\n",
    "    F=results2['boundpart3_germain']\n",
    "    plt.plot(A,F,'-o')\n",
    "    print(results2[\"target_germain\"])\n",
    "    print(results2[\"germain_bound\"])\n",
    "    ### lines for uninformative region and worse than random guessing; also for end of prior training\n",
    "    plt.axvline(A[0],color=\"grey\")\n",
    "    plt.axhline(y=0.5, color=\"black\", linestyle=\"--\")\n",
    "    plt.axhline(y=1, color=\"red\", linestyle=\"--\")\n",
    "    plt.legend([\"Training error\",\"Target error\",\"Bound\",\"KL-part\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "module5 = SourceFileLoader('plot', path_to_root_file+'mnist_transfer/results/plotting.py').load_module()\n",
    "from plot import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "#alpha=0.1\n",
    "delta=0.05 ## what would this be?   \n",
    "#sigma=0.01  \n",
    "\n",
    "alphas=[]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "length=10\n",
    "for i in range(length-1):\n",
    "    alphas.append((i+1)/length)\n",
    "\n",
    "epsilons=[0.03,0.01,0.001]\n",
    "#epsilons=[0.03]\n",
    "#epsilons=[0.01,0.001]\n",
    "### do hyperparameter sweep over sigma\n",
    "sigmas=[]\n",
    "#sigmas=[0.001,0.003,0.0001]\n",
    "#alphas=[0,0.1,0.5]#,0.6,0.7,0.8,0.9]\n",
    "#alphas=[0.3]\n",
    "\n",
    "for i in range(2,9):  \n",
    "    sigmas.append([3,i])#3*10**(-i))\n",
    "    if(i==8):\n",
    "        break\n",
    "    sigmas.append([1,i])#10**(-i))\n",
    "#alphas.append(0.3)\n",
    "#sigmas.append([3,2])\n",
    "alphas=[0]\n",
    "y_source_bin=make_mnist_binary(y_source)\n",
    "y_target_bin=make_mnist_binary(y_target)\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha is:\"+str(alpha))\n",
    "    #x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source_bin,test_size=alpha,random_state=69105)\n",
    "    #w_a=train_prior(alpha,1,x_source,y_source_bin,x_target=x_target,y_target=y_target_bin,save=True,Task=2,Binary=True)\n",
    "    #w_a=train_prior(alpha,1,x_prior,y_prior,x_target=x_target,y_target=y_target_bin,save=True,Task=2,Binary=True)\n",
    "    #read_prior(0.3,TASK=TASK,Binary=True)\n",
    "    #plot_result_file(0.03,alpha,[3,2],TASK,Binary=True)\n",
    "    #plot_prior_and_posterior(alpha,0.03,[3,3],TASK=TASK,Binary=True)\n",
    "    \n",
    "    for epsilon in epsilons:\n",
    "        w_s=train_posterior(alpha,x_source,y_source_bin,None,x_test=x_source,y_test=y_source_bin,epsilon=epsilon,Task=TASK,Binary=True)\n",
    "        #for sigma in sigmas:\n",
    "            #res=read_and_prepare_results(alpha,x_source,y_source_bin,x_target,y_target_bin,sigma,delta,len(x_source),epsilon,Binary=True)#x_bound,y_bound,x_target,y_target_bin,sigma,delta,len(x_bound),epsilon,Binary=True)\n",
    "            #plot_result_file(epsilon,alpha,sigma,TASK,Binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "mymodule2 = SourceFileLoader('DA', path_to_root_file+'mnist_transfer/experiments/DA_bound.py').load_module()\n",
    "from DA import *\n",
    "##### we want to compute the bound from Germain thm 7\n",
    "\n",
    "#### R_T  \\leq  omega' \\hat{R}_S+ a'/2 * dis_\\rho (S,T) +(omega'/omega +a'/a)*(KL(\\rho\\| \\pi )+\\ln(\\frac{3}{\\delta}))/m \n",
    "##### + \\lambda_\\rho + 1/2*(a'-1)\n",
    "\n",
    "\n",
    "#### a > 0 omega> 0, this can and probably should be optimised for the bound\n",
    "\n",
    "#### \\hat{R}_S is the empirical error on source, so just draw classifiers and calculate\n",
    "\n",
    "\n",
    "#### beta(T \\| S), domain divergence, this is more or less equal to average label density ratio or worst case depending on parameter q\n",
    "\n",
    "\n",
    " #### lambda_\\rho, difference in expected joint error |e_T-e_S| where e_S= E_h,h' E_x,y L(h(x),y)L(h'(x),y) \n",
    "    #### so draw two classifiers and calculate the mean of the product of losses on the domain   \n",
    "def read_weights_germain(model,w_a,x_bound,y_bound,x_target,y_target,epochs_trained,sigma,epsilon,alpha,Binary=False,Task=TASK):\n",
    "    import re\n",
    "    KLs=[]\n",
    "    e_s=[]\n",
    "    e_t=[]\n",
    "    d_tx=[]\n",
    "    d_sx=[]\n",
    "    epochs=[]\n",
    "    train_germain=[] \n",
    "    target_germain=[]\n",
    "    dis_rho=[]\n",
    "    lambda_rho=[]\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    \n",
    "    ### Here we do something more intelligent to not have to hardcode the epoch amounts. \n",
    "    ### we parse the filenames and sort them in numerical order and then load the weights\n",
    "    if Binary:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "    else:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    dirFiles = os.listdir(path) #list of directory files\n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non jpgs\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            ### if it has a one it goes in one list and if it starts with a two it goes in the other\n",
    "            if (name[0]==\"1\"):\n",
    "                list1.append(name)\n",
    "            elif (name[0]==\"2\"):\n",
    "                list2.append(name)\n",
    "            #epochs.append(name)\n",
    "    #epochs.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    num_batchweights=len(list1)\n",
    "    list2.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.extend(list2)\n",
    "    Ws=list1 ## vector of checkpoint filenames\n",
    "    #print(Ws)\n",
    "    #sys.exit(-1)\n",
    "    #epochs=[int(i) for i in Ws]\n",
    "    Xvector=[]\n",
    "    for i in Ws:\n",
    "        #print(i)\n",
    "        if i[0]==\"1\":\n",
    "            if i[1]==\"_\":\n",
    "                Xvector.append(int(i[2:]))\n",
    "    for i in list2:\n",
    "        Xvector.append((int(i[2:])+1)*547) ## TODO contant hack\n",
    "    print(Xvector)\n",
    "    #sys.exit(-1)\n",
    "    \"\"\"   \n",
    "    epochs = [] #list of checkpoint filenames\n",
    "    dirFiles = os.listdir(path) #list of directory files\n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non jpgs\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            epochs.append(name)\n",
    "    epochs.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    epochs=[int(i) for i in epochs]\n",
    "    \"\"\" \n",
    "    path=\"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"/\"#\"{epoch:0d}.ckpt\"\n",
    "    if Binary:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"/\"#\"{epoch:0d}.ckpt\"\n",
    "    \n",
    "    \n",
    "    L=len(Xvector)\n",
    "     ### vectors for saving std of each point\n",
    "    error_std=[]\n",
    "    target_error_std=[]\n",
    "    e_s_std=[]\n",
    "    e_t_std=[]\n",
    "    d_tx_std=[]\n",
    "    d_sx_std=[]\n",
    "    for checkpoint in Ws:\n",
    "        if Binary:\n",
    "            model=init_MNIST_model_binary()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        else:\n",
    "            model=init_MNIST_model()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "\n",
    "        model.load_weights(path+str(checkpoint)+\".ckpt\").expect_partial()\n",
    "        w_s=model.get_weights()\n",
    "        \"\"\"\n",
    "        ############################# test\n",
    "        #print(x_target[1])\n",
    "        pred = model.predict(x_target)\n",
    "        print(make_01(pred))\n",
    "        indices = [i for i,v in enumerate(pred) if np.sum(pred[i]-y_target[i])==0]\n",
    "        print(indices)\n",
    "        sys.exit(-1)\n",
    "        \"\"\"\n",
    "        ##### here we should draw classifiers and pass that on\n",
    "        CLASSIFIERS=4\n",
    "        t = time.time()\n",
    "        ## do X draws of the posterior, for two separate classifiers\n",
    "        w_s_draws=draw_classifier(w_s,sigma,num_classifiers=CLASSIFIERS)\n",
    "        w_s_draws2=draw_classifier(w_s,sigma,num_classifiers=CLASSIFIERS)\n",
    "        ## do X draws of the prior\n",
    "        #w_a_draws=draw_classifier(w_a,sigma,num_classifiers=2)\n",
    "          \n",
    "        elapsed = time.time() - t\n",
    "        print(\"Time spent drawing the classifiers: \"+str(elapsed)+\"\\n\")\n",
    "   \n",
    "        \n",
    "        ###### for each pair of drawn prior and posterior we calculate the necessary parts of the bound \n",
    "        ###### and then average the result and return that\n",
    "        \n",
    "        \n",
    "\n",
    "        errorsum=[]\n",
    "        target_errorsum=[]\n",
    "       \n",
    "        ######## in here we should make the results save in a vector for each part to be able to calculate\n",
    "        ######## the standard deviation and be able to get error bars on things.\n",
    "        t = time.time()\n",
    "        for h in w_s_draws:\n",
    "            model.set_weights(h)\n",
    "            errorsum.append((1-model.evaluate(x_bound,y_bound,verbose=0)[1]))\n",
    "            target_errorsum.append((1-model.evaluate(x_target,y_target,verbose=0)[1]))\n",
    "        \n",
    "        \n",
    "        for hprime in w_s_draws2:\n",
    "            model.set_weights(hprime)\n",
    "            errorsum.append((1-model.evaluate(x_bound,y_bound,verbose=0)[1]))\n",
    "            target_errorsum.append((1-model.evaluate(x_target,y_target,verbose=0)[1]))\n",
    "     \n",
    "        \n",
    "        train_germain.append((np.mean(errorsum))) #/(len(w_s_draws)+len(w_s_draws2))\n",
    "        target_germain.append(np.mean(target_errorsum))  #/(len(w_s_draws)+len(w_s_draws2))\n",
    "        error_std.append(np.std(errorsum))\n",
    "        target_error_std.append(np.std(target_errorsum))\n",
    "        elapsed = time.time() - t\n",
    "        print(\"Time spent calculating errors: \"+str(elapsed)+\"\\n\")\n",
    "        \n",
    "        ######## in here we should make the results save in a vector for each part to be able to calculate\n",
    "        ######## the standard deviation and be able to get error bars on things.\n",
    "        \n",
    "        #### loop over pairs of classifiers from posterior for the disagreement and joint error\n",
    "        #q=0\n",
    "        e_ssum=[]\n",
    "        e_tsum=[]\n",
    "        d_txsum=[]\n",
    "        d_sxsum=[]\n",
    "        d_tx_h=0\n",
    "        d_sx_h=0\n",
    "        d_tx_hprime=0\n",
    "        d_sx_hprime=0\n",
    "       \n",
    "        t = time.time()\n",
    "        \n",
    "        #### Here we should just do the four pairs so there is no cross-usage here\n",
    "        #### this can be not good for the independence of the values which makes the CI useless\n",
    "        \n",
    "        for i, h in enumerate(w_s_draws):\n",
    "            model.set_weights(h)\n",
    "            d_tx_h=model.predict(x_target,verbose=0)\n",
    "            d_sx_h=model.predict(x_bound,verbose=0)\n",
    "            d_sx_h=make_01(d_sx_h)\n",
    "            d_tx_h=make_01(d_tx_h)\n",
    "            #for hprime in w_s_draws2:\n",
    "            hprime=w_s_draws2[i]\n",
    "            model.set_weights(hprime)\n",
    "            d_tx_hprime=model.predict(x_target,verbose=0)\n",
    "            d_sx_hprime=model.predict(x_bound,verbose=0)\n",
    "            d_sx_hprime=make_01(d_sx_hprime)\n",
    "            d_tx_hprime=make_01(d_tx_hprime)\n",
    "                \n",
    "            e_ssum.append(joint_error(d_sx_h,d_sx_hprime,y_bound))\n",
    "            d_sxsum=(classifier_disagreement(d_sx_h,d_sx_hprime))\n",
    "            e_tsum=(joint_error(d_tx_h,d_tx_hprime,y_target))\n",
    "            d_txsum=(classifier_disagreement(d_tx_h,d_tx_hprime))\n",
    "        \n",
    "        e_s.append(np.mean(e_ssum))\n",
    "        d_sx.append(np.mean(d_sxsum))\n",
    "        e_t.append(np.mean(e_tsum))\n",
    "        d_tx.append(np.mean(d_txsum))\n",
    "        ### save the std\n",
    "        e_s_std.append(np.std(e_ssum))\n",
    "        d_sx_std.append(np.std(d_sxsum))\n",
    "        e_t_std.append(np.std(e_tsum))\n",
    "        d_tx_std.append(np.std(d_txsum))\n",
    "        elapsed = time.time() - t\n",
    "        print(\"Time spent calculating joint errors and disagreements: \"+str(elapsed)+\"\\n\")    \n",
    "        \n",
    "        KLsum=0\n",
    "        t = time.time()\n",
    "        \n",
    "        KLsum=estimate_KL(w_a,w_s,sigma)## compute the KL\n",
    "        ## only w_s, w_a here\n",
    "                \n",
    "      \n",
    "        KLs.append(KLsum)\n",
    "        elapsed = time.time() - t\n",
    "        print(\"Time spent calculating KL: \"+str(elapsed)+\"\\n\") \n",
    "        \n",
    "        ### memory leak city\n",
    "        del model\n",
    "        _=gc.collect()\n",
    "        \n",
    "        \n",
    "     \n",
    "    print(\"Finished calculation of bound parts\")\n",
    "   \n",
    "          #### load the result file if it exists otherwise make one\n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    if(os.path.exists(result_path+\"_results.pkl\")):\n",
    "        results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "    else:\n",
    "        results=pd.DataFrame({'Weightupdates': Xvector,\n",
    "        'train_germain': train_germain,\n",
    "        'target_germain':target_germain,\n",
    "        'KL': KLs})\n",
    "        with open(path_to_root_file+'mnist_transfer/'+result_path+\"_results.pkl\",'wb') as f:\n",
    "            pickle.dump(results,f)\n",
    "        f.close()\n",
    "        results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "\n",
    "    train_germain=np.array(train_germain)\n",
    "    results['Weightupdates']=Xvector\n",
    "    results['train_germain']=train_germain\n",
    "    results['target_germain']=target_germain\n",
    "    results['e_s']=e_s\n",
    "    results['e_t']=e_t\n",
    "    results['d_tx']=d_tx\n",
    "    results['d_sx']=d_sx\n",
    "    results['KL']=KLs\n",
    "    ### save the std deviations as well in some form like a vector of deviations for each factor\n",
    "    results['error_std']=error_std\n",
    "    results['target_error_std']=target_error_std\n",
    "    results['e_s_std']=e_s_std\n",
    "    results['e_t_std']=e_t_std\n",
    "    results['d_tx_std']=d_tx_std\n",
    "    results['d_sx_std']=d_sx_std\n",
    "    KL=KLs\n",
    "    \n",
    "    m=len(y_bound)\n",
    "    delta=0.05 ## hardcoded value\n",
    "     # calculate disrho bound\n",
    "    [res,bestparam, boundparts]=grid_search(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,m,L)\n",
    "    # calculate beta bound\n",
    "    [res2,bestparam2, boundparts2]=grid_search(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,m,L,beta_bound=True)            \n",
    "                \n",
    "                \n",
    "                \n",
    "    results['germain_bound']=res\n",
    "    print(\"Germain bound\"+str(res))\n",
    "    print(\"[a, omega]= \"+str(bestparam))\n",
    "    Best=np.zeros([len(res),1])\n",
    "    Best[0]=bestparam[0]\n",
    "    Best[1]=bestparam[1]\n",
    "    Best[2]=CLASSIFIERS\n",
    "    #print(Best)\n",
    "    results['bestparam']=Best\n",
    "    results['boundpart1_germain']=boundparts[0]\n",
    "    results['boundpart2_germain']=boundparts[1]\n",
    "    results['boundpart3_germain']=boundparts[2]\n",
    "    results['boundpart4_germain']=boundparts[3]\n",
    "    results['boundpart5_germain']=boundparts[4]\n",
    "    ## beta bound\n",
    "    results['beta_bound']=res2\n",
    "    results['beta_boundpart1']=boundparts2[0]\n",
    "    results['beta_boundpart2']=boundparts2[1]\n",
    "    results['beta_boundpart3']=boundparts2[2]\n",
    "    with open(path_to_root_file+'mnist_transfer/'+result_path+\"_results.pkl\",'wb') as f:\n",
    "        pickle.dump(results,f)\n",
    "    f.close()\n",
    "    return results\n",
    "\n",
    "def grid_search(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,m,L,beta_bound=False):\n",
    "    #### here we want to do a coarse grid search over a and omega to get the smallest bound \n",
    "    print(\"Starting gridsearch....\")\n",
    "    avec=[0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000,50000,100000]\n",
    "    omegas=[0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000,50000,100000]\n",
    "    tmp= sys.maxsize\n",
    "    res=[]\n",
    "    bestparam=[0,0]\n",
    "    for a in avec:\n",
    "        for omega in omegas:\n",
    "            if beta_bound:\n",
    "                germain_bound, boundparts=calculate_beta_bound(e_s,d_tx,KL,delta,a,omega,m,L)\n",
    "            else:\n",
    "                germain_bound,boundparts=calculate_germain_bound(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,a,omega,m,L)\n",
    "            if min(germain_bound)<tmp:\n",
    "                tmp=min(germain_bound)\n",
    "                #print(\"Best bound thus far:\"+str(tmp))\n",
    "                res=germain_bound\n",
    "                bestparam=[a,omega]\n",
    "                \n",
    "    ### do a finer sweep around the best parameters\n",
    "    if bestparam[0]!=0:\n",
    "        avec=np.arange(bestparam[0]-bestparam[0]/2,bestparam[0]+bestparam[0]*4,0.1*bestparam[0])\n",
    "    else:## no bound better than the max int was found, if that is even possible\n",
    "        avec=np.arange(-1,1,0.1)\n",
    "    if bestparam[1]!=0:\n",
    "        omegas=np.arange(bestparam[1]-bestparam[1]/2,bestparam[1]+bestparam[1]*4,0.1*bestparam[1])\n",
    "    else:## no bound better than the max int was found\n",
    "        avec=np.arange(-1,1,0.1)\n",
    "    boundparts=[0, 0,0,0,0]\n",
    "    for a in avec:\n",
    "        for omega in omegas:\n",
    "            if beta_bound:\n",
    "                germain_bound, boundparts=calculate_beta_bound(e_s,d_tx,KL,delta,a,omega,m,L)\n",
    "            else:\n",
    "                germain_bound,boundparts=calculate_germain_bound(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,a,omega,m,L)\n",
    "            if min(germain_bound)<tmp:\n",
    "                tmp=min(germain_bound)\n",
    "                #print(\"Best finer bound thus far:\"+str(tmp))\n",
    "                res=germain_bound\n",
    "                bestparam=[a,omega]\n",
    "                #boundparts=[a1,a2,a3,a4,a5]\n",
    "    return [res,bestparam, boundparts]\n",
    "def calculate_beta_bound(e_s,d_tx,KL,delta,b,c,m,L,BETA=0):\n",
    "    BETA=10.986111 ### hardcoded value for beta_infinity for TASK2 TODO!\n",
    "    m_s=m  ## temporary, we should pass these in\n",
    "    m_t=m  ## temporary, we should pass these in\n",
    "    bprime=b/(1-np.exp(-b))\n",
    "    cprime=c/(1-np.exp(-c))\n",
    "    \n",
    "    bound=[]\n",
    "    a1=np.zeros(L)\n",
    "    a2=np.zeros(L)\n",
    "    a3=np.zeros(L)\n",
    "    for i in range(L):\n",
    "        a1[i]=cprime/2*(d_tx[i])\n",
    "        a2[i]=bprime*e_s[i]\n",
    "        a3[i]=(cprime/(m_t*c)+bprime*BETA/(m_s*b))*(2*KL[i]+np.log(2/delta))\n",
    "    ## we cannot evaluate the eta term in the bound so this is it. For TASK 2 it is 0 anyway.\n",
    "    ## And for other tasks we will not evaluate this bound anyway as we probably have no way of doing so easily..\n",
    "        bound.append(a1[i]+a2[i]+a3[i])\n",
    "    boundparts=[a1,a2,a3]\n",
    "    return bound, boundparts\n",
    "def germain_bound(x_bound,y_bound,x_target,y_target,alpha,sigma,epsilon,task,Binary=False):\n",
    "    TASK=task\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "        ## read params.txt for the desired alpha and get the parameters\n",
    " \n",
    "    if Binary:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "    else:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "\n",
    "    epsilon=float(params[1])\n",
    "    epochs_trained=int(params[2])\n",
    "    if Binary:\n",
    "        M=init_MNIST_model_binary()\n",
    "    else:\n",
    "        M=init_MNIST_model()\n",
    "                \n",
    "    M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "      ### load the prior weights if there are any\n",
    "    if(Binary and alpha != 0):\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "    elif(alpha != 0):\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "    if alpha==0:\n",
    "        ### do nothing, just take the random initialisation\n",
    "        w_a=M.get_weights()\n",
    "    else:\n",
    "        M.load_weights(prior_path).expect_partial()\n",
    "        w_a=M.get_weights()\n",
    "    \n",
    " \n",
    "    ## get the prior weights for the KL and pass into read_weights\n",
    "    results=read_weights_germain(M,w_a,x_bound,y_bound,x_target,y_target,epochs_trained,sigma_tmp,epsilon,alpha,Binary=Binary,Task=TASK)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split\n",
    "\n",
    "delta=0.05\n",
    "Binary=True\n",
    "\n",
    "epsilons=[0.03]#,0.01]#,0.001]#,0.01,0.001]\n",
    "#epsilons=[0.01,0.001]\n",
    "#sigmas=[0.003]\n",
    "#sigmas=[0.00001,0.0003,0.000001,0.00003]\n",
    "alphas=[0,0.3]#,0.5]#,0.3]#,0.3]#0.3,0.4,0.6]\n",
    "#alphas=[0]\n",
    "sigmas=[[3,2],[3,3]]#,[3,3],[1,6]]\n",
    "'''\n",
    "for i in range(2,9):  \n",
    "    sigmas.append([3,i])#3*10**(-i))\n",
    "    if(i==8):\n",
    "        break\n",
    "    sigmas.append([1,i])#10**(-i))\n",
    "'''\n",
    "#errors=[428, 468, 1247, 1256, 2235, 2348, 2539, 2723, 2797, 3058, 3075, 3717, 3902, 3998, 4210, 4703, 4714, 4801, 5086, 5090, 5276, 5323, 5335, 5392, 5559, 5779, 6082, 6304, 6308, 6351, 6354, 6363, 6388, 6510, 6584, 6615, 6624, 6632, 6703, 6766, 6838, 6839, 6926, 7061, 7089, 7224, 7331, 7334, 7338, 7369, 7429, 7627, 7726, 7731, 7764, 7847, 7872, 7954, 8122, 8259, 8290, 8307, 8547, 8577, 8803, 8842, 8846, 8860, 8972, 9201, 9303, 9427, 9566, 9570, 9642, 9723, 9917, 10272, 10316, 10609, 10621, 10715, 10735, 10751, 10878, 10897, 11006, 11203, 11206, 11256, 11267, 11362, 11372, 11450, 11544, 11632, 11701, 12033, 12135, 12141, 12874, 13101, 13194, 13380, 14147, 14501, 14683, 15246, 15297, 15569, 15589, 15604, 15632, 15659, 15750, 15926, 16045, 16224, 16237, 16246, 16291, 16341, 16426, 16520, 16525, 16549, 16554, 16686, 16763, 16780, 16792, 16803, 16814, 16820, 16891, 16907, 16912, 17015, 17048, 17053, 17183, 17216, 17230, 17272, 17286, 17310, 17418, 17432, 17441, 17663, 17875, 17881, 17904, 17941, 17971, 18031, 18230, 18270, 18339, 18370, 18440, 18471, 18547, 18643, 18660, 18694, 18708, 18777, 18805, 18811, 18818, 18963, 19082, 19101, 19114, 19124, 19194, 19248, 19319, 19357, 19369, 19383, 19464, 19510, 19521, 19554, 19582, 19694, 19841, 19845, 19905, 19935, 19974, 19998, 20002, 20268, 20276, 20302, 20339, 20343, 20386, 20395, 20454, 20473, 20595, 20814, 20817, 20858, 21059, 21445, 21449, 21516, 21518, 21527, 21557, 21559, 21566, 21614, 21645, 21801, 21826, 21868, 21883, 21941, 21947, 22002, 22008, 22160, 22167, 22179, 22274, 22411, 22452, 22536, 22649, 22650, 22662, 22672, 22700, 22704, 22718, 22839, 22872, 22883, 22892, 23001, 23035, 23152, 23162, 23169, 23210, 23227, 23259, 23277, 23418, 23578, 23584, 23688, 23741, 23760, 23777, 23790, 23829, 23957, 24056, 24059, 24089, 24150, 24157, 24182, 24295, 24339, 24387, 24429, 24695, 24753, 24873, 24907, 24943, 25004, 25036, 25084, 25287, 25316, 25317, 25329, 25376, 25412, 25492, 25544, 25612, 25618, 25636, 25854, 26071, 26084, 26151, 26177, 26479, 26493, 26523, 26539, 26641, 26667, 26713, 26737, 27030, 27222, 27239, 27326, 27429, 27502, 27511, 27548, 27567, 27675, 27817, 27832, 27890, 27932, 27947, 28193, 28341, 28364, 28377, 28411, 28453, 28528, 28564, 28885, 28896, 28912, 28943, 28991, 29029, 29119, 29185, 29225, 29233, 29289, 29339, 29468, 29551, 29561, 29584, 29623, 29705, 29740, 29749, 29887, 29893, 29897, 29924, 30014, 30048, 30193, 30194, 30228, 30354, 30390, 30403, 30450, 30494, 30647, 30655, 30697, 30757, 31068, 31078, 31126, 31152, 31160, 31161, 31190, 31255, 31273, 31325, 31373, 31389, 31731, 31803, 31824, 31827, 31829, 31837, 31841, 31845, 31850, 31865, 31868, 31893, 31921, 31939, 31950, 31957, 31977, 31985, 32008, 32010, 32019, 32023, 32045, 32054, 32071, 32075, 32083, 32087, 32097, 32101, 32111, 32112, 32143, 32152, 32161, 32176, 32216, 32226, 32229, 32241, 32245, 32249, 32251, 32252, 32267, 32281, 32286, 32305, 32306, 32311, 32321, 32337, 32346, 32348, 32358, 32370, 32391, 32396, 32417, 32419, 32443, 32446, 32478, 32480, 32486, 32488, 32491, 32500, 32526, 32527, 32529, 32530, 32555, 32572, 32587, 32591, 32595, 32597, 32612, 32617, 32646, 32650, 32652, 32658, 32667, 32687, 32692, 32702, 32703, 32710, 32728, 32729, 32751, 32752, 32770, 32789, 32804, 32805, 32814, 32817, 32826, 32834, 32842, 32849, 32856, 32859, 32862, 32874, 32878, 32886, 32890, 32897, 32922, 32929, 32946, 32959, 32974, 32993, 33005, 33015, 33017, 33027, 33040, 33043, 33088, 33101, 33115, 33117, 33127, 33145, 33150, 33154, 33156, 33159, 33162, 33193, 33206, 33214, 33221, 33230, 33234, 33260, 33261, 33266, 33310, 33322, 33356, 33363, 33364, 33367, 33377, 33390, 33404, 33407, 33410, 33412, 33431, 33437, 33438, 33441, 33447, 33452, 33463, 33477, 33480, 33553, 33573, 33578, 33592, 33603, 33634, 33639, 33640, 33650, 33668, 33673, 33678, 33700, 33717, 33733, 33766, 33781, 33784, 33802, 33834, 33835, 33842, 33844, 33850, 33861, 33868, 33904, 33919, 33925, 33930, 33931, 33968, 33995, 34006, 34012, 34014, 34026, 34030, 34031, 34037, 34039, 34087, 34094, 34101, 34120, 34153, 34163, 34185, 34200, 34217, 34220, 34237, 34239, 34263, 34265, 34271, 34295, 34297, 34298, 34300, 34301, 34302, 34311, 34315, 34318, 34324, 34346, 34351, 34359, 34376, 34378, 34384, 34400, 34436, 34447, 34459, 34482, 34493, 34494, 34500, 34525, 34543, 34555, 34584, 34585, 34588, 34598, 34599, 34602, 34610, 34655, 34666, 34673, 34678, 34683, 34687, 34699, 34705, 34706, 34712, 34713, 34714, 34724, 34728, 34729, 34732, 34738, 34747, 34752, 34756, 34773, 34789, 34795, 34806, 34807, 34808, 34815, 34823, 34840, 34850, 34865, 34872, 34881, 34884, 34916, 34935, 34946, 34963, 35021, 35039, 35041, 35043, 35046, 35048, 35049, 35086, 35094, 35108, 35110, 35118, 35122, 35124, 35125, 35158, 35179, 35196, 35210, 35214, 35225, 35233, 35253, 35260, 35277, 35278, 35279, 35318, 35325, 35339, 35341, 35343, 35347, 35358, 35365, 35371, 35373, 35374, 35377, 35383, 35419, 35430, 35435, 35445, 35452, 35491, 35495, 35503, 35533, 35550, 35557, 35559, 35565, 35578, 35580, 35590, 35597, 35606, 35619, 35633, 35634, 35639, 35642, 35660, 35662, 35663, 35673, 35691, 35702, 35708, 35709, 35718, 35761, 35775, 35776, 35777, 35792, 35809, 35866, 35892, 35910, 35912, 35928, 35951, 35954, 35966, 35998, 36001, 36002, 36008, 36018, 36020, 36031, 36038, 36049, 36053, 36055, 36088, 36095, 36108, 36123, 36162, 36165, 36170, 36178, 36228, 36229, 36235, 36236, 36257, 36260, 36261, 36268, 36285, 36286, 36289, 36304, 36306, 36307, 36313, 36321, 36323, 36340, 36349, 36357, 36360, 36361, 36362, 36364, 36369, 36392, 36414, 36419, 36434, 36435, 36438, 36442, 36443, 36451, 36470, 36477, 36479, 36480, 36486, 36501, 36518, 36532, 36538, 36539, 36544, 36571, 36577, 36579, 36588, 36590, 36620, 36628, 36629, 36645, 36659, 36660, 36686, 36703, 36715, 36719, 36734, 36736, 36737, 36761, 36771, 36781, 36824, 36826, 36832, 36844, 36848, 36917, 36937, 36942, 36945, 36951, 36977, 37020, 37031, 37040, 37041, 37046, 37061, 37071, 37111, 37112, 37125, 37163, 37171, 37207, 37223, 37228, 37240, 37246, 37251, 37252, 37265, 37271, 37277, 37281, 37295, 37296, 37314, 37315, 37346, 37350, 37377, 37380, 37390, 37391, 37403, 37423, 37428, 37432, 37438, 37443, 37452, 37453, 37457, 37466, 37495, 37535, 37539, 37579, 37612, 37623, 37625, 37654, 37657, 37675, 37676, 37699, 37708, 37711, 37729, 37736, 37787, 37797, 37805, 37832, 37836, 37856, 37865, 37870, 37875, 37880, 37889, 37905, 37939, 37951, 37953, 37966, 37967, 37971, 37985, 38038, 38043, 38066, 38081, 38101, 38113, 38118, 38136, 38138, 38145, 38151, 38181, 38236, 38253, 38257, 38263, 38293, 38327, 38332, 38337, 38340, 38357, 38385, 38409, 38413, 38416, 38452, 38455, 38471, 38507, 38516, 38521, 38532, 38536, 38545, 38548, 38550, 38554, 38562, 38571, 38584, 38585, 38590, 38593, 38603, 38609, 38611, 38632, 38653, 38671, 38692, 38694, 38753, 38756, 38775, 38777, 38778, 38813, 38820, 38854, 38858, 38860, 38879, 38881, 38889, 38893, 38928, 38930, 38983, 38988, 39054, 39084, 39103, 39108, 39126, 39129, 39139, 39167, 39190, 39231, 39257, 39277, 39284, 39318, 39328, 39344, 39350, 39401, 39440, 39447, 39464, 39485, 39489, 39515, 39528, 39535, 39549, 39550, 39566, 39600, 39602, 39604, 39635, 39639, 39643, 39657, 39662, 39717, 39726, 39747, 39776, 39777, 39778, 39781, 39826, 39828, 39830, 39842, 39843, 39848, 39861, 39866, 39894, 39902, 39905, 39912, 39955, 39962, 39978, 39985, 39986, 39994, 40013, 40053, 40072, 40112, 40115, 40138, 40173, 40188, 40195, 40209, 40214, 40218, 40224, 40229, 40241, 40256, 40288, 40300, 40315, 40329, 40349, 40355, 40358, 40393, 40423, 40442, 40458, 40463, 40465, 40469, 40482, 40510, 40515, 40520, 40529, 40530, 40541, 40577, 40584, 40591, 40595, 40607, 40656, 40668, 40685, 40687, 40692, 40693, 40699, 40729, 40739, 40747, 40800, 40838, 40898, 40904, 40922, 40933, 40938, 40941, 40942, 40968, 40991, 41002, 41010, 41030, 41040, 41074, 41176, 41187, 41193, 41204, 41217, 41233, 41236, 41249, 41300, 41322, 41331, 41337, 41340, 41343, 41379, 41383, 41445, 41483, 41490, 41517, 41536, 41547, 41569, 41573, 41575, 41580, 41583, 41596, 41612, 41613, 41619, 41624, 41651, 41656, 41661, 41663, 41664, 41696, 41697, 41704, 41712, 41714, 41726, 41730, 41735, 41745, 41747, 41754, 41756, 41758, 41766, 41767, 41792, 41801, 41805, 41816, 41821, 41834, 41848, 41856, 41876, 41879, 41908, 41927, 41957, 41973, 42017, 42038, 42047, 42049, 42061, 42089, 42096, 42099, 42117, 42123, 42133, 42140, 42157, 42177, 42179, 42182, 42199, 42201, 42255, 42274, 42292, 42314, 42316, 42317, 42319, 42327, 42347, 42348, 42353, 42410, 42426, 42443, 42453, 42501, 42504, 42508, 42520, 42531, 42556, 42561, 42565, 42575, 42605, 42623, 42634, 42636, 42641, 42661, 42663, 42690, 42731, 42742, 42744, 42751, 42755, 42767, 42772, 42804, 42806, 42809, 42814, 42898, 42924, 42928, 42942, 42948, 42966, 43008, 43021, 43081, 43083, 43103, 43106, 43142, 43160, 43191, 43212, 43233, 43243, 43248, 43278, 43296, 43341, 43350, 43364, 43382, 43384, 43403, 43427, 43457, 43477, 43488, 43494, 43508, 43515, 43583, 43593, 43598, 43608, 43611, 43635, 43676, 43677, 43694, 43722, 43775, 43777, 43779, 43787, 43793, 43801, 43802, 43822, 43827, 43829, 43833, 43858, 43859, 43873, 43874, 43880, 43896, 43897, 43931, 43950, 43961, 43965, 43977, 43990, 44025, 44066, 44115, 44126, 44174, 44198, 44269, 44304, 44305, 44321, 44326, 44342, 44364, 44377, 44436, 44471, 44486, 44489, 44491, 44505, 44543, 44554, 44566, 44577, 44584, 44600, 44602, 44640, 44650, 44656, 44662, 44673, 44710, 44736, 44743, 44759, 44773, 44816, 44859, 44905, 44910, 44932, 44974, 44997, 45015, 45057, 45076, 45100, 45106, 45134, 45159, 45193, 45215, 45232, 45259, 45277, 45338, 45457, 45496, 45497, 45560, 45590, 45607, 45608, 45614, 45631, 45656, 45683, 45709, 45732, 45736, 45740, 45754, 45818, 45925, 45935, 45948, 45955, 45986, 45998, 46017, 46036, 46065, 46079, 46103, 46110, 46165, 46230, 46266, 46292, 46294, 46301, 46307, 46315, 46321, 46382, 46386, 46394, 46417, 46443, 46485, 46517, 46564, 46600, 46628, 46644, 46651, 46673, 46684, 46737, 46776, 46785, 46855, 46942, 47040, 47084, 47162, 47232, 47237, 47286, 47292, 47346, 47355, 47396, 47458, 47482, 47491, 47579, 47597, 47602, 47682, 47703, 47741, 47823, 47835, 47839, 47840, 47894, 47928, 47964, 47966, 47977, 48004, 48029, 48075, 48090, 48101, 48108, 48141, 48144, 48157, 48159, 48166, 48176, 48212, 48222, 48256, 48264, 48322, 48329, 48341, 48344, 48346, 48349, 48377, 48380, 48384, 48416, 48460, 48470, 48491, 48502, 48512, 48521, 48528, 48539, 48558, 48582, 48599, 48618, 48624, 48631, 48664, 48729, 48800, 48810, 48835, 48897, 48907, 48921, 48922, 48960, 48982, 49003, 49019, 49032, 49050, 49063, 49077, 49167, 49205, 49211, 49238, 49259, 49267, 49270, 49272, 49310, 49328, 49415, 49430, 49443, 49524, 49558, 49605, 49712, 49747, 49753, 49797, 49884, 49897, 49916, 49940, 49966, 49973, 49974, 49981, 50002, 50005, 50015, 50096, 50098, 50115, 50126, 50158, 50208, 50218, 50227, 50244, 50247, 50265, 50296, 50331, 50333, 50336, 50353, 50367, 50370, 50371, 50388, 50421, 50450, 50463, 50473, 50494, 50517, 50525, 50539, 50547, 50548, 50581, 50669, 50672, 50708, 50730, 50763, 50821, 50832, 50856, 50876, 50907, 50913, 50919, 50953, 50961, 50969, 51025, 51033, 51041, 51047, 51096, 51104, 51118, 51178, 51179, 51207, 51218, 51224, 51251, 51271, 51278, 51298, 51300, 51327, 51337, 51339, 51343, 51391, 51394, 51396, 51404, 51405, 51416, 51465, 51470, 51471, 51481, 51544, 51564, 51577, 51594, 51602, 51638, 51646, 51688, 51695, 51712, 51739, 51745, 51832, 51842, 51907, 51911, 51919, 51935, 51944, 51951, 51967, 51972, 51975, 52020, 52026, 52041, 52043, 52045, 52060, 52088, 52098, 52100, 52130, 52138, 52151, 52198, 52279, 52280, 52318, 52340, 52343, 52353, 52356, 52375, 52382, 52389, 52457, 52459, 52486, 52492, 52495, 52497, 52583, 52619, 52758, 52759, 52777, 52784, 52786, 52819, 52843, 52860, 52861, 52911, 52914, 52919, 52922, 52930, 52942, 52943, 52958, 52995, 53006, 53025, 53034, 53044, 53055, 53076, 53082, 53088, 53095, 53107, 53109, 53120, 53128, 53135, 53143, 53144, 53189, 53192, 53204, 53212, 53215, 53216, 53230, 53234, 53241, 53343, 53363, 53398, 53399, 53440, 53443, 53454, 53513, 53568, 53593, 53608, 53618, 53629, 53649, 53679, 53690, 53716, 53720, 53769, 53784, 53786, 53787, 53805, 53818, 53862, 53888, 53908, 53923, 53961, 54013, 54028, 54035, 54036, 54109, 54287, 54335, 54340, 54386, 54387, 54409, 54419, 54431, 54447, 54469, 54581, 54586, 54611, 54677, 54682, 54727, 54756, 54782, 54809, 54818, 54820, 54890, 54903, 54904, 54907, 54914, 54920, 54930, 54960, 54977, 54991, 54992, 54994, 54997, 55026, 55048, 55060, 55087, 55099, 55101, 55102, 55117, 55137, 55146, 55164, 55170, 55175, 55181, 55204, 55207, 55209, 55222, 55238, 55256, 55268, 55278, 55283, 55302, 55303, 55328, 55337, 55360, 55366, 55381, 55385, 55387, 55408, 55433, 55435, 55441, 55465, 55466, 55480, 55486, 55491, 55496, 55521, 55526, 55535, 55537, 55538, 55560, 55570, 55574, 55619, 55622, 55625, 55654, 55657, 55670, 55691, 55693, 55702, 55721, 55722, 55736, 55743, 55762, 55788, 55821, 55851, 55854, 55865, 55869, 55887, 55895, 55921, 55953, 55964, 55968, 55976, 55977, 55981, 55985, 55986, 56005, 56016, 56023, 56040, 56042, 56055, 56072, 56081, 56086, 56100, 56110, 56140, 56150, 56201, 56215, 56221, 56234, 56241, 56249, 56262, 56266, 56267, 56272, 56293, 56312, 56313, 56353, 56361, 56382, 56396, 56398, 56403, 56433, 56436, 56465, 56468, 56491, 56503, 56522, 56543, 56548, 56549, 56555, 56559, 56571, 56584, 56590, 56618, 56627, 56649, 56661, 56692, 56740, 56746, 56747, 56749, 56762, 56776, 56797, 56809, 56810, 56823, 56827, 56833, 56834, 56840, 56849, 56851, 56858, 56861, 56864, 56894, 56905, 56907, 56918, 56929, 56931, 56961, 56974, 56977, 56985, 56996, 57015, 57028, 57125, 57167, 57179, 57191, 57211, 57214, 57253, 57255, 57259, 57281, 57296, 57303, 57314, 57330, 57351, 57384, 57390, 57402, 57418, 57432, 57479, 57494, 57508, 57536, 57554, 57585, 57587, 57594, 57623, 57629, 57632, 57652, 57661, 57663, 57673, 57675, 57680, 57692, 57704, 57742, 57745, 57759, 57760, 57764, 57765, 57774, 57801, 57821, 57827, 57860, 57872, 57885, 57895, 57927, 57943, 57964, 57965, 57977, 57984, 57997, 58038, 58100, 58117, 58156, 58196, 58203, 58208, 58219, 58233, 58236, 58237, 58240, 58246, 58248, 58253, 58296, 58331, 58345, 58354, 58380, 58390, 58401, 58402, 58405, 58407, 58466, 58576, 58588, 58603, 58656, 58705, 58717, 58725, 58758, 58789, 58800, 58809, 58832, 58833, 58845, 58990, 59009, 59017, 59018, 59044, 59094, 59142, 59203, 59212, 59244, 59256, 59383, 59400, 59540, 59544, 59720, 59733, 59734, 59771, 59793, 59809, 59882, 59906, 59928, 60008, 60081, 60142, 60151, 60183, 60194, 60223, 60262, 60316, 60400, 60474, 60475, 60484, 60532, 60536, 60537, 60550, 60553, 60598, 60619, 60630, 60645, 60675, 60695, 60713, 60714, 60767, 60780, 60847, 60893, 60962, 61053, 61061, 61084, 61094, 61152, 61158, 61189, 61209, 61277, 61331, 61333, 61343, 61347, 61351, 61366, 61378, 61382, 61384, 61480, 61501, 61505, 61506, 61518, 61536, 61546, 61561, 61568, 61575, 61647, 61654, 61657, 61701, 61715, 61726, 61805, 61806, 61815, 61851, 61864, 61865, 62120, 62204, 62247, 62432, 62451, 62509, 62614, 62664, 62843, 62925, 62950, 63113, 63117, 63119, 63162, 63218, 63227, 63351, 63819, 63834, 63948, 63984, 64062, 64185, 64188, 64214, 64387, 64414, 64476, 64478, 64503, 64508, 64620, 64687, 64741, 64761, 64786, 64791, 64835, 64839, 64869, 64888, 64913, 64959, 65020, 65038, 65045, 65051, 65103, 65201, 65204, 65209, 65295, 65326, 65371, 65400, 65429, 65536, 65565, 65635, 65682, 65780, 65795, 65844, 65884, 65928, 65934, 65963, 65997, 66002, 66007, 66123, 66128, 66129, 66184, 66201, 66218, 66232, 66234, 66262, 66277, 66282, 66335, 66349, 66422, 66424, 66509, 66512, 66536, 66543, 66551, 66572, 66600, 66611, 66617, 66633, 66638, 66652, 66745, 66828, 66838, 66845, 66853, 66862, 66869, 66880, 66902, 66915, 66938, 66945, 66962, 67040, 67154, 67162, 67173, 67183, 67189, 67192, 67205, 67215, 67222, 67230, 67247, 67264, 67268, 67329, 67331, 67341, 67346, 67360, 67386, 67396, 67418, 67436, 67442, 67446, 67450, 67472, 67491, 67503, 67526, 67567, 67658, 67661, 67668, 67670, 67678, 67690, 67707, 67709, 67713, 67728, 67742, 67766, 67782, 67809, 67821, 67826, 67848, 67867, 67909, 67942, 67949, 67952, 67992, 67999, 68021, 68035, 68061, 68091, 68096, 68107, 68126, 68130, 68137, 68146, 68150, 68195, 68213, 68242, 68245, 68248, 68272, 68349, 68375, 68382, 68412, 68422, 68423, 68508, 68519, 68525, 68574, 68610, 68627, 68629, 68682, 68695, 68737, 68743, 68776, 68797, 68810, 68820, 68837, 68844, 68848, 68878, 68888, 68916, 68935, 68966, 68970, 69008, 69045, 69046, 69079, 69130, 69200, 69243, 69267, 69326, 69353, 69471, 69495, 69535, 69547, 69555, 69565, 69575, 69592, 69632, 69669, 69766, 69772, 69851, 69852, 69861, 69862, 69869, 69888, 69928, 69953]\n",
    "#args=0\n",
    "#for i in errors:\n",
    " #   args+=y_target[i]\n",
    "#print(args)\n",
    "#sys.exit(-1)\n",
    "y_target_bin=make_mnist_binary(y_target)\n",
    "y_source_bin=make_mnist_binary(y_source)\n",
    "for alpha in alphas:\n",
    "    '''\n",
    "    if alpha==0:\n",
    "        x_bound=x_source\n",
    "        y_bound=y_source\n",
    "        if Binary:\n",
    "            y_bound=make_mnist_binary(y_bound)\n",
    "            x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source_bin,test_size=alpha,random_state=69105)\n",
    "        else:\n",
    "            y_source_bin=make_mnist_binary(y_source)\n",
    "            x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source_bin,test_size=alpha,random_state=69105)\n",
    "    else:\n",
    "        x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source,test_size=alpha,random_state=69105)\n",
    "    '''\n",
    "    print(\"alpha:\"+str(alpha))\n",
    "    if alpha==0:\n",
    "        x_bound=x_source\n",
    "        y_bound=y_source_bin\n",
    "    else:\n",
    "        x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source_bin,test_size=alpha,random_state=69105)\n",
    "    for epsilon in epsilons:\n",
    "        print(\"epsilon:\"+str(epsilon))\n",
    "        for sigma in sigmas:    \n",
    "            print(\"sigma:\"+str(sigma))\n",
    "            results=germain_bound(x_bound,y_bound,x_target,y_target_bin,alpha,sigma,epsilon,TASK,Binary=Binary)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_germain_res(alpha,epsilon,sigma,Binary=False,do_errorbars=True,plot_parts=False):\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    import pandas as pd\n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(\"Binary: \"+r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    results=pd.read_pickle(result_path+\"_results.pkl\") #\n",
    "    num_classifiers=4#results['bestparam']\n",
    "    #print(num_classifiers)\n",
    "    \n",
    "    N=num_classifiers*2 # how many values we got the estimate of the standard deviation from\n",
    "    N2=num_classifiers\n",
    "    z_alpha=1.96 ## in actuality we could probably use some degree of freedom thing here to make it more correct as\n",
    "                 ## the standard deviation is unknown, but we do this for now and pretend like we know the standard deviation\n",
    "        \n",
    "    if do_errorbars==False:\n",
    "        plt.plot(results[\"Weightupdates\"],results[\"train_germain\"],'k^-')\n",
    "        plt.plot(results[\"Weightupdates\"],results[\"target_germain\"],'m^-')\n",
    "    else:\n",
    "        plt.errorbar(results[\"Weightupdates\"],results[\"train_germain\"],yerr=z_alpha*results['error_std']/N,fmt='k^-')\n",
    "        plt.errorbar(results[\"Weightupdates\"],results[\"target_germain\"],yerr=z_alpha*results['target_error_std']/N,fmt='m^-')\n",
    "    \n",
    "    plt.xlabel(\"Weight updates\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    if plot_parts==True:\n",
    "        if do_errorbars==False:\n",
    "            plt.plot(results[\"Weightupdates\"],results['boundpart1_germain'],'*')\n",
    "            plt.plot(results[\"Weightupdates\"],results['boundpart2_germain'],'+-')\n",
    "            plt.plot(results[\"Weightupdates\"],results['boundpart3_germain'],'X')\n",
    "            plt.plot(results[\"Weightupdates\"],results['boundpart4_germain'],'D')\n",
    "            plt.plot(results[\"Weightupdates\"],results['boundpart5_germain'],'o-')\n",
    "            plt.plot(results[\"Weightupdates\"],results[\"germain_bound\"],'r*-')\n",
    "            plt.plot(results[\"Weightupdates\"],results[\"beta_bound\"])\n",
    "            plt.legend([\"Sample error\",\"Target error\",\"sample error part\",\"dis_rho part\",\"KL part\",\"lambda_rho\",\"extra constant\",\"Dis-rho Bound\",\"beta bound\"], loc = 0)#,\"e_s\",\"e_t\",\"d_tx\",\"d_sx\"])#,\"Bound\"\n",
    "            plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "            plt.show()\n",
    "        else:\n",
    "            #### \n",
    "            #### Errors here are calculated with the amount of classifiers drawn as the n that divides\n",
    "            #### with n=2*(drawn classifiers) for errors and n=(drawn classifiers)^2 for other boundparts\n",
    "            #### \n",
    "            ####\n",
    "            plt.errorbar(results[\"Weightupdates\"],results['boundpart1_germain'],yerr=z_alpha*results['error_std']/N,fmt='*')\n",
    "            plt.errorbar(results[\"Weightupdates\"],results['boundpart2_germain'],yerr=z_alpha*(results['d_tx_std']+results['d_sx_std'])/N2,fmt='+-')\n",
    "            #plt.errorbar(results[\"Weightupdates\"],results['boundpart3_germain'],yerr=z_alpha*results['_std']/N,fmt='X')\n",
    "            plt.plot(results[\"Weightupdates\"],results['boundpart3_germain'],'X')\n",
    "            plt.errorbar(results[\"Weightupdates\"],results['boundpart4_germain'],yerr=z_alpha*(results['e_t_std']+results['e_s_std'])/N2,fmt='D')\n",
    "            plt.plot(results[\"Weightupdates\"],results['boundpart5_germain'],'o-')\n",
    "            #plt.errorbar(results[\"Weightupdates\"],results['boundpart5_germain'],yerr=z_alpha*results['_std']/N,fmt='o-')\n",
    "            plt.errorbar(results[\"Weightupdates\"],results[\"germain_bound\"],\n",
    "                         yerr=z_alpha*(results['error_std']/N+(results['e_t_std']+results['e_s_std']+results['d_tx_std']+results['d_sx_std'])/N2),fmt='r*-')\n",
    "            plt.errorbar(results[\"Weightupdates\"],results[\"beta_bound\"],\n",
    "                         yerr=(results['e_s_std']+results['d_tx_std'])/N2)\n",
    "            plt.legend([\"Sample error\",\"Target error\",\"sample error part\",\"dis_rho part\",\"KL part\",\"lambda_rho\",\"extra constant\",\"Dis-rho Bound\",\"beta bound\"], loc = 0)#,\"e_s\",\"e_t\",\"d_tx\",\"d_sx\"])#,\"Bound\"\n",
    "            plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "            plt.show()\n",
    "        \n",
    "    else:\n",
    "        if do_errorbars==False:\n",
    "            plt.plot(results[\"Weightupdates\"],results[\"germain_bound\"],'r*-')\n",
    "            plt.plot(results[\"Weightupdates\"],results[\"beta_bound\"])\n",
    "            plt.legend([\"Sample error\",\"Target error\",\"Dis-rho Bound\",\"beta bound\"], loc = 0)#,\"e_s\",\"e_t\",\"d_tx\",\"d_sx\"])#,\"Bound\"\n",
    "            plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "            plt.show()\n",
    "        else:\n",
    "            disrho_error=(results['error_std']/N+(results['e_t_std']+results['e_s_std']+results['d_tx_std']+results['d_sx_std'])/N2)\n",
    "            print(disrho_error)\n",
    "            plt.errorbar(results[\"Weightupdates\"],results[\"germain_bound\"],\n",
    "                         yerr=z_alpha*disrho_error,fmt='r*-',capsize=8)\n",
    "            plt.errorbar(results[\"Weightupdates\"],results[\"beta_bound\"],\n",
    "                         yerr=(results['e_s_std']+results['d_tx_std'])/N2,capsize=8)\n",
    "            plt.legend([\"Sample error\",\"Target error\",\"Dis-rho Bound\",\"beta bound\"], loc = 0)#,\"e_s\",\"e_t\",\"d_tx\",\"d_sx\"])#,\"Bound\"\n",
    "            plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "            plt.savefig(\"Plot\"+str(10*alpha)+\".png\",dpi=300)\n",
    "            plt.show()\n",
    "            #plt.savefig(\"Plot\"+str(10*alpha)+\".png\",dpi=300)\n",
    "sigma=[3,2]\n",
    "#plot_germain_res(0,0.03,sigma,True)\n",
    "plot_germain_res(0,0.03,sigma,True,True)\n",
    "plot_germain_res(0.3,0.03,sigma,True,True)\n",
    "#plot_germain_res(0.3,0.001,sigma,True)\n",
    "#plot_germain_res(0.3,0.01,sigma,True)\n",
    "#plot_germain_res(0.1,0.001,sigma,True)\n",
    "#plot_germain_res(0.1,0.01,sigma,True)\n",
    "#plot_germain_res(0.3,0.03,sigma,True)\n",
    "#plot_germain_res(0.1,0.03,sigma,True)\n",
    "#plot_germain_res(0.3,0.03,sigma,True)\n",
    "#plot_germain_res(0.3,0.01,sigma,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load module\n",
    "#mymodule = SourceFileLoader('train', path_to_root_file+'mnist_transfer/experiments/training.py').load_module()\n",
    "#mymodule2 = SourceFileLoader('plotting', path_to_root_file+'mnist_transfer/results/plotting.py').load_module()\n",
    "#from plotting import * \n",
    "#from train import *\n",
    "\n",
    "def joint_error(a,b,true_label):\n",
    "    ## expected joint error\n",
    "        shapes=a.shape\n",
    "        e_s=0\n",
    "        # e_S= E_h,h' E_x,y L(h(x),y)L(h'(x),y)  \n",
    "        arr1=np.abs(a-true_label)\n",
    "        arr1=np.sum(arr1,axis=1)\n",
    "        arr1=np.divide(arr1, 2)\n",
    "        arr2=np.abs(b-true_label)\n",
    "        arr2=np.sum(arr2,axis=1)\n",
    "        arr2=np.divide(arr2, 2)\n",
    "        #print(arr1)\n",
    "        #print(arr2)\n",
    "        e_s=arr1.T@arr2\n",
    "        e_s/=(shapes[0])\n",
    "        return e_s\n",
    "\n",
    "\n",
    "       \n",
    "    \n",
    "\n",
    "def classifier_disagreement(a,b):\n",
    "    ### classifier disagreement, i.e. R(h,h')= 1/n sum(L( h(x),h'(x) ))\n",
    "    shapes=a.shape\n",
    "    d=0\n",
    "    arr=np.abs(a-b)\n",
    "    arr=np.sum(arr,axis=1)\n",
    "    d=np.count_nonzero(arr)\n",
    "    d/=(shapes[0])\n",
    "    return d\n",
    "#a=np.array([[1,0],[1,0],[1,0]])\n",
    "#b=np.array([[1,0],[0,1],[1,0]])\n",
    "#d=np.array([[1,0],[1,0],[0,1]])\n",
    "#c=classifier_disagreement(a,b)\n",
    "#print(c)\n",
    "#e=joint_error(a,b,d)\n",
    "#print(e)\n",
    "def compute_beta(alpha,epsilon,sigma,Binary=False):\n",
    "    ### computes the beta bound from results and saves it to the result file along with its parts\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    import pandas as pd\n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(\"Binary: \"+r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    results=pd.read_pickle(result_path+\"_results.pkl\") \n",
    "    \n",
    "   \n",
    "    \n",
    "    bound, params, parts = grid_search(results['train_germain'],results['e_s'],results['e_t'],results['d_tx'],results['d_sx'],results['KL'],0.05,70000,len(results['KL']),beta_bound=True)\n",
    "    results[\"beta_bound\"]=bound\n",
    "    results['beta_boundpart1']=parts[0]\n",
    "    results['beta_boundpart2']=parts[1]\n",
    "    results['beta_boundpart3']=parts[2]\n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    with open(path_to_root_file+'mnist_transfer/'+result_path+\"_results.pkl\",'wb') as f:\n",
    "        pickle.dump(results,f)\n",
    "    f.close()\n",
    "#compute_beta(0.3,0.03,[3,3],True)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def make_sigma_plot(alpha,epsilon,Binary=True):\n",
    "    low_bound=[]\n",
    "    x_sigmas=[]\n",
    "    sigmas=[]\n",
    "    \n",
    "    for i in range(2,9):  \n",
    "        sigmas.append([3,i])#3*10**(-i))\n",
    "        if(i==8):\n",
    "            break\n",
    "        sigmas.append([1,i])#10**(-i))\n",
    "        \n",
    "    #sigmas=[[3,3]]\n",
    "    for sigma in sigmas:\n",
    "        sigma_tmp=sigma\n",
    "        sigma=sigma[0]*10**(-1*sigma[1])\n",
    "        x_sigmas.append(sigma)\n",
    "        \n",
    "        if Binary:\n",
    "            result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        else:\n",
    "            result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "\n",
    "        results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "        low_bound.append(results[\"germain_bound\"].min())\n",
    "    print(low_bound)\n",
    "    print(x_sigmas)\n",
    "    plt.title(\"Plot of minimum bound over sigma for \"+r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon))\n",
    "    plt.semilogx(x_sigmas,low_bound,'k*')\n",
    "    plt.show()\n",
    "make_sigma_plot(0.3,0.03)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
