{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#### Keras implementation of NN's which we will look at MNIST with\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras as keras \n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import L2\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "import scipy\n",
    "import h5py\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "svhn_path=\"../Datasets/svhn\"#\"/Home/Adam/Research/Datasets/svhn\"\n",
    "# Hyper-parameters\n",
    "K.clear_session() ## needed???\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "### ???\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 2GB of memory on the first GPU\n",
    "  # I do not know why I have to do this but gpu does not work otherwise.\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "####### label shifting and plotting\n",
    "\n",
    "#class_label=1\n",
    "#summand=1\n",
    "#delta=0.7\n",
    "\n",
    "## Note: this assumes that you have a one hot encoding and that class_label is within the range of that vector length\n",
    "def label_shift(X,y,delta,class_label):\n",
    "    ## takes a dataset and shifts the class label distribution by some margin delta \n",
    "    ## we will just give the ``removed'' entries back as the target distribution\n",
    "    N=len(y)\n",
    "    idx=[]\n",
    "    y_2=[]\n",
    "    X_2=[]\n",
    "    x_target=[]\n",
    "    y_target=[]\n",
    "    for i in range(N):\n",
    "        if(y[i][class_label]==1):\n",
    "            idx.append(i)\n",
    "    ## what proportion of the label to remove\n",
    "    M=int(len(idx)*delta)\n",
    "    ## choose randomly delta amount of sample to include in target\n",
    "    chosen=random.sample(idx,M)\n",
    "    for i in range(N):\n",
    "        if(i in chosen):\n",
    "            x_target.append(X[i])\n",
    "            y_target.append(y[i])\n",
    "        else:\n",
    "            y_2.append(y[i])\n",
    "            X_2.append(X[i])\n",
    "    x_target=np.array(x_target)\n",
    "    y_target=np.array(y_target)\n",
    "    X_2=np.array(X_2)\n",
    "    y_2=np.array(y_2)\n",
    "    return([X_2, y_2, x_target, y_target])\n",
    "\n",
    "## Note: this assumes that you have a one hot encoding and that class_label is within the range of that vector length\n",
    "def label_shift_linear(X,y,delta,labels,decreasing=True):\n",
    "    \"\"\"\n",
    "    X: data points\n",
    "    y: labels\n",
    "    delta: percentage amount which you want to decrease for each label, i.e. slope for the shifting; delta in [0,1)\n",
    "    labels: a vector of the possible labels i.e. for MNIST we have labels=[0,1,2,3,4,5,6,7,8,9]\n",
    "    decreasing: bool to see if you want to make the shift increasing or decreasing\n",
    "    \"\"\"\n",
    "    ## takes a dataset and shifts the class label distribution for all labels by\n",
    "    ## a linearly increasing or decreasing amount\n",
    "    ## we will just remove entries of the class for now\n",
    "    \n",
    "    L=len(labels)\n",
    "    y_2=y\n",
    "    X_2=X\n",
    "    x_target=[]\n",
    "    y_target=[]\n",
    "    ## for every label go through and remove delta*label(or delta*(L-label)) amount of them (+1 to ensure overlap)\n",
    "    for label in labels:\n",
    "        if decreasing:\n",
    "            delta2=delta*(label+1)\n",
    "        else:\n",
    "            delta2=delta*(L-label+1)\n",
    "        assert(delta2<1)\n",
    "        X_2, y_2, x_target2, y_target2=label_shift(X_2,y_2,delta2,label)\n",
    "        if (label==0):\n",
    "            x_target=x_target2\n",
    "            y_target=y_target2\n",
    "        else:   \n",
    "            x_target=np.concatenate((x_target,x_target2))\n",
    "            y_target=np.concatenate((y_target,y_target2))\n",
    "        #print(\"--------------\")\n",
    "        #T=np.array(x_target)\n",
    "        #print(T.shape)\n",
    "    return([X_2, y_2, x_target, y_target])\n",
    "\n",
    "def plot_labeldist(labels,y_1,label_1):\n",
    "    \"\"\"\n",
    "    labels: a vector of the possible labels i.e. for MNIST we have labels=[0,1,2,3,4,5,6,7,8,9]\n",
    "    y_1: labels of dataset\n",
    "    label_1: name of dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    # calculate the amount of label j in both datasets\n",
    "    N=len(y_1)\n",
    "   # M=len(labels)\n",
    "    densities_1=[]\n",
    "    sum=0\n",
    "    for j in labels:\n",
    "        sum=0\n",
    "        for i in range(len(y_1)):\n",
    "            if y_1[i][j]==1:\n",
    "                sum+=1\n",
    "        densities_1.append(sum)\n",
    "       \n",
    "    densities_1_rel=[]\n",
    "   \n",
    "    ## calculate relative density\n",
    "    for i in range(len(densities_1)):\n",
    "        densities_1_rel.append(densities_1[i]/(N))\n",
    "        \n",
    "    #print(densities_1_rel)\n",
    "\n",
    "\n",
    "    width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.bar(labels, densities_1_rel, width, label=label_1)\n",
    "    #ax.set_ylim([0,1.25])\n",
    "    ax.set_xlabel('Labels')\n",
    "    ax.set_title('Label distribution')\n",
    "    ax.legend()\n",
    "    plt.rc('font', size=12, family='serif')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_splitbars(labels,y_1,y_2,label_1,label_2):\n",
    "    \"\"\"\n",
    "    labels: a vector of the possible labels i.e. for MNIST we have labels=[0,1,2,3,4,5,6,7,8,9]\n",
    "    y_1: labels of dataset1\n",
    "    y_2: labels of dataset2\n",
    "    label_1: name of dataset1\n",
    "    label_2: name of dataset2\n",
    "    \"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    # calculate the amount of label j in both datasets\n",
    "    densities_1=[]\n",
    "    densities_2=[]\n",
    "    sum=0\n",
    "    for j in labels:\n",
    "        sum=0\n",
    "        for i in range(len(y_1)):\n",
    "            if y_1[i][j]==1:\n",
    "                sum+=1\n",
    "        densities_1.append(sum)\n",
    "        sum=0\n",
    "        for i in range(len(y_2)):\n",
    "            if y_2[i][j]==1:\n",
    "                sum+=1\n",
    "        densities_2.append(sum)\n",
    "    densities_1_rel=[]\n",
    "    densities_2_rel=[]\n",
    "    ## calculate relative densities #### TODO: is this normalisation really what we want?\n",
    "    for i in range(len(densities_1)):\n",
    "        densities_1_rel.append(densities_1[i]/(densities_1[i]+densities_2[i]))\n",
    "        densities_2_rel.append(densities_2[i]/(densities_1[i]+densities_2[i]))\n",
    "    #print(densities_1_rel)\n",
    "    #print(densities_2_rel)\n",
    "\n",
    "\n",
    "    width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.bar(labels, densities_1_rel, width, label=label_1)\n",
    "    ax.bar(labels, densities_2_rel, width , bottom=densities_1_rel,\n",
    "           label=label_2)\n",
    "    ax.set_ylim([0,1.25])\n",
    "    ax.set_xlabel('Labels')\n",
    "    ax.set_title('Label distribution')\n",
    "    ax.legend()\n",
    "    plt.rc('font', size=12, family='serif')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "######### Here we use the functions above ##############################################################\n",
    "\n",
    "###### Add train and test together and shift the distributions to create source and target distributions\n",
    "### MNIST all data\n",
    "x_full=np.append(x_train,x_test, axis=0)\n",
    "y_full=np.append(y_train,y_test, axis=0)\n",
    "### MNIST-M all data\n",
    "x_full_m=np.append(x_train_m,x_test_m, axis=0)\n",
    "y_full_m=np.append(y_train_m,y_test_m, axis=0)\n",
    "#x_shift,y_shift,x_shift_target,y_shift_target =label_shift(x_train,y_train,1/2,7)\n",
    "x_shift, y_shift, x_shift_target, y_shift_target =label_shift_linear(x_full,y_full,1/12,[0,1,2,3,4,5,6,7,8,9])\n",
    "x_shift_m, y_shift_m,x_shift_target_m, y_shift_target_m=label_shift_linear(x_full_m,y_full_m,1/12,[0,1,2,3,4,5,6,7,8,9],decreasing=False)\n",
    "#rint(\"test of shift\")\n",
    "#print(x_shift_target.shape)\n",
    "#print(x_shift.shape)\n",
    "#print(y_shift_target.shape)\n",
    "#print(y_shift.shape)\n",
    "plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_shift_target,\"shifted, target\")\n",
    "plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_shift,\"shifted, source\")\n",
    "plot_splitbars([0,1,2,3,4,5,6,7,8,9],y_shift,y_shift_m,\"MNIST, source\",\"MNIST-M, source\")\n",
    "plot_splitbars([0,1,2,3,4,5,6,7,8,9],y_shift_target,y_shift_target_m,\"MNIST, target\",\"MNIST-M, target\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TODO: make source and target be the same amount and the proportions more symmetrical across labels if possible \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Add the label shifted datasets to each other creating the source and target domain for task 2\n",
    "x_source=np.append(x_shift,x_shift_m, axis=0)\n",
    "y_source=np.append(y_shift,y_shift_m, axis=0)\n",
    "x_target=np.append(x_shift_target,x_shift_target_m, axis=0)\n",
    "y_target=np.append(y_shift_target,y_shift_target_m, axis=0)\n",
    "#print(x_shift.shape)\n",
    "#print(x_shift_target.shape)\n",
    "## sanity check for label distribution, seems ok to me\n",
    "#plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_full,\"MNIST\")\n",
    "#plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_full_m,\"MNIST-M\")\n",
    "#plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_source,\"MNIST+MNIST-M, source\")\n",
    "#plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_target,\"MNIST+MNIST-M, target\")\n",
    "\n",
    "\n",
    "##### make index lists for train and test splits for source\n",
    "\n",
    "#N=70000 ideally, however, how can we ensure this when the amount differs between labels?\n",
    "## maybe we do not care too much about it exactly\n",
    "N=len(y_source)\n",
    "M=len(x_shift)\n",
    "train2=[]\n",
    "train1=[]\n",
    "test1=[]\n",
    "test2=[]\n",
    "ntr1=round(0.8*M)\n",
    "ntr2=round(0.8*N)\n",
    "### sample n_tr datapoints (w/o replacement) to be the training set at random\n",
    "## do this 10 times and save the indices into a file along with the training ones\n",
    "for i in range(10):\n",
    "    T=random.sample(range(M),M)\n",
    "    T2=random.sample(range(N),N)\n",
    "    train1.append(T[:ntr1])\n",
    "    train2.append(T2[:ntr2])\n",
    "    test1.append(T[ntr1:])\n",
    "    test2.append(T2[ntr2:])\n",
    "\n",
    "task1=[train1,test1]\n",
    "task2=[train2,test2]\n",
    "import pickle\n",
    "pkl_file=open('splits_task1.pkl','wb')\n",
    "listoflist=task1\n",
    "pickle.dump(listoflist,pkl_file)\n",
    "\n",
    "\n",
    "if True:\n",
    "    import pickle\n",
    "    pkl_file=open('splits_task2.pkl','wb')\n",
    "    listoflist=task2\n",
    "    pickle.dump(listoflist,pkl_file)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=10000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "##### load the splits from the file and make the split on the data\n",
    "import sys\n",
    "pkl_file=open('splits_task1.pkl','rb')\n",
    "split1=pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "traindata=[]\n",
    "#print(split1[0][0])\n",
    "for i in split1[0]:\n",
    "    trainidx=i\n",
    "    for j in trainidx:\n",
    "        traindata.append(x_shift[j])\n",
    "    print(traindata)\n",
    "    sys.exit(-1)\n",
    "for j in split1[1]:\n",
    "    testdata=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, variance 2.1985865 50.549427\n",
      "---------------Load SVHN----------------\n",
      "Training set (604388, 32, 32, 3) (604388, 10)\n",
      "Test set (26032, 32, 32, 3) (26032, 10)\n"
     ]
    }
   ],
   "source": [
    "### import svhn_cropped without grayscale\n",
    "\n",
    "# Open the file as readonly\n",
    "h5f = h5py.File('SVHN_cropped.h5', 'r')\n",
    "\n",
    "# Load the training, test and validation set\n",
    "X_train = h5f['X_train'][:]\n",
    "Y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "Y_test = h5f['y_test'][:]\n",
    "X_extra = h5f['X_extra'][:]\n",
    "Y_extra = h5f['y_extra'][:]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_extra = X_extra.astype('float32')\n",
    "\n",
    "#### make validation set from train and extra (and make extra part of train(?))\n",
    "\n",
    "X_train=np.append(X_train,X_extra, axis=0)\n",
    "Y_train=np.append(Y_train,Y_extra, axis=0)\n",
    "## normalising\n",
    "sigma=np.std(X_train)\n",
    "X_train /= sigma \n",
    "X_test /= sigma\n",
    "\n",
    "\n",
    "mu=np.mean(X_train)\n",
    "X_train -= mu\n",
    "X_test -= mu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('mean, variance', mu, sigma)\n",
    "print(\"---------------Load SVHN----------------\")\n",
    "print('Training set', X_train.shape, Y_train.shape)\n",
    "#print('Extra set', X_extra.shape, Y_extra.shape)\n",
    "print('Test set', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## import svhn_cropped which is svhn in 32x32 size\\n####### do not load this at the moment!\\n####### do not load this at the moment!\\n####### do not load this at the moment!\\n####### do not load this at the moment!\\n####### do not load this at the moment!\\n####### do not load this at the moment!\\n####### do not load this at the moment!\\n# Open the file as readonly\\nh5f = h5py.File('SVHN_gray.h5', 'r')\\n\\n# Load the training, test and validation set\\nX_train = h5f['X_train'][:]\\nY_train = h5f['y_train'][:]\\nX_test = h5f['X_test'][:]\\nY_test = h5f['y_test'][:]\\nX_val = h5f['X_val'][:]\\nY_val = h5f['y_val'][:]\\n\\n# Close this file\\nh5f.close()\\n\\nx_train = x_train.astype('float32')\\nx_test = x_test.astype('float32')\\nx_test = x_test.astype('float32')\\n## normalising\\n#_train[:,axis=3] /= 255.0 \\n#X_test /= 255.0\\n#X_val /= 255.0\\n\\nprint('Training set', X_train.shape, Y_train.shape)\\nprint('Validation set', X_val.shape, Y_val.shape)\\nprint('Test set', X_test.shape, Y_test.shape)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## import svhn_cropped which is svhn in 32x32 size\n",
    "####### do not load this at the moment!\n",
    "####### do not load this at the moment!\n",
    "####### do not load this at the moment!\n",
    "####### do not load this at the moment!\n",
    "####### do not load this at the moment!\n",
    "####### do not load this at the moment!\n",
    "####### do not load this at the moment!\n",
    "# Open the file as readonly\n",
    "h5f = h5py.File('SVHN_gray.h5', 'r')\n",
    "\n",
    "# Load the training, test and validation set\n",
    "X_train = h5f['X_train'][:]\n",
    "Y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "Y_test = h5f['y_test'][:]\n",
    "X_val = h5f['X_val'][:]\n",
    "Y_val = h5f['y_val'][:]\n",
    "\n",
    "# Close this file\n",
    "h5f.close()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "## normalising\n",
    "#_train[:,axis=3] /= 255.0 \n",
    "#X_test /= 255.0\n",
    "#X_val /= 255.0\n",
    "\n",
    "print('Training set', X_train.shape, Y_train.shape)\n",
    "print('Validation set', X_val.shape, Y_val.shape)\n",
    "print('Test set', X_test.shape, Y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, variance 0.36348352 70.18035\n",
      "---------------Load MNIST----------------\n",
      "Training set (60000, 32, 32, 3) (60000, 10)\n",
      "Test set (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "## import mnist\n",
    "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
    "x_train = np.pad(x_train,((0,0),(2,2),(2,2))) #padding to make images 32x32 and not 28x28\n",
    "x_test = np.pad(x_test,((0,0),(2,2),(2,2))) \n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "## normalising\n",
    "#x_train /= 255.0 \n",
    "#x_test /= 255.0\n",
    "\n",
    "## normalising to unit variance\n",
    "sigma=np.std(x_train)\n",
    "x_train /= sigma \n",
    "x_test /= sigma\n",
    "\n",
    "## mean subtraction\n",
    "mu=np.mean(x_train)\n",
    "x_train -= mu\n",
    "x_test -= mu\n",
    "## make labels into categorical classes\n",
    "y_train = keras.utils.to_categorical(lbl_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(lbl_test, num_classes)\n",
    "\n",
    "\n",
    "x_train=np.expand_dims(x_train,3)\n",
    "x_test=np.expand_dims(x_test,3)\n",
    "\n",
    "\n",
    "### make mnist into 3 channels\n",
    "x_train=np.concatenate((x_train,)*3, axis=-1)\n",
    "x_test=np.concatenate((x_test,)*3, axis=-1)\n",
    "print('mean, variance', mu, sigma)\n",
    "print(\"---------------Load MNIST----------------\")\n",
    "print('Training set', x_train.shape, y_train.shape)\n",
    "#print('Validation set', x_val.shape, y_val.shape)\n",
    "print('Test set', x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, variance 1.1809415 74.36859\n",
      "---------------Load MNIST-M----------------\n",
      "Training set (60000, 32, 32, 3) (60000, 10)\n",
      "Test set (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### load MNIST-M\n",
    "\n",
    "#h5f = h5py.File('MNIST-M.h5', 'r')\n",
    "\n",
    "# Load the training, test and \n",
    "#x_train_m = h5f['x_train'][:]\n",
    "#y_train_m = h5f['y_train'][:]\n",
    "#x_test_m = h5f['x_test'][:]\n",
    "#y_test_m = h5f['y_test'][:]\n",
    "import pandas as pd\n",
    "\n",
    "# Close this file\n",
    "#h5f.close()\n",
    "\n",
    "M = pd.read_pickle('mnistm_data.pkl')\n",
    "x_train_m =M['train']\n",
    "x_test_m =M['test']\n",
    "y_train_m=y_train\n",
    "y_test_m =y_test\n",
    "x_train_m = np.pad(x_train_m,((0,0),(2,2),(2,2),(0,0))) #padding to make images 32x32 and not 28x28\n",
    "x_test_m = np.pad(x_test_m,((0,0),(2,2),(2,2),(0,0)))\n",
    "\n",
    "x_train_m = x_train_m.astype('float32')\n",
    "x_test_m = x_test_m.astype('float32')\n",
    "## normalising to unit variance\n",
    "sigma=np.std(x_train_m)\n",
    "x_train_m /= sigma \n",
    "x_test_m /= sigma\n",
    "\n",
    "## mean subtraction\n",
    "mu=np.mean(x_train_m)\n",
    "x_train_m -= mu\n",
    "x_test_m -= mu\n",
    "\n",
    "print('mean, variance', mu, sigma)\n",
    "print(\"---------------Load MNIST-M----------------\")\n",
    "print('Training set', x_train_m.shape, y_train_m.shape)\n",
    "#print('Validation set', x_val.shape, y_val.shape)\n",
    "print('Test set', x_test_m.shape, y_test_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVeElEQVR4nO3de5QV1ZUG8G+PImhrVOSRFtAWVBSjgAsQgQUGIw+DA6gDaB7EBy8hgjrIw0EQjUYcecwoIC8DBqV5qeBohCFGIhEFBVsQQWHaBdjQRhRfqKB7/qjq2JDadW/XrVu3m/P91mJx++w+dTbV7L731rl1jqgqiOjo9y+5ToCIksFiJ3IEi53IESx2Ikew2IkcwWIncsSxmXQWkS4ApgA4BsAsVf19iu/nPB9RlqmqBLVL1Hl2ETkGwDYAVwDYBWAdgOtU9Z2QPix2oiyzij2Tl/GtALyvqjtU9VsACwB0z+B4RJRFmRR7PQA7y329y28jokooo/fs6RCR/gD6Z3scIgqXSbHvBtCg3Nf1/bbDqOoMADMAvmcnyqVMXsavA3COiJwlIscB6ANgWTxpEVHcIj+zq+ohERkC4EV4U29zVHVzbJkRUawiT71FGowv44myLhtTb0RUhbDYiRzBYidyBIudyBEsdiJHZP0TdEeTbrc0C2yf+uhks08DdAg5oj05sWLrY2as888G2YfcFdw8dq5928K4Xz9jxlpeU9OMrV/6iZ1HJVH/kuD2nWs/NPss3zDVjN006D4zdtddvzJjQ6+abcaAaoGtIoEX1SPjMzuRI1jsRI5gsRM5gsVO5AgWO5Ejjt7Pxle3Q48sGmnGBl91f8hBg6+Ofokis8eYKXebsUnDng0ZK2a17ZCW2j+W4q9XmLGzju+cSUY5pfppSPTk2Mf7GvZ5vGPMiMD2qfdtjDQWPxtP5DgWO5EjWOxEjmCxEzmCxU7kCBY7kSOqxNTbhd1OCGyfPXu+2adlnR5RhkqhNLC1WqO6Zo9DO7KQRsw+1lfNWE20NmNSEHKjxgeZZBQg5JatR5b9xowN7nqrEWkeMZE1ZiQvv50Z+2pPxOEi4NQbkeNY7ESOYLETOYLFTuQIFjuRI1jsRI7IaOpNRIoBfA7gOwCHVLVFiu+PNJidY/BUGABMmHeXGRvRd5YZGzC+jRmbPmZ5YPtVAy8w+zz3WIJzLhG1udq+JW7NEvscPzCvhxkb3Tf4jr7zu9h5LF48zYw1yRtodwxxEC8Eti9asdDsc32nsWZs5/6VZuyMUyrHZsXW1FscC07+VFX/HsNxiCiL+DKeyBGZFrsCWCEib4hI5XgNQ0SBMn0Z305Vd4tIHQArReRdVV1d/hv8XwL8RUCUYxk9s6vqbv/vUgBPA2gV8D0zVLVFqot3RJRdkYtdRPJE5KSyxwA6AdgUV2JEFK/IU28i0hDeszngvR14UlV/l6JPpMFa9Ap+t7F+4aEoh4vMWqSwaJ89jdP0tKr9Dkb145CovTUUsNVoPzekj30X3TulU8xYz57DzNi2v4UMZ3j+leFmrGvbCWbsorZ2/m9HyCOq2KfeVHUHgKaRMyKiRHHqjcgRLHYiR7DYiRzBYidyBIudyBFVYsHJyuLFzcH7wHVqMsrsk9fYno75alvGKaXt1IZ2bNo0a1FGoHcne8orXPCPetyj9qKM9wxJcH4qRMOQj39tX2f/F16xbpwZ69zqngwyqhguOEnkOBY7kSNY7ESOYLETOYLFTuQIXo2vgBMuDG7/suhbs8+8Nb81Y33bPRYpjy632GvGLXh0bmD7yegaaSzgHTMiYq+91+b8kYHta955IGIe8RIJ2boqxAF93YzVQP2Q8U6PNF4UvBpP5DgWO5EjWOxEjmCxEzmCxU7kCBY7kSM49RaDd78Inu4CgMZ515mxDV/+txlrlneJGRO0Dclmf2Brv97/Y/aYWXh9yPFsHVvea8ZeWh/8b9Mv7O2kkBcpjUiiTr39Zqz9c3l83FozdvujHczYpCGrzVgUnHojchyLncgRLHYiR7DYiRzBYidyBIudyBEpp95EZA6AbgBKVfUnfltNAIUACgAUA+ilqp+kHKyKT71d2CW4veiFD0N65Ucaq2j/o2Zsz8KbzFinfjUijRfFhjV27OJ2wVNbt908x+wzceYNmaaUtqhTb2FUN5uxEmwxY6fXuTY48FHUPKJPvf0BwJH/zUcCWKWq5wBY5X9NRJVYymL391vfd0RzdwBlnySZC6BHvGkRUdyivmevq6ol/uM9AOrGlA8RZUnkXVzLqKqGvRcXkf4Aqva+xURHgajP7HtFJB8A/L/NDzyr6gxVbaGqIUvvE1G2RS32ZQD6+o/7Ang2nnSIKFvSmXp7CsBlAGoB2AtgLIBnACwEcAaAD+BNvR15ES/oWJVi6m34/W3M2IRR00J6XmS0B99p5jk5JLbTjIicYcaSvFMxuu2BrSL29k8/XAaKTzam2CxvfjzZjDWvObTCx4uauzX1lvI9u6pa92heHikTIsoJfoKOyBEsdiJHsNiJHMFiJ3IEi53IERl/gi4J4+d3D2yvX+vHZp8bOk0OOWLYnWEbzMid97YMbH/o7vVmn8XP32rGrun6oBm7pL0ZCp2SiTItl43pqbG3LTYie8w+hdODp+sAoPfARhlmlL5m3ezY+N8NN2NRpteSxGd2Ikew2IkcwWIncgSLncgRLHYiR7DYiRxRJfZ6s3MsNvusK11qxvr3ucOMbXwpzaTSVPtMO1ZabJ+Ooq1TzFjT84ZlkFF8ok3zFZixC+v/3IwV7bQX4AybOrxtfPAyChPH2PvzAU1CYrbifY+bsYKaPwvp+Xlgq8gFkfLgXm9EjmOxEzmCxU7kCBY7kSNY7ESOqNJX45v3sK/CbqwCS2Ae0FVmrAbON2OSd7p90K8yyahiovzf6dFhohl7drU9S/KtPm/GqiHkriHkGe32kolPLh9hxn7xr7NCxrJdd3N9e7yZwWsRxr0GHZ/ZiRzBYidyBIudyBEsdiJHsNiJHMFiJ3JEOts/zQHQDUCpqv7EbxsHoB+Aj/xvG60aMjfyw7EiTr0dCGzv1PsUs8/Khd9EGSpRvW5raMYKJ9rrsU0ovMqMjejzXEY5HSnq1OzWFcHt53VuHtJrY6Q89uNJMzZo4JDA9qce+yQkj2Spvh/YLnJ2xONFn3r7A4AuAe2TVLWZ/ydloRNRbqUsdlVdjbBPIBBRlZDJe/YhIlIkInNE5NTYMiKirIha7NMANALQDEAJgIetbxSR/iKyXkTsxdWJKOsiFbuq7lXV71T1ewAzAbQK+d4ZqtpCVYOXDCGiREQqdhHJL/dlTwCb4kmHiLIlnam3pwBcBqAWgL0AxvpfNwOg8BaCG6CqJSkHi/mut+375pl9zj6tb5ShKo3qgRMgnh+hthkrVfucRDGq9xIz9vuFd4b03GG023eoqb4ccryvzYjUPN7uVnlm2EzTlt0c2D4o4h121tRbyr3eVPW6gObZkbIgopzhJ+iIHMFiJ3IEi53IESx2Ikew2IkcUSUWnPzwwLLA9vwaV5h98lva0zF7Ksln+cLO/YR+RWZsxKx/M2M/bTggsL16dTuPP225zw6GzF1Vh33+5zwSPGFz/eAGZp8xU1qbsXuHrjVj/e5sbMZmPbTNjFUa1s2P1uxlClxwkshxLHYiR7DYiRzBYidyBIudyBEsdiJHVImpt24DzgxsXz692OxTuMa+I6tPu4eipBG7sHPfqfEUM7Zy27AIo7UxI+3Pt++wW/T0GDNWx57xiiRsb7Owc3UQ9t1yx8llGWRUNXHqjchxLHYiR7DYiRzBYidyBIudyBFV4mq85YC+YsZqoFZIHufFmQbODVk3d8GCuWaseaNeIUf9zIyI1DVj1s/zZXspOXS4JiSNBIVdjV/17mQz1rHxrWasUYfg57Mdq9NOq8rh1Xgix7HYiRzBYidyBIudyBEsdiJHsNiJHJHO9k8NAMwDUBfedk8zVHWKiNQEUAigAN4WUL1UNXSznbin3u5f0M2Mjeptb1rz5JoRZmz96jfs8UZNDmyvgY5mnzDbSx43Y/1uvNGMtW3TzIzdd3fwlN3DI582+9z+wEVmLEzYVFnc6l9ix3autf9bLVkbfEPUtZcmezNUWP5/nPMfge2XXRC2NqAtk6m3QwDuUNUmAFoDGCwiTQCMBLBKVc8BsMr/mogqqZTFrqolqvqm//hzAFsA1APQHUDZJ0bmAuiRpRyJKAYVes8uIgUAmgN4DUDdcju37oH3Mp+IKqmUu7iWEZETASwBMExVPyv/fk1V1Xo/LiL9AfTPNFEiykxaz+wiUg1eoc9X1aV+814Ryffj+QBKg/qq6gxVbaGqIZ8gJ6JsS1ns4j2FzwawRVUnlgstA9DXf9wXwLPxp0dEcUln6q0dgL8CeBvA937zaHjv2xcCOAPAB/Cm3valOFasU2+3PtzMjE25fUPEo5aExIL343l8iT2NM6Sf/Tvwq9CJyqjaB7aeihPMHvv0hUgjJTn1FuYL/YsZy8Opge1Sp6l9wI/s0PBH7Dm0CYPn2x3RKCQWLOr5tabeUr5nV9VXAFijXh4pGyJKHD9BR+QIFjuRI1jsRI5gsRM5gsVO5IgqseDk/327OLC9oNrVYaNFGQqFf+5qxvpc/qdIx4xb2M9s3NAVge33/Fdns8+Lcz42Y51vPC39xHJk+OTg6UYAmDDU2hpqf8gRwyap8kJiB83IvOW3mLG+V88KDhwKGSoEF5wkchyLncgRLHYiR7DYiRzBYidyBIudyBFVYupN9dPA9plLhpl9jj3GPt4NPSabscI//9aM9bn8CfugMYv75yJi33XVvqG92dvqHckuzGjpNaC+GSucviCkZ9sKj/U1lpuxXwz8pRlb+pi9P1+SOPVG5DgWO5EjWOxEjmCxEzmCxU7kiCpxNT5u3kpbljPMiIgdi1vcP5drWk43Y0vW/dyM1Whk/5u/CV6Sz1M7uPnpRcPNLj06jA85YI2QWHFI7McVPl7zDvZNVBtXhwxVSfBqPJHjWOxEjmCxEzmCxU7kCBY7kSNY7ESOSGf7pwYA5sHbklkBzFDVKSIyDkA//LBZzmhVfT7FsSrF1Nv90+y160YNXGLGBj/QIbB96uho8zFJTnsWW0uxASjoELYe2yYz8iXsGz/yYK/lZx/P3oZq0GB7I+Anpu4yY7UbBreXbj9g9nl57d1m7LJLK8eNQWEib/8Eb9m7O1T1TRE5CcAbIrLSj01S1f+MK0kiyp509norgb/boap+LiJbANTLdmJEFK8KvWcXkQIAzeHt4AoAQ0SkSETmiEjwdplEVCmkXewiciKAJQCGqepnAKbB24e2Gbxn/oeNfv1FZL2IrM88XSKKKq1iF5Fq8Ap9vqouBQBV3auq36nq9wBmAmgV1FdVZ6hqC1VtEVfSRFRxKYtdvB3hZwPYoqoTy7Xnl/u2ngi7bEtEOZfO1Fs7AH8F8DaA7/3m0QCug/cSXuHddjTAv5gXdqxKMfUWxnuhEuxrBL8TOV4CX9SkMVZyp+OZtb82Yz1az4t41C/NSOGKOwPbhw2bavbZsyViGhHsPTDXjNWpYa/JJ9VOtA8acbumuEWeelPvftCgzqFz6kRUufATdESOYLETOYLFTuQIFjuRI1jsRI5wcsHJMK+++4gZa914cGB7o5b2AoU7Qj43GHbuw+5S69lzqBnb+MlTxljv2QfEySEx24TpHc3YiEEvRTpmUm4efq4ZmznhXTM2ZuLlZuy+OyrHv5kLThI5jsVO5AgWO5EjWOxEjmCxEzmCxU7kCE69HaH+hXZsZ1HwIoUlBxeafRYu+qMZG3p92N5mrUNiB83I1pJJge2XXjrC7FO9uj1SydbNZqyo+Dkz1vQse7zKTvULM7b/H4s0/bNTxJ6WSxKn3ogcx2IncgSLncgRLHYiR7DYiRzBYidyBKfejtDr5h+ZscKZYXuiRWHvbTZhpr3f2Ij+yS3B/+rm+81Y6yY3mbEGTeoGtu9KcFHJqOb/ZaQZu77DA2asoK199+MHf7PH+9GZwe2ffWD3CcOpNyLHsdiJHMFiJ3IEi53IESx2Ikeks/1TDQCrAVSHt4PMYlUdKyJnAVgA4DQAbwD4lap+m+JYlf5qPFFVl8nV+G8AdFTVpvD2dusiIq0BPAhgkqqeDeATAPY8DBHlXMpiV0/ZPX/V/D8KoCOAxX77XAA9spEgEcUj3f3ZjxGRjQBKAawEsB3Ap6patm/lLgD1spIhEcUirWJX1e9UtRmA+gBaATgv3QFEpL+IrBeR5D72RUT/pEJX41X1UwAvAbgUwCkiUrblc30Au40+M1S1haq2yCRRIspMymIXkdoicor/+HgAVwDYAq/or/W/rS+AZ7OUIxHFIJ2pt4vgXYA7Bt4vh4WqOl5EGsKbeqsJYAOAX6rqNymOxak3oiyzpt541xvRUYZ3vRE5jsVO5AgWO5EjWOxEjmCxEzni2NTfEqu/AyhbWauW/3WuMY/DMY/DVbU8jBXtEp56O2xgkfWV4VN1zIN5uJIHX8YTOYLFTuSIXBb7jByOXR7zOBzzONxRk0fO3rMTUbL4Mp7IETkpdhHpIiJbReR9EbH32sl+HsUi8raIbExycQ0RmSMipSKyqVxbTRFZKSLv+X+fmqM8xonIbv+cbBSRKxPIo4GIvCQi74jIZhEZ6rcnek5C8kj0nIhIDRF5XUTe8vO4x28/S0Re8+umUESOq9CBVTXRP/Buld0OoCGA4wC8BaBJ0nn4uRQDqJWDcdsDuBjApnJtEwCM9B+PBPBgjvIYB+DfEz4f+QAu9h+fBGAbgCZJn5OQPBI9JwAEwIn+42oAXgPQGsBCAH389ukABlXkuLl4Zm8F4H1V3aHe0tMLAHTPQR45o6qrAew7ork7vHUDgIQW8DTySJyqlqjqm/7jz+EtjlIPCZ+TkDwSpZ7YF3nNRbHXA7Cz3Ne5XKxSAawQkTdEpH+OcihTV1VL/Md7AARvg5qMISJS5L/Mz/rbifJEpABAc3jPZjk7J0fkASR8TrKxyKvrF+jaqerFALoCGCwi7XOdEOD9Zof3iygXpgFoBG+PgBIADyc1sIicCGAJgGGq+ln5WJLnJCCPxM+JZrDIqyUXxb4bQINyX5uLVWabqu72/y4F8DS8k5ore0UkHwD8v0tzkYSq7vX/o30PYCYSOiciUg1egc1X1aV+c+LnJCiPXJ0Tf+xPUcFFXi25KPZ1AM7xryweB6APgGVJJyEieSJyUtljAJ0AbArvlVXL4C3cCeRwAc+y4vL1RALnREQEwGwAW1R1YrlQoufEyiPpc5K1RV6TusJ4xNXGK+Fd6dwO4K4c5dAQ3kzAWwA2J5kHgKfgvRw8CO+9103w9sxbBeA9AP8LoGaO8ngCwNsAiuAVW34CebSD9xK9CMBG/8+VSZ+TkDwSPScALoK3iGsRvF8sd5f7P/s6gPcBLAJQvSLH5SfoiBzh+gU6Imew2IkcwWIncgSLncgRLHYiR7DYiRzBYidyBIudyBH/D/+jNAXPzdX8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## preprocessing for mnist and svhn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(X_test)\n",
    "#print(\"----------------------------------------------------\")\n",
    "#print(x_test)\n",
    "\n",
    "\n",
    "plt.imshow(x_test_m[605]) \n",
    "#print(x_test_m[303])\n",
    "print(y_test_m[605])\n",
    "#plt.imshow(x_test[605]) \n",
    "#print(x_test[303])\n",
    "print(y_test[605])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement LeNet-5 architecture\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6,(5,5),strides=(1,1), activation='tanh',input_shape=(32,32,1))) ## 6 5x5 conv kernels\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "    model.add(Conv2D(16,(5,5),strides=(1,1), activation='tanh')) ## 16 5x5 conv kernels\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "    model.add(Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='tanh'))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(120, activation='tanh'))  #equivalent to the last conv2d above?\n",
    "    model.add(Dense(84, activation='tanh'))\n",
    "    model.add(Dense(10, activation='softmax')) # output layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe use stochastic gradient descent with\\nmomentum: 0.9\\nweight_decay: 0.0005\\n------ this was not used on mnist<->svhn tests\\nand the learning rate annealing described by the following formula:\\np =0/(1 +   p)^,\\nwhere p is the training progress linearly changing from 0\\nto 1, 0 = 0.01,  = 10 and  = 0.75 (the schedule\\nwas optimized to promote convergence and low error on\\nthe source domain).\\n------\\n\\nFollowing (Srivastava et al., 2014) we also use dropout and\\nl_2-norm restriction when we train the SVHN architecture.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## implement LeNet-5-like architecture\n",
    "def init_SVHN_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(5,5),strides=(1,1), activation='relu',input_shape=(32,32,3),kernel_constraint=max_norm(4), bias_constraint=max_norm(4),kernel_regularizer=L2(0.0005), bias_regularizer=L2(0.0005))) ## 6 5x5 conv kernels\n",
    "    model.add(Dropout(0.9))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "    model.add(Conv2D(64,(5,5),strides=(1,1), activation='relu',kernel_constraint=max_norm(4), bias_constraint=max_norm(4),kernel_regularizer=L2(0.0005), bias_regularizer=L2(0.0005))) ## 16 5x5 conv kernels\n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
    "    model.add(Conv2D(128,(5,5),strides=(1,1), activation='relu',kernel_constraint=max_norm(4), bias_constraint=max_norm(4),kernel_regularizer=L2(0.0005), bias_regularizer=L2(0.0005)))\n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3072, activation='relu',kernel_constraint=max_norm(4), bias_constraint=max_norm(4),kernel_regularizer=L2(0.0005), bias_regularizer=L2(0.0005)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2048, activation='relu',kernel_constraint=max_norm(4), bias_constraint=max_norm(4),kernel_regularizer=L2(0.0005), bias_regularizer=L2(0.0005)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax',kernel_constraint=max_norm(4), bias_constraint=max_norm(4),kernel_regularizer=L2(0.0005), bias_regularizer=L2(0.0005))) # output layer\n",
    "    \n",
    "    return model\n",
    "\n",
    "'''\n",
    "We use stochastic gradient descent with\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "------ this was not used on mnist<->svhn tests\n",
    "and the learning rate annealing described by the following formula:\n",
    "p =0/(1 +   p)^,\n",
    "where p is the training progress linearly changing from 0\n",
    "to 1, 0 = 0.01,  = 10 and  = 0.75 (the schedule\n",
    "was optimized to promote convergence and low error on\n",
    "the source domain).\n",
    "------\n",
    "\n",
    "Following (Srivastava et al., 2014) we also use dropout and\n",
    "l_2-norm restriction when we train the SVHN architecture.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement LeNet-5-like architecture\n",
    "def init_MNIST_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,(5,5),strides=(1,1), activation='relu',input_shape=(32,32,3))) ## 6 5x5 conv kernels\n",
    "    model.add(AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "    model.add(Conv2D(48,(5,5),strides=(1,1), activation='relu')) ## 16 5x5 conv kernels\n",
    "    model.add(AveragePooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax')) # output layer\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shamelessly taken from : https://stackoverflow.com/questions/47731935/using-multiple-validation-sets-with-keras\n",
    "\n",
    "## Custom callback to be able to evaluate and save the results from several validation sets during training\n",
    "class AdditionalValidationSets(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_sets, verbose=0, batch_size=None):\n",
    "        \"\"\"\n",
    "        :param validation_sets:\n",
    "        a list of 3-tuples (validation_data, validation_targets, validation_set_name)\n",
    "        or 4-tuples (validation_data, validation_targets, sample_weights, validation_set_name)\n",
    "        :param verbose:\n",
    "        verbosity mode, 1 or 0\n",
    "        :param batch_size:\n",
    "        batch size to be used when evaluating on the additional datasets\n",
    "        \"\"\"\n",
    "        super(AdditionalValidationSets, self).__init__()\n",
    "        self.validation_sets = validation_sets\n",
    "        for validation_set in self.validation_sets:\n",
    "            if len(validation_set) not in [2, 3]:\n",
    "                raise ValueError()\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "        self.verbose = verbose\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "\n",
    "        # record the same values as History() as well\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        # evaluate on the additional validation sets\n",
    "        for validation_set in self.validation_sets:\n",
    "            if len(validation_set) == 3:\n",
    "                validation_data, validation_targets, validation_set_name = validation_set\n",
    "                sample_weights = None\n",
    "            elif len(validation_set) == 4:\n",
    "                validation_data, validation_targets, sample_weights, validation_set_name = validation_set\n",
    "            else:\n",
    "                raise ValueError()\n",
    "\n",
    "            results = self.model.evaluate(x=validation_data,\n",
    "                                          y=validation_targets,\n",
    "                                          verbose=self.verbose,\n",
    "                                          sample_weight=sample_weights,\n",
    "                                          batch_size=self.batch_size)\n",
    "\n",
    "            for i, result in enumerate(results):\n",
    "                \n",
    "                if i == 0:\n",
    "                    valuename = validation_set_name + '_loss'\n",
    "                else:\n",
    "                    valuename = validation_set_name + '_' + self.model.metrics[i].name\n",
    "                self.history.setdefault(valuename, []).append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model=\"SVHN\" ,batch_size=128 ,total_epochs=25 ,iterations=1 ,x_train=[] ,y_train=[] ,x_test=[] ,y_test=[] ,x_target=[] ,y_target=[]):\n",
    "    history = AdditionalValidationSets([(x_target, y_target, 'target_val')])\n",
    "    \n",
    "    # Include the epoch in the file name (uses `str.format`)\n",
    "    checkpoint_path = \"checkpoints/\"+model+\"-cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights every 5 epochs\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "        ## tune when to save as needed for plots\n",
    "    save_freq=50*469 ### 469 = ceiling(60000/128) i.e training set for MNIST/MNIST-M\n",
    "\n",
    "   \n",
    "    histories=[]\n",
    "    M=init_SVHN_model()\n",
    "    for i in range(iterations):\n",
    "        if model==\"SVHN\":\n",
    "            M=init_SVHN_model()\n",
    "        elif model==\"MNIST\":\n",
    "            M=init_MNIST_model()\n",
    "        elif model==\"MNIST-M\":\n",
    "            M=init_MNIST_model()\n",
    "        elif model==\"2MNIST-M\":\n",
    "            M=init_MNIST_model()\n",
    "        # Save the weights using the `checkpoint_path` format\n",
    "        M.save_weights(checkpoint_path.format(epoch=0))\n",
    "        ## choose loss function, optimiser etc. and train\n",
    "        M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                      metrics=['accuracy'],)\n",
    "\n",
    "        fit_info = M.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=total_epochs,\n",
    "           verbose=1,\n",
    "           validation_data=(x_test, y_test),\n",
    "           callbacks=[history,cp_callback])\n",
    "        histories.append(history.history)\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(total_epochs,model=\"SVHN\",result=[], xlabel=\"Epoch\",save=True):#,ylabel=\"\", title=\"\"): \n",
    "    ### TODO: do one for each type of plot?\n",
    "    \n",
    "    from datetime import datetime\n",
    "\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # dd/mm/YY_H:M\n",
    "    dt_string = now.strftime(\"%d%m%Y_%H:%M\")\n",
    "    #print(\"date and time =\", dt_string)\n",
    "    \n",
    "    ## plotting and saving to disk\n",
    "    x=[i+1 for i in range(total_epochs)]\n",
    "\n",
    "    if model==\"SVHN\":\n",
    "        prefix=[\"S2MTGTACC\",\"S2MVAL\",\"S2MLOSS\",\"S2MVALLOSS\",\"S2MTGTLOSS\"]\n",
    "    elif model==\"MNIST\":\n",
    "        prefix=[\"M2STGTACC\",\"M2SVAL\",\"M2SLOSS\",\"M2SVALLOSS\",\"M2STGTLOSS\"]\n",
    "    elif model==\"MNIST-M\":\n",
    "         prefix=[\"MM2MTGTACC\",\"MM2MVAL\",\"MM2MLOSS\",\"MM2MVALLOSS\",\"MM2MTGTLOSS\"]\n",
    "    elif model==\"2MNIST-M\":\n",
    "        prefix=[\"M2MMTGTACC\",\"M2MMVAL\",\"M2MMLOSS\",\"M2MMVALLOSS\",\"M2MMTGTLOSS\"]\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot(x,result['target_val_accuracy'], '*-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    ax.legend(['Target acc'], loc = 0)\n",
    "    ax.set_title('Target acc per epoch')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/\"+prefix[0]+dt_string+\".pdf\")\n",
    "   \n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot(x,result['val_accuracy'], 'x-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    ax.legend(['Validation acc'], loc = 0)\n",
    "    ax.set_title('Validation acc per epoch')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/\"+prefix[1]+dt_string+\".pdf\")\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(x,result['loss'], 'x-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    ax.legend(['Training loss'], loc = 0)\n",
    "    ax.set_title('Training loss per epoch')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Loss')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/\"+prefix[2]+dt_string+\".pdf\")\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot(x,result['val_loss'], 'x-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    ax.legend(['Validation loss'], loc = 0)\n",
    "    ax.set_title('Validation loss per epoch')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Loss')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/\"+prefix[3]+dt_string+\".pdf\")\n",
    "    \n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot(x,result['target_val_loss'], 'x-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    ax.legend(['Target acc'], loc = 0)\n",
    "    ax.set_title('Target loss per epoch')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Loss')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/\"+prefix[4]+dt_string+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_data(sizes=[],model=\"SVHN\",result=[],save=True):# plot for the increasing amount of data\n",
    "    ### TODO: do one for each type of plot?\n",
    "    \n",
    "    from datetime import datetime\n",
    "\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    "\n",
    "    # dd/mm/YY_H:M\n",
    "    dt_string = now.strftime(\"%d%m%Y_%H:%M\")\n",
    "    #print(\"date and time =\", dt_string)\n",
    "    \n",
    "    ## plotting and saving to disk\n",
    "    x=[i+1 for i in range(total_epochs)]\n",
    "\n",
    "    if model==\"SVHN\":\n",
    "        prefix=[\"S2MTGTACC\",\"S2MVAL\",\"S2MVALLOSS\",\"S2MTGTLOSS\"]\n",
    "        target=\"MNIST\"\n",
    "    elif model==\"MNIST\":\n",
    "        prefix=[\"M2STGTACC\",\"M2SVAL\",\"M2SVALLOSS\",\"M2STGTLOSS\"]\n",
    "        target=\"SVHN\"\n",
    "    elif model==\"MNIST-M\":\n",
    "         prefix=[\"MM2MTGTACC\",\"MM2MSRCACC\",\"MM2MSRCLOSS\",\"MM2MTGTLOSS\"]\n",
    "    elif model==\"2MNIST-M\":\n",
    "        prefix=[\"M2MMTGTACC\",\"M2MMVAL\",\"M2MMLOSS\",\"M2MMVALLOSS\",\"M2MMTGTLOSS\"]\n",
    "    \n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot(sizes,aggregate_acc_t, '*-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    #ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "    ax.legend(['Target acc'], loc = 0)\n",
    "    #ax.legend(['Validation acc'], loc = 0)\n",
    "    ax.set_title('Target acc per amount of training data ('+model+'->'+target+')')\n",
    "    #ax.set_title('Validation acc per epoch')\n",
    "    ax.set_xlabel('Data amount')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/data/\"+prefix[0]+dt_string+\".pdf\")\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    #ax.plot(x,result['accuracy'], 'o-')\n",
    "    #ax.plot(x,result['val_accuracy'], 'x-')\n",
    "    ax.plot(sizes,aggregate_acc_s, '*-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    #ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "    ax.legend(['Source acc'], loc = 0)\n",
    "    #ax.legend(['Validation acc'], loc = 0)\n",
    "    ax.set_title('Source acc per amount of training data ('+model+'->'+target+')')\n",
    "    #ax.set_title('Validation acc per epoch')\n",
    "    ax.set_xlabel('Data amount')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/data/\"+prefix[1]+dt_string+\".pdf\")\n",
    "\n",
    "    f, ax = plt.subplots()\n",
    "    #ax.plot(x,result['accuracy'], 'o-')\n",
    "    #ax.plot(x,result['val_accuracy'], 'x-')\n",
    "    ax.plot(sizes,aggregate_loss_s, '*-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    #ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "    ax.legend(['Source loss'], loc = 0)\n",
    "    #ax.legend(['Validation acc'], loc = 0)\n",
    "    ax.set_title('Source loss per amount of training data ('+model+'->'+target+')')\n",
    "    #ax.set_title('Validation acc per epoch')\n",
    "    ax.set_xlabel('Data amount')\n",
    "    ax.set_ylabel('Loss')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/data/\"+prefix[2]+dt_string+\".pdf\")\n",
    "    \n",
    "    f, ax = plt.subplots()\n",
    "    #ax.plot(x,result['accuracy'], 'o-')\n",
    "    #ax.plot(x,result['val_accuracy'], 'x-')\n",
    "    ax.plot(sizes,aggregate_loss_t, '*-')\n",
    "    # Plot legend and use the best location automatically: loc = 0.\n",
    "    #ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "    ax.legend(['Target loss'], loc = 0)\n",
    "    #ax.legend(['Validation acc'], loc = 0)\n",
    "    ax.set_title('Target loss per amount of training data ('+model+'->'+target+')')\n",
    "    #ax.set_title('Validation acc per epoch')\n",
    "    ax.set_xlabel('Data amount')\n",
    "    ax.set_ylabel('Loss')\n",
    "    if(save):\n",
    "        f.savefig(\"./images/data/\"+prefix[3]+dt_string+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''### test for SVHN-> MNIST, \n",
    "total_epochs=220 #\n",
    "\n",
    "\n",
    "iterations=10\n",
    "histories=[]\n",
    "\n",
    "#histories=train_model(model=\"SVHN\",total_epochs=total_epochs,iterations=iterations,x_train=X_train,y_train=Y_train,x_test=X_test,y_test=Y_test,x_target=x_test,y_target=y_test)\n",
    "    \n",
    "histories=train_model(total_epochs=total_epochs,x_train=X_train,y_train=Y_train,x_test=X_test,y_test=Y_test,x_target=x_test,y_target=y_test)\n",
    "   \n",
    "                      \n",
    "##### Aggregating over all the training runs                    \n",
    "K=histories[0].keys()\n",
    "                \n",
    "result={}\n",
    "for key in K:\n",
    "    tmp=[]\n",
    "    for epoch in range(len(histories)):\n",
    "        tmp.append(histories[epoch][key])\n",
    "    result[key]=tmp\n",
    "\n",
    "for key in K:\n",
    "    result[key]=np.mean(result[key],axis=0)\n",
    "\n",
    "    \n",
    "## plotting and saving to disk\n",
    "plot_results(model=\"SVHN\",result=result,xlabel=\"Epoch\",total_epochs=total_epochs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''### test for MNIST->SVHN\n",
    "total_epochs=2000 #\n",
    "\n",
    "\n",
    "iterations=10\n",
    "histories=[]\n",
    "\n",
    "\n",
    "    \n",
    "histories=train_model(model=\"MNIST\",total_epochs=total_epochs,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,x_target=X_test,y_target=Y_test)\n",
    "   \n",
    "                      \n",
    "##### Aggregating over all the training runs                    \n",
    "K=histories[0].keys()\n",
    "                \n",
    "result={}\n",
    "for key in K:\n",
    "    tmp=[]\n",
    "    for epoch in range(len(histories)):\n",
    "        tmp.append(histories[epoch][key])\n",
    "    result[key]=tmp\n",
    "\n",
    "for key in K:\n",
    "    result[key]=np.mean(result[key],axis=0)\n",
    "\n",
    "    \n",
    "## plotting and saving to disk\n",
    "plot_results(model=\"MNIST\",result=result,xlabel=\"Epoch\",total_epochs=total_epochs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''### test for MNIST-M-> MNIST\n",
    "total_epochs=2000 #\n",
    "\n",
    "\n",
    "iterations=10\n",
    "histories=[]\n",
    "\n",
    "\n",
    "    \n",
    "histories=train_model(model=\"MNIST-M\",total_epochs=total_epochs,x_train=x_train_m,y_train=y_train_m,x_test=x_test_m,y_test=y_test_m,x_target=x_test,y_target=y_test)\n",
    "   \n",
    "                      \n",
    "##### Aggregating over all the training runs                    \n",
    "K=histories[0].keys()\n",
    "                \n",
    "result={}\n",
    "for key in K:\n",
    "    tmp=[]\n",
    "    for epoch in range(len(histories)):\n",
    "        tmp.append(histories[epoch][key])\n",
    "    result[key]=tmp\n",
    "\n",
    "for key in K:\n",
    "    result[key]=np.mean(result[key],axis=0)\n",
    "\n",
    "    \n",
    "## plotting and saving to disk\n",
    "plot_results(model=\"MNIST-M\",result=result,xlabel=\"Epoch\",total_epochs=total_epochs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "469/469 [==============================] - 3s 4ms/step - loss: 0.7533 - accuracy: 0.7628 - val_loss: 0.0855 - val_accuracy: 0.9724\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9eb69b1fe33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2MNIST-M\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-37c2e58d2481>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, batch_size, total_epochs, iterations, x_train, y_train, x_test, y_test, x_target, y_target)\u001b[0m\n\u001b[1;32m     33\u001b[0m                       metrics=['accuracy'],)\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         fit_info = M.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     36\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m            \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2fd020d06a3a>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             results = self.model.evaluate(x=validation_data,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1355\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                **kwargs):\n\u001b[1;32m    262\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    265\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \"\"\"\n\u001b[0;32m-> 1404\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1405\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1411\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test for MNIST-> MNIST-M\n",
    "total_epochs=200 #\n",
    "\n",
    "\n",
    "iterations=1\n",
    "histories=[]\n",
    "\n",
    "\n",
    "\n",
    "histories=train_model(model=\"2MNIST-M\",total_epochs=total_epochs,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,x_target=x_test_m,y_target=y_test_m)\n",
    "\n",
    "\n",
    "                      \n",
    "##### Aggregating over all the training runs                    \n",
    "K=histories[0].keys()\n",
    "                \n",
    "result={}\n",
    "for key in K:\n",
    "    tmp=[]\n",
    "    for epoch in range(len(histories)):\n",
    "        tmp.append(histories[epoch][key])\n",
    "    result[key]=tmp\n",
    "\n",
    "for key in K:\n",
    "    result[key]=np.mean(result[key],axis=0)\n",
    "\n",
    "    \n",
    "## plotting and saving to disk\n",
    "plot_results(model=\"2MNIST-M\",result=result,xlabel=\"Epoch\",total_epochs=total_epochs,save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### test for SVHN-> MNIST,  USING only a part of the training set\n",
    "total_epochs=200 #\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "num_runs=1\n",
    "iterations=1\n",
    "histories=[]\n",
    "prev_loss_t=[]\n",
    "prev_loss_s=[]\n",
    "prev_acc_t=[]\n",
    "prev_acc_s=[]\n",
    "N=len(X_train)\n",
    "\n",
    "for runs in range(num_runs):\n",
    "    target_acc=[]\n",
    "    target_loss=[]\n",
    "    source_acc=[]\n",
    "    source_loss=[]\n",
    "    sizes=[]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        size=round(0.001*N)*(10*i+1)\n",
    "        \n",
    "        sizes.append(size)\n",
    "         ## take out 1*i percent of the data and train\n",
    "        X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X_train,Y_train,test_size=size)\n",
    "        histories=train_model(total_epochs=total_epochs,x_train=X_test2,y_train=Y_test2,x_test=X_test,y_test=Y_test,x_target=x_test,y_target=y_test)\n",
    "        \n",
    "        # get last epochs accuracy for target\n",
    "        target_acc.append(histories[0]['target_val_accuracy'][-1])\n",
    "        target_loss.append(histories[0]['target_val_loss'][-1])\n",
    "        source_acc.append(histories[0]['val_accuracy'][-1])\n",
    "        source_loss.append(histories[0]['val_loss'][-1])\n",
    "    \n",
    "    ##### append the list of last epoch accuracies for each amount of data                    \n",
    "    ##### to the prev_runs list\n",
    "    print(target_acc)\n",
    "    prev_loss_t.append(target_loss)\n",
    "    prev_loss_s.append(source_loss)\n",
    "    prev_acc_t.append(target_acc)\n",
    "    prev_acc_s.append(source_acc)\n",
    "    \n",
    "\n",
    "### take mean over all runs\n",
    "\n",
    "aggregate_loss_t=np.mean(prev_loss_t,axis=0)\n",
    "aggregate_loss_s=np.mean(prev_loss_s,axis=0)\n",
    "aggregate_acc_t=np.mean(prev_acc_t,axis=0)\n",
    "aggregate_acc_s=np.mean(prev_acc_s,axis=0)\n",
    "\n",
    "result=[]\n",
    "result.append(aggregate_acc_t)\n",
    "result.append(aggregate_acc_s)\n",
    "result.append(aggregate_loss_s)\n",
    "result.append(aggregate_loss_t)\n",
    "\n",
    "    \n",
    "## plotting and saving to disk\n",
    "plot_results_data(sizes=sizes,result=result,save=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    "    ### test for MNIST->SVHN,  USING only a part of the training set\n",
    "total_epochs=200 #\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "num_runs=5\n",
    "iterations=15\n",
    "histories=[]\n",
    "prev_loss_t=[]\n",
    "prev_loss_s=[]\n",
    "prev_acc_t=[]\n",
    "prev_acc_s=[]\n",
    "N=len(X_train)\n",
    "\n",
    "for runs in range(num_runs):\n",
    "    target_acc=[]\n",
    "    target_loss=[]\n",
    "    source_acc=[]\n",
    "    source_loss=[]\n",
    "    sizes=[]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        size=round(0.001*N)*(10*i+1)\n",
    "        \n",
    "        sizes.append(size)\n",
    "         ## take out 1*i percent of the data and train\n",
    "        x_train2, x_test2, y_train2, y_test2 = train_test_split(x_train,y_train,test_size=size)\n",
    "        histories=train_model(model='MNIST',total_epochs=total_epochs,x_train=x_test2,y_train=y_test2,x_test=x_test,y_test=y_test,x_target=X_test,y_target=Y_test)\n",
    "        \n",
    "        # get last epochs accuracy for target\n",
    "        target_acc.append(histories[0]['target_val_accuracy'][-1])\n",
    "        target_loss.append(histories[0]['target_val_loss'][-1])\n",
    "        source_acc.append(histories[0]['val_accuracy'][-1])\n",
    "        source_loss.append(histories[0]['val_loss'][-1])\n",
    "    \n",
    "    ##### append the list of last epoch accuracies for each amount of data                    \n",
    "    ##### to the prev_runs list\n",
    "    print(target_acc)\n",
    "    prev_loss_t.append(target_loss)\n",
    "    prev_loss_s.append(source_loss)\n",
    "    prev_acc_t.append(target_acc)\n",
    "    prev_acc_s.append(source_acc)\n",
    "    \n",
    "\n",
    "### take mean over all runs\n",
    "\n",
    "aggregate_loss_t=np.mean(prev_loss_t,axis=0)\n",
    "aggregate_loss_s=np.mean(prev_loss_s,axis=0)\n",
    "aggregate_acc_t=np.mean(prev_acc_t,axis=0)\n",
    "aggregate_acc_s=np.mean(prev_acc_s,axis=0)\n",
    "\n",
    "result=[]\n",
    "result.append(aggregate_acc_t)\n",
    "result.append(aggregate_acc_s)\n",
    "result.append(aggregate_loss_s)\n",
    "result.append(aggregate_loss_t)\n",
    "\n",
    "    \n",
    "## plotting and saving to disk\n",
    "plot_results_data(model='MNIST',sizes=sizes,result=result)\n",
    "    \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''\n",
    "    ######## PLOTS for MNIST ############\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result['accuracy'], 'o-')\n",
    "#ax.plot(x,result['val_accuracy'], 'x-')\n",
    "ax.plot(x,result['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "ax.legend(['Target acc'], loc = 0)\n",
    "#ax.legend(['Validation acc'], loc = 0)\n",
    "ax.set_title('Target acc per Epoch (MNIST->SVHN)')\n",
    "#ax.set_title('Validation acc per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "#f.savefig(\"MNIST2SVHN.pdf\")\n",
    "#f.savefig(\"MNISTval.pdf\")\n",
    "\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result['accuracy'], 'o-')\n",
    "ax.plot(x,result['val_accuracy'], 'x-')\n",
    "#ax.plot(x,result['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "#ax.legend(['Target acc'], loc = 0)\n",
    "ax.legend(['Validation acc'], loc = 0)\n",
    "#ax.set_title('Target acc per Epoch (MNIST->SVHN)')\n",
    "ax.set_title('Validation acc per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "#f.savefig(\"MNIST2SVHN.pdf\")\n",
    "#f.savefig(\"MNIST2SVHNval.pdf\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result2['accuracy'], 'o-')\n",
    "ax.plot(x,result2['val_loss'], 'x-')\n",
    "#ax.plot(x,result2['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "#ax.legend(['Target acc'], loc = 0)\n",
    "ax.legend(['Validation acc'], loc = 0)\n",
    "#ax.set_title('Target acc per Epoch (SVHN->MNIST)')\n",
    "ax.set_title('Training loss per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "#f.savefig(\"SVHN2MNIST.pdf\")\n",
    "#f.savefig(\"MNIST2SVHNloss.pdf\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result2['accuracy'], 'o-')\n",
    "ax.plot(x,result2['val_loss'], 'x-')\n",
    "#ax.plot(x,result2['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "#ax.legend(['Target acc'], loc = 0)\n",
    "ax.legend(['Validation acc'], loc = 0)\n",
    "#ax.set_title('Target acc per Epoch (SVHN->MNIST)')\n",
    "ax.set_title('Validation loss per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "#f.savefig(\"SVHN2MNIST.pdf\")\n",
    "#f.savefig(\"MNIST2SVHNvalloss.pdf\")\n",
    "\n",
    "\n",
    "############SVHN PLOTS ############ \n",
    "\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result2['accuracy'], 'o-')\n",
    "#ax.plot(x,result2['val_accuracy'], 'x-')\n",
    "ax.plot(x,result2['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "ax.legend(['Target acc'], loc = 0)\n",
    "#ax.legend(['Validation acc'], loc = 0)\n",
    "ax.set_title('Target acc per Epoch (SVHN->MNIST)')\n",
    "#ax.set_title('Validation acc per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "#f.savefig(\"SVHN2MNIST.pdf\")\n",
    "#f.savefig(\"SVHN2MNISTval.pdf\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result2['accuracy'], 'o-')\n",
    "ax.plot(x,result2['val_accuracy'], 'x-')\n",
    "#ax.plot(x,result2['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "#ax.legend(['Target acc'], loc = 0)\n",
    "ax.legend(['Validation acc'], loc = 0)\n",
    "#ax.set_title('Target acc per Epoch (SVHN->MNIST)')\n",
    "ax.set_title('Validation acc per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "#f.savefig(\"SVHN2MNIST.pdf\")\n",
    "#f.savefig(\"SVHN2MNISTval.pdf\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result2['accuracy'], 'o-')\n",
    "ax.plot(x,result2['val_loss'], 'x-')\n",
    "#ax.plot(x,result2['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "#ax.legend(['Target acc'], loc = 0)\n",
    "ax.legend(['Validation acc'], loc = 0)\n",
    "#ax.set_title('Target acc per Epoch (SVHN->MNIST)')\n",
    "ax.set_title('Training loss per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "#f.savefig(\"SVHN2MNIST.pdf\")\n",
    "#f.savefig(\"SVHN2MNISTloss.pdf\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "#ax.plot(x,result2['accuracy'], 'o-')\n",
    "ax.plot(x,result2['val_loss'], 'x-')\n",
    "#ax.plot(x,result2['target_val_accuracy'], '*-')\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "#ax.legend(['Train acc', 'Validation acc','Target acc'], loc = 0)\n",
    "#ax.legend(['Target acc'], loc = 0)\n",
    "ax.legend(['Validation acc'], loc = 0)\n",
    "#ax.set_title('Target acc per Epoch (SVHN->MNIST)')\n",
    "ax.set_title('Validation loss per epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "#f.savefig(\"SVHN2MNIST.pdf\")\n",
    "#f.savefig(\"SVHN2MNISTvalloss.pdf\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
