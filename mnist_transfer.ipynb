{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#### Keras implementation of NN's which we will look at MNIST with\n",
    "\n",
    "from __future__ import print_function\n",
    "#import keras as keras \n",
    "import tensorflow as tf\n",
    "#import scipy\n",
    "#import h5py\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "#svhn_path=\"../Datasets/svhn\"#\"/Home/Adam/Research/Datasets/svhn\"\n",
    "\n",
    "# Hyper-parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "## where did you put mnist_transfer\n",
    "path_to_root_file=\"/home/adam/Code/\"\n",
    "### making sure that we have the GPU to work on\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "  # I do not know why I have to do this but gpu does not work otherwise.\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, variance 0.36348352 70.18035\n",
      "---------------Load MNIST----------------\n",
      "Training set (60000, 32, 32, 3) (60000, 10)\n",
      "Test set (10000, 32, 32, 3) (10000, 10)\n",
      "\n",
      "\n",
      "mean, variance 1.1809415 74.36859\n",
      "---------------Load MNIST-M----------------\n",
      "Training set (60000, 32, 32, 3) (60000, 10)\n",
      "Test set (10000, 32, 32, 3) (10000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "### load module, and also MNIST/MNIST-M\n",
    "from importlib.machinery import SourceFileLoader\n",
    "mymodule = SourceFileLoader('mnistm', path_to_root_file+'mnist_transfer/data/mnist_m.py').load_module()\n",
    "mymodule2 = SourceFileLoader('mnist', path_to_root_file+'mnist_transfer/data/mnist.py').load_module()\n",
    "import mnistm\n",
    "import mnist\n",
    "x_train, y_train, x_test, y_test = mnist.load_mnist()\n",
    "x_train_m, y_train_m, x_test_m, y_test_m = mnistm.load_mnistm(y_train,y_test)\n",
    "\n",
    "\n",
    "### load module\n",
    "from importlib.machinery import SourceFileLoader\n",
    "mymodule = SourceFileLoader('label_shift', path_to_root_file+'mnist_transfer/data/label_shift.py').load_module()\n",
    "\n",
    "from label_shift import *\n",
    "    \n",
    "######### Here we use the functions from label_shift ##############################################################\n",
    "\n",
    "###### Add train and test together and shift the distributions to create source and target distributions\n",
    "### MNIST all data\n",
    "x_full=np.append(x_train,x_test, axis=0)\n",
    "y_full=np.append(y_train,y_test, axis=0)\n",
    "### MNIST-M all data\n",
    "x_full_m=np.append(x_train_m,x_test_m, axis=0)\n",
    "y_full_m=np.append(y_train_m,y_test_m, axis=0)\n",
    "#x_shift,y_shift,x_shift_target,y_shift_target =label_shift(x_train,y_train,1/2,7)\n",
    "x_shift, y_shift, x_shift_target, y_shift_target =label_shift_linear(x_full,y_full,1/12,[0,1,2,3,4,5,6,7,8,9])\n",
    "x_shift_m, y_shift_m,x_shift_target_m, y_shift_target_m=label_shift_linear(x_full_m,y_full_m,1/12,[0,1,2,3,4,5,6,7,8,9],decreasing=False)\n",
    "\n",
    "plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_shift_target,\"shifted, target\")\n",
    "plot_labeldist([0,1,2,3,4,5,6,7,8,9],y_shift,\"shifted, source\")\n",
    "plot_splitbars([0,1,2,3,4,5,6,7,8,9],y_shift,y_shift_m,\"MNIST, source\",\"MNIST-M, source\")\n",
    "plot_splitbars([0,1,2,3,4,5,6,7,8,9],y_shift_target,y_shift_target_m,\"MNIST, target\",\"MNIST-M, target\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.986111, 5.0, 2.999428, 1.99958, 1.399789, 1.0, 0.71435696, 0.5, 0.33346358, 0.20003448], [0.09088036, 0.19987813, 0.33326975, 0.5, 0.7143216, 1.0, 1.4001397, 2.0, 3.0, 5.0025883]]\n"
     ]
    }
   ],
   "source": [
    "##### Add the label shifted datasets to each other creating the source and target domain for task 2\n",
    "\n",
    "##### calculate the label densities here\n",
    "densities=[]\n",
    "densities.append(np.sum(y_shift,axis=0))\n",
    "densities.append(np.sum(y_shift_m,axis=0))\n",
    "densities.append(np.sum(y_shift_target,axis=0))\n",
    "densities.append(np.sum(y_shift_target_m,axis=0))\n",
    "# mnist source, mnist-m source, mnist target,  mnist-m target\n",
    "#print(densities)\n",
    "TASK=2\n",
    "if TASK==1:\n",
    "    x_source=x_shift\n",
    "    y_source=y_shift\n",
    "    x_target=x_shift_target\n",
    "    y_target=y_shift_target\n",
    "elif TASK==2:\n",
    "    L=len(densities[0])\n",
    "    interdomain_densities = [[] for x in range(2)]\n",
    "    for i in range(L):\n",
    "        ## all densities are # in mnist over # in mnist-m\n",
    "        interdomain_densities[0].append(densities[0][i]/densities[1][i])\n",
    "        interdomain_densities[1].append(densities[2][i]/densities[3][i])\n",
    "    print(interdomain_densities)\n",
    "    x_source=np.append(x_shift,x_shift_m, axis=0)\n",
    "    y_source=np.append(y_shift,y_shift_m, axis=0)\n",
    "    x_target=np.append(x_shift_target,x_shift_target_m, axis=0)\n",
    "    y_target=np.append(y_shift_target,y_shift_target_m, axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## testing images and such\n",
    "\n",
    "\n",
    "\n",
    "#print(X_test)\n",
    "#print(\"----------------------------------------------------\")\n",
    "#print(x_test)\n",
    "\n",
    "#print(make_mnist_binary(y_train))\n",
    "#plt.imshow(x_test_m[605]) \n",
    "#print(x_test_m[303])\n",
    "#print(y_test_m[605])\n",
    "#plt.imshow(x_test[605]) \n",
    "#print(x_test[303])\n",
    "#print(y_test[605])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def flatten_images(x_train,x_train_m):\n",
    "    ### flatten images into vectors to be able to compute MMD\n",
    "    mnist_flat=[None]*len(x_train)\n",
    "    mnistm_flat=[None]*len(x_train)\n",
    "    for i in range(len(x_train)):\n",
    "        mnist_flat[i]=tf.reshape(x_train[i],[-1])\n",
    "        mnistm_flat[i]=tf.reshape(x_train_m[i],[-1])\n",
    "    #print(np.array(mnist_flat).shape)\n",
    "    #print(np.array(mnistm_flat).shape)\n",
    "    return mnist_flat, mnistm_flat\n",
    "mnist_flat, mnistm_flat=flatten_images(x_train,x_train_m)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=[4.03175373e-01 9.51696495e-01 6.17701393e-01 9.47211392e-01\n",
      " 5.30300482e-01 9.91062275e-01 8.00564380e-01 4.06917777e-03\n",
      " 2.76502659e-01 4.89856122e-02 3.67845384e-02 1.27117418e-05\n",
      " 6.48640390e-02 2.31980995e-01 3.93689698e-01 3.42871875e-03\n",
      " 4.29839079e-02 9.99941871e-01 7.04050169e-01 5.06259134e-01\n",
      " 9.23253550e-01 9.12236518e-01 2.43997738e-01 3.36189907e-02\n",
      " 7.24770280e-01 1.97197142e-02 3.29385389e-01 6.56565185e-01\n",
      " 3.70047350e-03 4.57224025e-01 2.88979573e-01 7.16348408e-02\n",
      " 2.28561426e-01 5.71252271e-01 9.71181766e-01 9.51823405e-01\n",
      " 4.63863259e-01 8.84484797e-01 4.97424841e-02 9.67594142e-01\n",
      " 7.93808979e-01 2.05012499e-01 9.85547234e-01 5.35515745e-01\n",
      " 1.21097317e-01 5.87788082e-01 1.09559886e-03 1.96905665e-04\n",
      " 7.99649122e-01 4.72160101e-01]\n",
      "B=[1.05145541e-002 1.15083026e-014 5.70213389e-005 1.81266144e-022\n",
      " 3.29335323e-025 1.85832547e-002 4.31913285e-018 1.13365188e-140\n",
      " 2.09742973e-014 5.75535727e-004 2.46778120e-001 1.16777738e-001\n",
      " 5.49089099e-009 9.25057115e-003 3.16255338e-061 6.74958586e-001\n",
      " 2.10850147e-028 1.03401262e-015 3.21174290e-002 9.01437971e-014\n",
      " 2.21278336e-026 9.99740266e-001 6.79865897e-040 8.34216196e-001\n",
      " 6.21543627e-001 4.12806828e-001 3.43301566e-004 9.27246576e-001\n",
      " 1.46702511e-042 9.59114938e-001 1.07722569e-010 1.23385414e-034\n",
      " 1.39167324e-007 5.63137194e-005 6.58436610e-005 1.56161588e-068\n",
      " 2.71392462e-022 1.33592062e-010 3.66211726e-004 3.34961216e-041\n",
      " 3.71682966e-014 4.04267747e-001 3.98129191e-002 9.21692888e-001\n",
      " 3.75753605e-010 3.79696772e-002 1.07529866e-013 1.82418459e-013\n",
      " 3.46523742e-006 2.19708120e-013]\n",
      "C=[-9.87791823e-01 -9.77395668e-06 -3.79970599e-01 -2.64396374e-03\n",
      " -4.78720726e-01 -7.23993012e-01 -3.67379255e-13 -6.66651635e-27\n",
      " -4.90167647e-01 -3.07033907e-13 -1.31225968e-11 -4.98051425e-03\n",
      " -7.15077125e-09 -1.68721146e-01 -7.66662067e-08 -2.04872683e-01\n",
      " -4.59069273e-01 -5.62376899e-12 -2.39162213e-01 -5.69902323e-01\n",
      " -1.33686671e-22 -9.70597230e-01 -6.71076932e-20 -2.63539377e-09\n",
      " -3.29618844e-06 -1.87432647e-07 -2.09011333e-01 -4.88751192e-01\n",
      " -9.25051333e-55 -3.31010319e-08 -7.61531523e-17 -1.05504129e-19\n",
      " -3.28954554e-03 -1.44818194e-03 -3.49879677e-12 -1.54728451e-21\n",
      " -3.56523094e-11 -4.77397702e-01 -1.77861023e-07 -5.14952790e-27\n",
      " -8.12029587e-02 -3.03687524e-01 -8.31029974e-03 -4.10422747e-01\n",
      " -9.65618580e-01 -3.31345481e-08 -1.39289310e-09 -1.06410058e-02\n",
      " -3.74159267e-01 -1.37603497e-12]\n",
      "D=[-3.18036696e-01 -1.51826413e-02 -1.22770577e-01 -4.91131360e-11\n",
      " -1.31749809e-15 -8.48053823e-04 -1.24304874e-01 -1.98237299e-27\n",
      " -1.84133619e-06 -4.45181236e-01 -1.79213921e-02 -2.28126484e-08\n",
      " -5.86069118e-02 -5.29642565e-03 -9.38107238e-34 -1.22276238e-08\n",
      " -6.25899783e-35 -5.46853681e-01 -2.37747702e-03 -3.93140739e-14\n",
      " -9.10405204e-01 -9.87041474e-01 -6.26089465e-02 -1.20982238e-15\n",
      " -1.36238717e-06 -3.76233521e-21 -1.00659525e-03 -4.36549655e-02\n",
      " -1.08449242e-06 -8.51660447e-05 -2.92417833e-03 -6.95773386e-01\n",
      " -3.04554696e-12 -1.75345702e-01 -5.38274948e-29 -3.68149439e-13\n",
      " -2.01538793e-01 -3.17747038e-06 -6.95311698e-01 -1.46417580e-02\n",
      " -4.92817941e-06 -1.83761977e-05 -7.67905869e-01 -1.22714862e-01\n",
      " -5.89688642e-18 -7.42674787e-02 -6.31397004e-02 -1.88606600e-17\n",
      " -1.31350490e-02 -3.39790191e-01]\n",
      "-------------------------------------------------------------\n",
      "0.28472674642368206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([-0.21527325, -0.16527325, -0.11527325, -0.06527325, -0.01527325,\n",
       "         0.03472675,  0.08472675,  0.13472675,  0.18472675,  0.23472675,\n",
       "         0.28472675,  0.33472675,  0.38472675,  0.43472675,  0.48472675,\n",
       "         0.53472675,  0.58472675,  0.63472675,  0.68472675,  0.73472675,\n",
       "         0.78472675]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "def mmd_rbf_linear(x,y,sigma_square):\n",
    "    from sklearn import metrics\n",
    "    \"\"\"\n",
    "    Here we want to compute the unbiased estimate of the MMD in linear time using the formula\n",
    "    MMD^2_k(p,q)=2/n_s for i=1 to n_s/2 g_k(z_i)\n",
    "    ,where z_i=(x^s_2i-1,x^s_2i,x^t_2i-1,x^t_2i) and\n",
    "    g_k(z_i)= k(x^s_2i-1,x^s_2i)+k(x^t_2i-1,x^t_2i)-k(x^s_2i-1,x^t_2i)-k(x^s_2i,x^t_2i-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_s=len(x)\n",
    "    n=round(n_s/2.0)\n",
    "    if x.ndim==1 or y.ndim==1:\n",
    "        x=x.reshape(-1, 1)\n",
    "        y=y.reshape(-1, 1)\n",
    "    \n",
    "    ##take out odd and even entries for the two vectors\n",
    "    x_even=x[:n_s:2]\n",
    "    x_odd=x[1:n_s:2]\n",
    "    y_even=y[:n_s:2]\n",
    "    y_odd=y[1:n_s:2]\n",
    "    \n",
    "    #sys.exit(-1)\n",
    "    #print(\"New computation\")\n",
    "    #print(np.mean(kernel(x[:n:2], x[1:n:2],sigma_square) + kernel(y[:n:2], y[1:n:2],sigma_square)\n",
    "       #   - kernel(x[:n:2], y[1:n:2],sigma_square) -kernel(x[1:n:2], y[:n:2],sigma_square)))\n",
    "      \n",
    "    mmd=0\n",
    "    A=kernel2(x[:n:2], x[1:n:2],sigma_square) \n",
    "    B= kernel2(y[:n:2], y[1:n:2],sigma_square)\n",
    "    C=- kernel2(x[:n:2], y[1:n:2],sigma_square)\n",
    "    D=-kernel2(x[1:n:2], y[:n:2],sigma_square)\n",
    "    mmd=np.mean(A+B+C+D)\n",
    "    print(\"A=\"+str(A))\n",
    "    print(\"B=\"+str(B))\n",
    "    print(\"C=\"+str(C))\n",
    "    print(\"D=\"+str(D))\n",
    "    #metrics.pairwise.rbf_kernel\n",
    "    #mmd=kernel(x_even,x_odd,sigma_square)+kernel(y_even,y_odd,sigma_square)-kernel(x_even,y_odd,sigma_square)-kernel(y_even,x_odd,sigma_square)\n",
    "    #print(\"old computation\")\n",
    "    #print(np.mean(mmd))\n",
    "    #print(mmd.shape)\n",
    "    #print(mmd)\n",
    "    #mmd=mmd*(2/n_s)\n",
    "    '''\n",
    "    for i in range(n):\n",
    "        ### sum the kernels for the chosen pairs\n",
    "        mmd+=kernel(x_even[i],x_odd[i],sigma_square)\n",
    "        mmd+=kernel(y_even[i],y_odd[i],sigma_square)\n",
    "        mmd-=kernel(x_even[i],y_odd[i],sigma_square)\n",
    "        mmd-=kernel(y_even[i],x_odd[i],sigma_square)\n",
    "    mmd=mmd*(2/n_s)\n",
    "    '''\n",
    "    \n",
    "    return mmd.mean()\n",
    "def kernel(x,y,sigma_square):\n",
    "    return np.exp(-(1/(2*sigma_square)) * ((x - y) ** 2).sum(axis=1))\n",
    "def kernel2(x,y,sigma_square):\n",
    "    return np.exp(-np.sum(np.square(x-y),axis=1)/(2*sigma_square))\n",
    "\n",
    "\n",
    "\n",
    "def mmd_rbf2(X, Y, sigma=0):\n",
    "    # n = (T.smallest(X.shape[0], Y.shape[0]) // 2) * 2\n",
    "    import theano.tensor as T\n",
    "    X=X.reshape(-1, 1)\n",
    "    Y=Y.reshape(-1, 1)\n",
    "    n = (X.shape[0] // 2) * 2\n",
    "    gamma = 1 / (2 * sigma**2)\n",
    "    rbf = lambda A, B: T.exp(-gamma * ((A - B) ** 2).sum(axis=1))\n",
    "    mmd2 = (rbf(X[:n:2], X[1:n:2]) + rbf(Y[:n:2], Y[1:n:2])\n",
    "          - rbf(X[:n:2], Y[1:n:2]) - rbf(X[1:n:2], Y[:n:2])).mean()\n",
    "   \n",
    "    return mmd2\n",
    "def mmd_rbf(x,y,sigma_square):\n",
    "    from sklearn import metrics\n",
    "    #### if needed for one dimensional data\n",
    "    if x.ndim==1 or y.ndim==1:\n",
    "        x=x.reshape(-1, 1)\n",
    "        y=y.reshape(-1, 1)\n",
    "    XX = metrics.pairwise.rbf_kernel(x, x, 1/sigma_square)\n",
    "    YY = metrics.pairwise.rbf_kernel(y, y, 1/sigma_square)\n",
    "    XY = metrics.pairwise.rbf_kernel(x, y, 1/sigma_square)\n",
    "    A=np.diag(XX,1)\n",
    "    B=np.diag(YY,1)\n",
    "    C=-np.diag(XY,1)\n",
    "    D=-np.diag(XY,1)\n",
    "    print(\"A=\"+str(A))\n",
    "    print(\"B=\"+str(B))\n",
    "    print(\"C=\"+str(C))\n",
    "    print(\"D=\"+str(D))\n",
    "    \n",
    "    return (np.diag(XX,1)+np.diag(YY,1)-np.diag(XY,1)-np.diag(XY,1)).mean()#XX.mean() + YY.mean() - 2 * XY.mean()\n",
    "\n",
    "    #return np.exp(-np.sum(np.square(x-y))/(2*sigma_square))#*1/(np.sqrt(2*math.pi*sigma_square))\n",
    "#print(kernel(np.array(mnist_flat[0]),np.array(mnistm_flat[0])))\n",
    "#mmd_linear(mnist_flat,mnistm_flat)\n",
    "##### do this for a range of sigma and sum the results for an estimation of the true MMD\n",
    "\n",
    "sigmas = [\n",
    "      1e-6, 1e-5, \n",
    "      1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100,\n",
    "      1e3, 1e4, 1e5, 1e6\n",
    "  ]\n",
    "\n",
    "mmdlist=[]\n",
    "\n",
    "\n",
    "#### generate data from two gaussian distributions with different mean and compute mmd?\n",
    "#x=[1,2,3,4]\n",
    "#y=[4,4,4,4]\n",
    "#print(mmd_linear(x,y,1e5))\n",
    "'''\n",
    "for sigma in sigmas:\n",
    "    mmdlist.append(mmd_rbf(mnist_flat[:1000],mnistm_flat[:1000],sigma))\n",
    "print(mmdlist)\n",
    "finalmmd=np.sqrt(np.sum(mmdlist))\n",
    "print(finalmmd)\n",
    "#### test with normal dist\n",
    "'''\n",
    "MMDsq=[]\n",
    "MMDsq2=[]\n",
    "for i in range(1):\n",
    "    samples = np.random.normal(0, 1, 200);\n",
    "    samples2= np.random.normal(0,3*np.sqrt(2), 200);\n",
    "    #MMDsq.append(mmd_rbf(mnist_flat,mnistm_flat,0.5))\n",
    "    #mmds=[]\n",
    "    #for sigma in sigmas:\n",
    "            #mmds.append(mmd_rbf_linear(samples,samples2,sigma))\n",
    "    MMDsq.append(mmd_rbf_linear(samples,samples2,0.5))\n",
    "    #MMDsq2.append(mmd_rbf(samples,samples2,0.5))\n",
    "    #MMDsq.append(np.sum(mmds))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "#print(MMDsq)\n",
    "print(np.mean(MMDsq))\n",
    "#for i in MMDsq:\n",
    "#    mmdlist.append(i.eval())\n",
    "#print(mmdlist)\n",
    "plt.hist(MMDsq,bins=20)#,density=True);\n",
    "#plt.xlim([0.05,0.4])\n",
    "#print(MMDsq[1].eval())\n",
    "#plt.hist(MMDsq,bins=20);\n",
    "### mnist vs mnistm: 0.5367568640253743\n",
    "\n",
    "### label shift:\n",
    "\n",
    "\n",
    "#mymodule = SourceFileLoader('kl', path_to_root_file+'mnist_transfer/util/kl.py').load_module()\n",
    "#import kl\n",
    "#print(kl.estimate_KL(samples,samples2,1))\n",
    "#### KL with N(0,1) vs N(5,1): ~13000 expected 12500 on average so seems about right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "### load module\n",
    "mymodule = SourceFileLoader('train', path_to_root_file+'mnist_transfer/experiments/training.py').load_module()\n",
    "mymodule2 = SourceFileLoader('kl', path_to_root_file+'mnist_transfer/util/kl.py').load_module()\n",
    "mymodule3 = SourceFileLoader('util', path_to_root_file+'mnist_transfer/util/misc.py').load_module()\n",
    "mymodule4 = SourceFileLoader('SL', path_to_root_file+'mnist_transfer/experiments/SL_bound.py').load_module()\n",
    "from kl import *\n",
    "from train import *\n",
    "from util import *\n",
    "from SL import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import gc\n",
    "import re\n",
    "\n",
    "def read_weights(model,w_a,x_bound,y_bound,x_target,y_target,epochs_trained,sigma,epsilon,alpha,Binary=False,Task=TASK):\n",
    "    \n",
    "    epoch=1\n",
    "    KLs=[]\n",
    "    errors=[]\n",
    "    targeterrors=[]\n",
    "    epochs=[]\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])    \n",
    "    ### Here we do something more intelligent to not have to hardcode the epoch amounts. \n",
    "    ### we parse the filenames and sort them in numerical order and then load the weights\n",
    "    if Binary:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "    else:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "        \n",
    "    #epochs = [] #list of \n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    dirFiles = os.listdir(path) #list of directory files\n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non jpgs\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            ### if it has a one it goes in one list and if it starts with a two it goes in the other\n",
    "            if (name[0]==\"1\"):\n",
    "                list1.append(name)\n",
    "            elif (name[0]==\"2\"):\n",
    "                list2.append(name)\n",
    "            #epochs.append(name)\n",
    "    #epochs.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    num_batchweights=len(list1)\n",
    "    list2.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.extend(list2)\n",
    "    Ws=list1 ## vector of checkpoint filenames\n",
    "    #print(Ws)\n",
    "    #sys.exit(-1)\n",
    "    #epochs=[int(i) for i in Ws]\n",
    "    Xvector=[]\n",
    "    for i in Ws:\n",
    "        #print(i)\n",
    "        if i[0]==\"1\":\n",
    "            if i[1]==\"_\":\n",
    "                Xvector.append(int(i[2:]))\n",
    "    for i in list2:\n",
    "        Xvector.append((int(i[2:])+1)*547)\n",
    "    #print(Xvector)\n",
    "    \n",
    "    \n",
    "    path=\"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"/\"#+\"/{epoch:0d}.ckpt\"\n",
    "    if Binary:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"/\"#+\"/{epoch:0d}.ckpt\"\n",
    "    for checkpoint in Ws:\n",
    "        if Binary:\n",
    "            model=init_MNIST_model_binary()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        else:\n",
    "            model=init_MNIST_model()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        model.load_weights(path+str(checkpoint)+\".ckpt\").expect_partial()\n",
    "        w_s=model.get_weights()\n",
    "        \n",
    "        ##### here we should draw two classifiers and pass that on to the KL and calculate the training error\n",
    "        \n",
    "        t = time.time()\n",
    "        ## do some draws of the posterior\n",
    "        w_s_draws=draw_classifier(w_s,sigma,num_classifiers=2)\n",
    "        ## do some draws of the prior\n",
    "        if w_a is not None:\n",
    "            w_a_draws=draw_classifier(w_a,sigma,num_classifiers=2)\n",
    "        else:\n",
    "            print(\"Error: No prior weights were supplied!\")\n",
    "            sys.exit(-1)\n",
    "          \n",
    "        elapsed = time.time() - t\n",
    "        print(\"Time spent drawing the classifiers: \"+str(elapsed)+\"\\n\")\n",
    "   \n",
    "    \n",
    "        \n",
    "        ###### for each pair of drawn prior and posterior we calculate the necessary parts of the bound \n",
    "        ###### and then average the result and return that\n",
    "        k=0\n",
    "        l=0\n",
    "        errorsum=0\n",
    "        target_errorsum=0\n",
    "        KLsum=0\n",
    "        \n",
    "        for i in w_s_draws:\n",
    "            model.set_weights(i)\n",
    "            errorsum=((1-model.evaluate(x_bound,y_bound,verbose=0)[1])+errorsum*k)/(k+1)\n",
    "            target_errorsum=((1-model.evaluate(x_target,y_target,verbose=0)[1])+target_errorsum*k)/(k+1)\n",
    "            k+=1\n",
    "            for j in w_a_draws:\n",
    "                ## calculate the KL component\n",
    "                KLsum=(estimate_KL(j,i,sigma)+KLsum*l)/(l+1)\n",
    "                l+=1\n",
    "        print(\"Iteration done with sigma:\"+str(sigma)+\" and epsilon:\"+str(epsilon))\n",
    "        KLs.append(KLsum)\n",
    "        targeterrors.append(target_errorsum)\n",
    "        errors.append(errorsum)\n",
    "        ## this is needed because keras is bad and leaks memory; Or I am dumb and cannot see what I am doing wrong\n",
    "        del model\n",
    "        _ = gc.collect()\n",
    "    \n",
    "    #print(\"we made it here!!!!\")\n",
    "    #sys.exit(-1)\n",
    "    \n",
    "    return KLs,errors,targeterrors,Ws,Xvector\n",
    "\n",
    "class stop_callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='accuracy', value=0.001, verbose=0):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy')> self.value): # select the accuracy\n",
    "            print(\"\\n !!! training error threshold reached, no further training !!!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "class fast_checkpoints(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,checkpoint_path,save_freq):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.save_freq=save_freq\n",
    "        #self.bat=45\n",
    "        self.filepath=checkpoint_path#+\"/\"+str(self.bat)+\".ckpt\"\n",
    "        self.verbose=1\n",
    "        self.save_best_only=False\n",
    "        self.save_weights_only=True\n",
    "    def on_train_batch_begin(self, batch, epoch, logs=None):\n",
    "        if batch==0:\n",
    "            self.model.save_weights(self.filepath+\"/1_\"+str(batch)+\".ckpt\")\n",
    "    def on_train_batch_end(self, batch, epoch, logs=None):\n",
    "        if batch%self.save_freq==0 and batch!=0:\n",
    "            print(\"\\n Saved weights after \"+str(batch)+\" batches \\n\")\n",
    "            #self.filepath=batch\n",
    "            #print()\n",
    "            #print(self.filepath+\"/1_\"+str(batch)+\".ckpt\")\n",
    "            self.model.save_weights(self.filepath+\"/1_\"+str(batch)+\".ckpt\")\n",
    "def train_posterior(alpha,x_train,y_train,prior_weights=None,x_test=[],y_test=[],save=True,epsilon=0.01,Task=2,Binary=False):\n",
    "        #global TASK\n",
    "        TASK=Task\n",
    "        batch_size=128\n",
    "        ### x_test should be the whole of S for early stopping purposes\n",
    "        \"\"\"\n",
    "        takes the prior weights, if any, and trains so we get a posterior.\n",
    "        \"\"\"\n",
    "        # Include the epoch in the file name (uses `str.format`)\n",
    "        checkpoint_path = \"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))#+\"/{}_{epoch:0d}.ckpt\"\n",
    "        if Binary:\n",
    "            checkpoint_path = \"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))#+\"/{epoch:0d}.ckpt\"\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "        \n",
    "        # Create a callback that saves the model's weights every 50 epochs\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        save_freq=547,   ### 547 = ceiling(70000/128) i.e training set for MNIST/MNIST-M,\n",
    "        filepath=checkpoint_path+\"/2_{epoch:0d}.ckpt\", \n",
    "        verbose=1,\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True,\n",
    "            ## tune when to save as needed for plots\n",
    "        )\n",
    "        fast_cp_callback =fast_checkpoints(checkpoint_path,45)\n",
    "     \n",
    "    \n",
    "        if Binary:\n",
    "            M=init_MNIST_model_binary()\n",
    "        else:\n",
    "            M=init_MNIST_model()\n",
    "\n",
    "        \n",
    "            \n",
    "        ## choose loss function, optimiser etc. and train\n",
    "        \n",
    "        M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        ### load the prior weights\n",
    "        if prior_weights is not None:\n",
    "            M.set_weights(prior_weights)\n",
    "        elif(alpha==0):\n",
    "            ### do nothing\n",
    "            pass\n",
    "        else:\n",
    "            if Binary:\n",
    "                prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "                M.load_weights(prior_path).expect_partial()\n",
    "            else:\n",
    "                prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "                M.load_weights(prior_path).expect_partial()\n",
    "        stopping_callback=stop_callback(monitor='val_acc',value=1-epsilon)\n",
    "    \n",
    "        if save:\n",
    "            CALLBACK=[fast_cp_callback,stopping_callback]\n",
    "        else:\n",
    "            CALLBACK=[stopping_callback]\n",
    "        ###### experimental, to see if we can do more saving before the first epoch\n",
    "        fit_info = M.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=1, \n",
    "           callbacks=CALLBACK,\n",
    "           validation_data=(x_test, y_test),\n",
    "           verbose=1,\n",
    "                        )\n",
    "        if save:\n",
    "            CALLBACK=[cp_callback,stopping_callback]\n",
    "        else:\n",
    "            CALLBACK=[stopping_callback]\n",
    "        fit_info = M.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           epochs=2000, # we should have done early stopping before this completes\n",
    "           callbacks=CALLBACK,\n",
    "           validation_data=(x_test, y_test),\n",
    "           verbose=1,\n",
    "                        )\n",
    "         #### save the last posterior weights to disk\n",
    "        epochs_trained=len(fit_info.history['loss'])\n",
    "        if save:\n",
    "            M.save_weights(checkpoint_path+\"/2_\"+str(epochs_trained)) ###### check if we need this; TODO!!!!!!\n",
    "        #### save textfile with parameters, i.e. alpha ,epochs trained and epsilon\n",
    "        if Binary:\n",
    "            with open('posteriors/'+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'w') as f:\n",
    "                f.write('\\n'.join([str(alpha), str(epsilon), str(epochs_trained)]))     \n",
    "            f.close()\n",
    "        else:\n",
    "            with open('posteriors/'+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'w') as f:\n",
    "                f.write('\\n'.join([str(alpha), str(epsilon), str(epochs_trained)]))     \n",
    "            f.close()\n",
    "        W=M.get_weights()\n",
    "        return W#, fit_info.history['val_accuracy'] ## should it be accuracy on train here? \n",
    "    \n",
    "def train_prior(alpha,total_epochs,x_train=[],y_train=[],x_target=[],y_target=[],save=True,Task=2,Binary=False):\n",
    "    #global TASK\n",
    "    TASK=Task\n",
    "    # Include the epoch in the file name (uses `str.format`)\n",
    "    checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))#+\"/prior.ckpt\"\n",
    "\n",
    "    #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    if Binary:\n",
    "        M=init_MNIST_model_binary()\n",
    "        checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))#+\"/prior.ckpt\"\n",
    "    else:\n",
    "        M=init_MNIST_model()\n",
    "    fast_cp_callback =fast_checkpoints(checkpoint_path,10)\n",
    "    if save:\n",
    "            CALLBACK=[fast_cp_callback]\n",
    "    else:\n",
    "            CALLBACK=[]\n",
    "        ## choose loss function, optimiser etc. and train\n",
    "    M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "    fit_info = M.fit(x_train, y_train,\n",
    "           batch_size=batch_size,\n",
    "           callbacks=CALLBACK,\n",
    "           epochs=total_epochs,\n",
    "           verbose=1,\n",
    "                        )\n",
    "    #### save the final prior weights to disk\n",
    "    if save:\n",
    "        M.save_weights(checkpoint_path+\"/prior.ckpt\")\n",
    "    \n",
    " \n",
    "    \n",
    "    list1=[]\n",
    "    \n",
    "    dirFiles = os.listdir(checkpoint_path) #list of directory files\n",
    "    #print(dirFiles)\n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non weights\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            if (name[0]==\"1\"):\n",
    "                list1.append(name)\n",
    "        \n",
    "    list1.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.append(\"prior\")    ## add the final weights\n",
    "    #print(list1)\n",
    "    Ws=list1\n",
    "    Xvector=[]\n",
    "    for i in Ws:\n",
    "        #print(i)\n",
    "        if i[0]==\"1\":\n",
    "            if i[1]==\"_\":\n",
    "                Xvector.append(int(i[2:]))\n",
    "    Xvector.append(int(np.ceil(len(y_train)/128)))\n",
    "    #print(Xvector)\n",
    "    error=[]\n",
    "    target_error=[]\n",
    "    for checkpoint in Ws:\n",
    "        if Binary:\n",
    "            model=init_MNIST_model_binary()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        else:\n",
    "            model=init_MNIST_model()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        model.load_weights(checkpoint_path+\"/\"+str(checkpoint)+\".ckpt\").expect_partial()\n",
    "        target_error.append(1-model.evaluate(x_target,y_target,verbose=0)[1])\n",
    "        error.append(1-model.evaluate(x_train,y_train,verbose=0)[1])\n",
    "    \n",
    "    if save:\n",
    "        results=pd.DataFrame({'Weightupdates': Xvector,\n",
    "            'Trainerror': error,\n",
    "            'targeterror':target_error,\n",
    "            })\n",
    "        with open(path_to_root_file+'mnist_transfer/'+checkpoint_path+\"/results.pkl\",'wb') as f:\n",
    "            pickle.dump(results,f)\n",
    "        f.close()\n",
    "    \n",
    "    return model.get_weights()\n",
    "    \n",
    "def read_and_prepare_results(alpha,x_bound,y_bound,x_target,y_target,sigma,delta,N,epsilon,Binary=False,Task=TASK):\n",
    "    #global TASK\n",
    "    ## read params.txt for the desired alpha and get the parameters\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    print(sigma)\n",
    "    if Binary:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "    else:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "        \n",
    "    epsilon=float(params[1])\n",
    "    epochs_trained=int(params[2])\n",
    "\n",
    "    if Binary:\n",
    "        M=init_MNIST_model_binary()\n",
    "    else:\n",
    "        M=init_MNIST_model()\n",
    "    M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "    ### load the prior weights if there are any\n",
    "    if alpha==0:\n",
    "        ### do nothing\n",
    "        w_a=M.get_weights()\n",
    "    else:\n",
    "        M.load_weights(prior_path).expect_partial()\n",
    "        w_a=M.get_weights()\n",
    "    \n",
    "   \n",
    "    [KLs,errors,targeterrors,Ws,Xvec]=read_weights(M,w_a,x_bound,y_bound,x_target,y_target,epochs_trained,sigma_tmp,epsilon,alpha,Binary=Binary,Task=TASK)    \n",
    "    #print(\"OK, I am back!\")\n",
    "    print(KLs)\n",
    "    print(errors)\n",
    "    print(targeterrors)\n",
    "    print(Ws)\n",
    "   \n",
    "    bound=[]\n",
    "    ### calculate the bound\n",
    "    for i in range(len(Xvec)):\n",
    "        bound.append(calculate_bound(KLs[i],alpha,delta,N,errors[i]))\n",
    "    #save the results to a pickled dataframe in results\n",
    "    \n",
    "    results=pd.DataFrame({'Weightupdates': Xvec,\n",
    "        'Trainerror': errors,\n",
    "        'targeterror':targeterrors,\n",
    "        'KL': KLs,\n",
    "        'Bound': bound})\n",
    "    with open(path_to_root_file+'mnist_transfer/'+result_path+str(sigma_tmp[0])+str(sigma_tmp[1])+\"_results.pkl\",'wb') as f:#int(sigma*10**8)\n",
    "        pickle.dump(results,f)\n",
    "    f.close()\n",
    "    return results\n",
    "\n",
    "def plot_result_file(epsilon,alpha,sigma,Binary=False,Task=TASK):\n",
    "    import pandas as pd\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(\"Binary: \"+r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "    print(results.head())\n",
    "    ### do the plots\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"Bound\"],'r*-')\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"Trainerror\"],'m^-')\n",
    "    \n",
    "    plt.xlabel(\"Weight updates\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    \n",
    "    plt.legend([\"Bound\",\"Empirical error\"])\n",
    "    plt.show()\n",
    "\n",
    "def find_optimal_sigma(sigmas,epsilon, alpha,Binary=False,Task=TASK):\n",
    "    #### to find the optimal sigma just do a search through all the results \n",
    "    #### and save the one for each parameter which has the minimal bound\n",
    "    #### Do we do this per epoch or for some other value? The sigma which yields the lowest bound overall for some epoch?\n",
    "    optimal=[0,1]\n",
    "    # search through all epochs and pick the sigma which yields the smallest bound during the whole training process\n",
    "    for sigma in sigmas:\n",
    "        sigma_tmp=sigma\n",
    "        sigma=sigma[0]*10**(-1*sigma[1])\n",
    "        if Binary:\n",
    "            result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        else:\n",
    "            result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "        MIN=np.min(results[\"Bound\"])\n",
    "        if (MIN<optimal[1]):\n",
    "            optimal[1]=MIN\n",
    "            optimal[0]=sigma\n",
    "    print(\"The optimal sigma is {} with bound value {}\".format(optimal[0],optimal[1]))\n",
    "\n",
    "   \n",
    "#### find the optimal sigma for every combination of parameters\n",
    "\n",
    "#### use the optimal sigmas to calculate the bound 50 times(with different data orders and initialisation)\n",
    "#### (Note: also delta=13*delta_0) for every combination and save the mean and std for plotting into a result file\n",
    "#for i in range(50):\n",
    "    ## take in the data and split with a new seed\n",
    " #   x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source,test_size=alpha,random_state=(69105+i))\n",
    "#### \n",
    "    \n",
    "#find_optimal_sigma(sigmas,0.01,0.2,Binary=False)\n",
    "def read_prior(alpha,TASK=2,Binary=True):\n",
    "    checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))\n",
    "    if Binary:\n",
    "        checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))\n",
    "    result_path=path_to_root_file+'mnist_transfer/'+checkpoint_path+\"/results.pkl\"\n",
    "    results=pd.read_pickle(result_path)\n",
    "    plt.title(r\"$\\alpha$=\"+str(alpha))\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"Trainerror\"],'m^-')\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"targeterror\"],'k^-')\n",
    "    plt.legend([\"Training error\",\"Target error\"])\n",
    "    \n",
    "def plot_prior_and_posterior(alpha,epsilon,sigma,TASK=2,Binary=True):\n",
    "    ### load in the prior data\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))\n",
    "    if Binary:\n",
    "        checkpoint_path = \"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))\n",
    "    result_path=path_to_root_file+'mnist_transfer/'+checkpoint_path+\"/results.pkl\"\n",
    "    results=pd.read_pickle(result_path)\n",
    "    result_path_post=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    results2=pd.read_pickle(result_path_post+\"_results.pkl\")\n",
    "    ### remove/ignore the first entry of the posterior data \n",
    "    ### as it should be a duplication of the last one from the prior results\n",
    "    \n",
    "    ### training error\n",
    "    A=list(results2[\"Weightupdates\"]+list(results[\"Weightupdates\"])[-1])\n",
    "    B=list(results[\"Weightupdates\"])\n",
    "    B.extend(A[1:])\n",
    "    C=list(results[\"Trainerror\"])\n",
    "    C.extend(list(results2[\"train_germain\"][1:]))\n",
    "    plt.plot(B,C,'-m^')\n",
    "    ## target error\n",
    "    D=list(results[\"targeterror\"])\n",
    "    D.extend(list(results2[\"target_germain\"][1:]))\n",
    "    plt.plot(B,D,'-k*')\n",
    "    ### bound\n",
    "    E=results2[\"germain_bound\"]\n",
    "    plt.plot(A[1:],E[1:],'D')\n",
    "    F=results2['boundpart3_germain']\n",
    "    plt.plot(A[1:],F[1:],'-o')\n",
    "    ### lines for uninformative region and worse than random guessing; also for end of prior training\n",
    "    plt.axvline(A[0],color=\"grey\")\n",
    "    plt.axhline(y=0.5, color=\"black\", linestyle=\"--\")\n",
    "    plt.axhline(y=1, color=\"red\", linestyle=\"--\")\n",
    "    plt.legend([\"Training error\",\"Target error\",\"Bound\",\"KL-part\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha is:0.5\n",
      " 36/547 [>.............................] - ETA: 1s - loss: 0.2358 - accuracy: 0.9030\n",
      " Saved weights after 45 batches \n",
      "\n",
      " 81/547 [===>..........................] - ETA: 1s - loss: 0.2275 - accuracy: 0.9059\n",
      " Saved weights after 90 batches \n",
      "\n",
      "126/547 [=====>........................] - ETA: 1s - loss: 0.2224 - accuracy: 0.9074\n",
      " Saved weights after 135 batches \n",
      "\n",
      "173/547 [========>.....................] - ETA: 1s - loss: 0.2176 - accuracy: 0.9093\n",
      " Saved weights after 180 batches \n",
      "\n",
      "221/547 [===========>..................] - ETA: 1s - loss: 0.2140 - accuracy: 0.9108\n",
      " Saved weights after 225 batches \n",
      "\n",
      "268/547 [=============>................] - ETA: 0s - loss: 0.2111 - accuracy: 0.9122\n",
      " Saved weights after 270 batches \n",
      "\n",
      "313/547 [================>.............] - ETA: 0s - loss: 0.2083 - accuracy: 0.9135\n",
      " Saved weights after 315 batches \n",
      "\n",
      "359/547 [==================>...........] - ETA: 0s - loss: 0.2056 - accuracy: 0.9148\n",
      " Saved weights after 360 batches \n",
      "\n",
      "389/547 [====================>.........] - ETA: 0s - loss: 0.2040 - accuracy: 0.9156\n",
      " Saved weights after 405 batches \n",
      "\n",
      "443/547 [=======================>......] - ETA: 0s - loss: 0.2011 - accuracy: 0.9169\n",
      " Saved weights after 450 batches \n",
      "\n",
      "492/547 [=========================>....] - ETA: 0s - loss: 0.1988 - accuracy: 0.9180\n",
      " Saved weights after 495 batches \n",
      "\n",
      "538/547 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.9189\n",
      " Saved weights after 540 batches \n",
      "\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.1963 - accuracy: 0.9191 - val_loss: 0.1264 - val_accuracy: 0.9513\n",
      "Epoch 1/2000\n",
      "531/547 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9534\n",
      "Epoch 00001: saving model to posteriors/task2/Binary/30_50/2_1.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.1215 - accuracy: 0.9535 - val_loss: 0.1029 - val_accuracy: 0.9613\n",
      "Epoch 2/2000\n",
      "542/547 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9652\n",
      "Epoch 00002: saving model to posteriors/task2/Binary/30_50/2_2.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0936 - accuracy: 0.9652 - val_loss: 0.0781 - val_accuracy: 0.9708\n",
      "Epoch 3/2000\n",
      "535/547 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9697\n",
      "Epoch 00003: saving model to posteriors/task2/Binary/30_50/2_3.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0805 - accuracy: 0.9697 - val_loss: 0.0707 - val_accuracy: 0.9731\n",
      "Epoch 4/2000\n",
      "542/547 [============================>.] - ETA: 0s - loss: 0.0695 - accuracy: 0.9744\n",
      "Epoch 00004: saving model to posteriors/task2/Binary/30_50/2_4.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0695 - accuracy: 0.9745 - val_loss: 0.0581 - val_accuracy: 0.9784\n",
      "\n",
      " !!! training error threshold reached, no further training !!!\n",
      " 37/547 [=>............................] - ETA: 1s - loss: 0.2218 - accuracy: 0.9071\n",
      " Saved weights after 45 batches \n",
      "\n",
      " 90/547 [===>..........................] - ETA: 1s - loss: 0.2163 - accuracy: 0.9094\n",
      " Saved weights after 90 batches \n",
      "\n",
      "122/547 [=====>........................] - ETA: 1s - loss: 0.2140 - accuracy: 0.9103\n",
      " Saved weights after 135 batches \n",
      "\n",
      "172/547 [========>.....................] - ETA: 1s - loss: 0.2122 - accuracy: 0.9110\n",
      " Saved weights after 180 batches \n",
      "\n",
      "222/547 [===========>..................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9120\n",
      " Saved weights after 225 batches \n",
      "\n",
      "257/547 [=============>................] - ETA: 0s - loss: 0.2077 - accuracy: 0.9129\n",
      " Saved weights after 270 batches \n",
      "\n",
      "310/547 [================>.............] - ETA: 0s - loss: 0.2051 - accuracy: 0.9142\n",
      " Saved weights after 315 batches \n",
      "\n",
      "344/547 [=================>............] - ETA: 0s - loss: 0.2037 - accuracy: 0.9149\n",
      " Saved weights after 360 batches \n",
      "\n",
      "396/547 [====================>.........] - ETA: 0s - loss: 0.2016 - accuracy: 0.9160\n",
      " Saved weights after 405 batches \n",
      "\n",
      "446/547 [=======================>......] - ETA: 0s - loss: 0.1996 - accuracy: 0.9170\n",
      " Saved weights after 450 batches \n",
      "\n",
      "479/547 [=========================>....] - ETA: 0s - loss: 0.1983 - accuracy: 0.9176\n",
      " Saved weights after 495 batches \n",
      "\n",
      "534/547 [============================>.] - ETA: 0s - loss: 0.1961 - accuracy: 0.9186\n",
      " Saved weights after 540 batches \n",
      "\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.1956 - accuracy: 0.9189 - val_loss: 0.1332 - val_accuracy: 0.9491\n",
      "Epoch 1/2000\n",
      "540/547 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9541\n",
      "Epoch 00001: saving model to posteriors/task2/Binary/10_50/2_1.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.1185 - accuracy: 0.9543 - val_loss: 0.0948 - val_accuracy: 0.9650\n",
      "Epoch 2/2000\n",
      "535/547 [============================>.] - ETA: 0s - loss: 0.0936 - accuracy: 0.9644\n",
      "Epoch 00002: saving model to posteriors/task2/Binary/10_50/2_2.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0933 - accuracy: 0.9645 - val_loss: 0.0854 - val_accuracy: 0.9668\n",
      "Epoch 3/2000\n",
      "544/547 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9702\n",
      "Epoch 00003: saving model to posteriors/task2/Binary/10_50/2_3.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0800 - accuracy: 0.9701 - val_loss: 0.0765 - val_accuracy: 0.9702\n",
      "Epoch 4/2000\n",
      "538/547 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9749\n",
      "Epoch 00004: saving model to posteriors/task2/Binary/10_50/2_4.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0689 - accuracy: 0.9749 - val_loss: 0.0615 - val_accuracy: 0.9762\n",
      "Epoch 5/2000\n",
      "547/547 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9772\n",
      "Epoch 00005: saving model to posteriors/task2/Binary/10_50/2_5.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0623 - accuracy: 0.9772 - val_loss: 0.0554 - val_accuracy: 0.9792\n",
      "Epoch 6/2000\n",
      "531/547 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9787\n",
      "Epoch 00006: saving model to posteriors/task2/Binary/10_50/2_6.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0572 - accuracy: 0.9787 - val_loss: 0.0491 - val_accuracy: 0.9831\n",
      "Epoch 7/2000\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9804\n",
      "Epoch 00007: saving model to posteriors/task2/Binary/10_50/2_7.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0532 - accuracy: 0.9803 - val_loss: 0.0493 - val_accuracy: 0.9824\n",
      "Epoch 8/2000\n",
      "534/547 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9826\n",
      "Epoch 00008: saving model to posteriors/task2/Binary/10_50/2_8.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0467 - accuracy: 0.9827 - val_loss: 0.0413 - val_accuracy: 0.9853\n",
      "Epoch 9/2000\n",
      "531/547 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.9836\n",
      "Epoch 00009: saving model to posteriors/task2/Binary/10_50/2_9.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0441 - accuracy: 0.9837 - val_loss: 0.0439 - val_accuracy: 0.9832\n",
      "Epoch 10/2000\n",
      "542/547 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9849\n",
      "Epoch 00010: saving model to posteriors/task2/Binary/10_50/2_10.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0416 - accuracy: 0.9850 - val_loss: 0.0343 - val_accuracy: 0.9885\n",
      "Epoch 11/2000\n",
      "540/547 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9865\n",
      "Epoch 00011: saving model to posteriors/task2/Binary/10_50/2_11.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0368 - accuracy: 0.9866 - val_loss: 0.0349 - val_accuracy: 0.9870\n",
      "Epoch 12/2000\n",
      "537/547 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9882\n",
      "Epoch 00012: saving model to posteriors/task2/Binary/10_50/2_12.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.0361 - val_accuracy: 0.9873\n",
      "Epoch 13/2000\n",
      "541/547 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9887\n",
      "Epoch 00013: saving model to posteriors/task2/Binary/10_50/2_13.ckpt\n",
      "547/547 [==============================] - 3s 5ms/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 0.0266 - val_accuracy: 0.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/2000\n",
      "124/547 [=====>........................] - ETA: 1s - loss: 0.0282 - accuracy: 0.9903"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "module5 = SourceFileLoader('plot', path_to_root_file+'mnist_transfer/results/plotting.py').load_module()\n",
    "from plot import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "#alpha=0.1\n",
    "delta=0.05 ## what would this be?   \n",
    "#sigma=0.01  \n",
    "\n",
    "alphas=[]\n",
    "from sklearn.model_selection import train_test_split\n",
    "'''\n",
    "length=10\n",
    "for i in range(length-1):\n",
    "    alphas.append((i+1)/length)\n",
    "'''\n",
    "epsilons=[0.03,0.01,0.001]\n",
    "#epsilons=[0.03]\n",
    "#epsilons=[0.01,0.001]\n",
    "### do hyperparameter sweep over sigma\n",
    "sigmas=[]\n",
    "#sigmas=[0.001,0.003,0.0001]\n",
    "#alphas=[0,0.1,0.5]#,0.6,0.7,0.8,0.9]\n",
    "#alphas=[0.3]\n",
    "\n",
    "for i in range(2,9):  \n",
    "    sigmas.append([3,i])#3*10**(-i))\n",
    "    if(i==8):\n",
    "        break\n",
    "    sigmas.append([1,i])#10**(-i))\n",
    "alphas.append(0.5)\n",
    "#sigmas.append([3,2])\n",
    "# \n",
    "y_source_bin=make_mnist_binary(y_source)\n",
    "y_target_bin=make_mnist_binary(y_target)\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha is:\"+str(alpha))\n",
    "    x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source_bin,test_size=alpha,random_state=69105)\n",
    "    #w_a=train_prior(alpha,1,x_prior,y_prior,x_target=x_target,y_target=y_target_bin,save=True,Task=2,Binary=True)\n",
    "    #read_prior(0.3,TASK=TASK,Binary=True)\n",
    "    #plot_result_file(0.03,alpha,[3,2],TASK,Binary=True)\n",
    "    #plot_prior_and_posterior(alpha,0.03,[3,3],TASK=TASK,Binary=True)\n",
    "    for epsilon in epsilons:\n",
    "        \n",
    "        w_s=train_posterior(alpha,x_source,y_source_bin,None,x_test=x_source,y_test=y_source_bin,epsilon=epsilon,Task=TASK,Binary=True)\n",
    "        #for sigma in sigmas:\n",
    "            #res=read_and_prepare_results(alpha,x_source,y_source_bin,x_target,y_target_bin,sigma,delta,len(x_source),epsilon,Binary=True)#x_bound,y_bound,x_target,y_target_bin,sigma,delta,len(x_bound),epsilon,Binary=True)\n",
    "            #plot_result_file(epsilon,alpha,sigma,TASK,Binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "import os\n",
    "mymodule2 = SourceFileLoader('DA', path_to_root_file+'mnist_transfer/experiments/DA_bound.py').load_module()\n",
    "from DA import *\n",
    "##### we want to compute the bound from Germain thm 7\n",
    "\n",
    "#### R_T  \\leq  omega' \\hat{R}_S+ a'/2 * dis_\\rho (S,T) +(omega'/omega +a'/a)*(KL(\\rho\\| \\pi )+\\ln(\\frac{3}{\\delta}))/m \n",
    "##### + \\lambda_\\rho + 1/2*(a'-1)\n",
    "\n",
    "\n",
    "#### a > 0 omega> 0, this can and probably should be optimised for the bound\n",
    "\n",
    "#### \\hat{R}_S is the empirical error on source, so just draw classifiers and calculate\n",
    "\n",
    "\n",
    "#### beta(T \\| S), domain divergence, this is more or less equal to average label density ratio or worst case depending on parameter q\n",
    "\n",
    "\n",
    " #### lambda_\\rho, difference in expected joint error |e_T-e_S| where e_S= E_h,h' E_x,y L(h(x),y)L(h'(x),y) \n",
    "    #### so draw two classifiers and calculate the mean of the product of losses on the domain   \n",
    "def read_weights_germain(model,w_a,x_bound,y_bound,x_target,y_target,epochs_trained,sigma,epsilon,alpha,Binary=False,Task=TASK):\n",
    "    import re\n",
    "    KLs=[]\n",
    "    e_s=[]\n",
    "    e_t=[]\n",
    "    d_tx=[]\n",
    "    d_sx=[]\n",
    "    epochs=[]\n",
    "    train_germain=[] \n",
    "    target_germain=[]\n",
    "    dis_rho=[]\n",
    "    lambda_rho=[]\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    \n",
    "    ### Here we do something more intelligent to not have to hardcode the epoch amounts. \n",
    "    ### we parse the filenames and sort them in numerical order and then load the weights\n",
    "    if Binary:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "    else:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    dirFiles = os.listdir(path) #list of directory files\n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non jpgs\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            ### if it has a one it goes in one list and if it starts with a two it goes in the other\n",
    "            if (name[0]==\"1\"):\n",
    "                list1.append(name)\n",
    "            elif (name[0]==\"2\"):\n",
    "                list2.append(name)\n",
    "            #epochs.append(name)\n",
    "    #epochs.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    num_batchweights=len(list1)\n",
    "    list2.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    list1.extend(list2)\n",
    "    Ws=list1 ## vector of checkpoint filenames\n",
    "    #print(Ws)\n",
    "    #sys.exit(-1)\n",
    "    #epochs=[int(i) for i in Ws]\n",
    "    Xvector=[]\n",
    "    for i in Ws:\n",
    "        #print(i)\n",
    "        if i[0]==\"1\":\n",
    "            if i[1]==\"_\":\n",
    "                Xvector.append(int(i[2:]))\n",
    "    for i in list2:\n",
    "        Xvector.append((int(i[2:])+1)*547)\n",
    "    print(Xvector)\n",
    "    #sys.exit(-1)\n",
    "    \"\"\"   \n",
    "    epochs = [] #list of checkpoint filenames\n",
    "    dirFiles = os.listdir(path) #list of directory files\n",
    "    ## remove the ckpt.index and sort so that we get the epochs that are in the directory\n",
    "    for files in dirFiles: #filter out all non jpgs\n",
    "        if '.ckpt.index' in files:\n",
    "            name = re.sub('\\.ckpt.index$', '', files)\n",
    "            epochs.append(name)\n",
    "    epochs.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    epochs=[int(i) for i in epochs]\n",
    "    \"\"\" \n",
    "    path=\"posteriors/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"/\"#\"{epoch:0d}.ckpt\"\n",
    "    if Binary:\n",
    "        path=\"posteriors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"/\"#\"{epoch:0d}.ckpt\"\n",
    "    \n",
    "    \n",
    "    L=len(Xvector)\n",
    "    \n",
    "    for checkpoint in Ws:\n",
    "        if Binary:\n",
    "            model=init_MNIST_model_binary()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "        else:\n",
    "            model=init_MNIST_model()\n",
    "            model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "\n",
    "        model.load_weights(path+str(checkpoint)+\".ckpt\").expect_partial()\n",
    "        w_s=model.get_weights()\n",
    "        \"\"\"\n",
    "        ############################# test\n",
    "        #print(x_target[1])\n",
    "        pred = model.predict(x_target)\n",
    "        print(make_01(pred))\n",
    "        indices = [i for i,v in enumerate(pred) if np.sum(pred[i]-y_target[i])==0]\n",
    "        print(indices)\n",
    "        sys.exit(-1)\n",
    "        \"\"\"\n",
    "        ##### here we should draw two classifiers and pass that on to the KL and calculate the training error\n",
    "        \n",
    "        t = time.time()\n",
    "        ## do X draws of the posterior, for two separate classifiers\n",
    "        w_s_draws=draw_classifier(w_s,sigma,num_classifiers=2)\n",
    "        w_s_draws2=draw_classifier(w_s,sigma,num_classifiers=2)\n",
    "        ## do X draws of the prior\n",
    "        w_a_draws=draw_classifier(w_a,sigma,num_classifiers=2)\n",
    "          \n",
    "        elapsed = time.time() - t\n",
    "        print(\"Time spent drawing the classifiers: \"+str(elapsed)+\"\\n\")\n",
    "   \n",
    "        \n",
    "        ###### for each pair of drawn prior and posterior we calculate the necessary parts of the bound \n",
    "        ###### and then average the result and return that\n",
    "        k=0\n",
    "        errorsum=0\n",
    "        target_errorsum=0\n",
    "        errorsum2=0\n",
    "        target_errorsum2=0\n",
    "        d_tx_h=0\n",
    "        d_sx_h=0\n",
    "        d_tx_hprime=0\n",
    "        d_sx_hprime=0\n",
    "        \n",
    "        for h in w_s_draws:\n",
    "            model.set_weights(h)\n",
    "            errorsum=((1-model.evaluate(x_bound,y_bound,verbose=0)[1])+errorsum*k)/(k+1)\n",
    "            target_errorsum=((1-model.evaluate(x_target,y_target,verbose=0)[1])+target_errorsum*k)/(k+1)\n",
    "            k+=1\n",
    "        k=0\n",
    "        for hprime in w_s_draws2:\n",
    "            model.set_weights(hprime)\n",
    "            errorsum2=((1-model.evaluate(x_bound,y_bound,verbose=0)[1])+errorsum2*k)/(k+1)\n",
    "            target_errorsum2=((1-model.evaluate(x_target,y_target,verbose=0)[1])+target_errorsum2*k)/(k+1)\n",
    "            k+=1\n",
    "        train_germain.append((errorsum+errorsum2)/2)\n",
    "        target_germain.append((target_errorsum+target_errorsum2)/2)\n",
    "        \n",
    "        #### loop over pairs of classifiers from posterior for the disagreement and joint error\n",
    "        q=0\n",
    "        e_ssum=0\n",
    "        e_tsum=0\n",
    "        d_txsum=0\n",
    "        d_sxsum=0\n",
    "        for h in w_s_draws:\n",
    "            model.set_weights(h)\n",
    "            d_tx_h=model.predict(x_target,verbose=0)\n",
    "            d_sx_h=model.predict(x_bound,verbose=0)\n",
    "            newlist=make_01(d_sx_h)\n",
    "            newlist3=make_01(d_tx_h)\n",
    "            for hprime in w_s_draws2:\n",
    "                model.set_weights(hprime)\n",
    "                d_tx_hprime=model.predict(x_target,verbose=0)\n",
    "                d_sx_hprime=model.predict(x_bound,verbose=0)\n",
    "                newlist2=make_01(d_sx_hprime)\n",
    "                newlist4=make_01(d_tx_hprime)\n",
    "                e_ssum=(joint_error(newlist,newlist2,y_bound)+q*e_ssum)/(q+1)\n",
    "                d_sxsum=(classifier_disagreement(newlist,newlist2)+q*d_sxsum)/(q+1)\n",
    "                e_tsum=(joint_error(newlist3,newlist4,y_target)+q*e_tsum)/(q+1)\n",
    "                d_txsum=(classifier_disagreement(newlist3,newlist4)+q*d_txsum)/(q+1)\n",
    "                q+=1\n",
    "        e_s.append(e_ssum)\n",
    "        d_sx.append(d_sxsum)\n",
    "        e_t.append(e_tsum)\n",
    "        d_tx.append(d_txsum)\n",
    "            \n",
    "        ## compute the KL\n",
    "        l=0\n",
    "        KLsum=0\n",
    "        for j in w_a_draws:\n",
    "            for i in w_s_draws:\n",
    "                KLsum=(estimate_KL(j,i,sigma)+l*KLsum)/(l+1)\n",
    "                l+=1\n",
    "        \n",
    "        for j in w_a_draws:\n",
    "            for i in w_s_draws2:\n",
    "                KLsum=(estimate_KL(j,i,sigma)+l*KLsum)/(l+1)\n",
    "                l+=1\n",
    "        KLs.append(KLsum)\n",
    "        \n",
    "        ### memory leak city\n",
    "        del model\n",
    "        _=gc.collect()\n",
    "        \n",
    "        \n",
    "     \n",
    "    print(\"Finished calculation of bound parts\")\n",
    "   \n",
    "          #### load the result file if it exists otherwise make one\n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "    if(os.path.exists(result_path+\"_results.pkl\")):\n",
    "        results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "    else:\n",
    "        results=pd.DataFrame({'Weightupdates': Xvector,\n",
    "        'train_germain': train_germain,\n",
    "        'target_germain':target_germain,\n",
    "        'KL': KLs})\n",
    "        with open(path_to_root_file+'mnist_transfer/'+result_path+\"_results.pkl\",'wb') as f:\n",
    "            pickle.dump(results,f)\n",
    "        f.close()\n",
    "        results=pd.read_pickle(result_path+\"_results.pkl\")\n",
    "\n",
    "    train_germain=np.array(train_germain)\n",
    "    results['Weightupdates']=Xvector\n",
    "    results['train_germain']=train_germain\n",
    "    results['target_germain']=target_germain\n",
    "    results['e_s']=e_s\n",
    "    results['e_t']=e_t\n",
    "    results['d_tx']=d_tx\n",
    "    results['d_sx']=d_sx\n",
    "    results['KL']=KLs\n",
    "    KL=KLs\n",
    "    \n",
    "    m=len(y_bound)\n",
    "    \n",
    "    [res,bestparam, boundparts]=grid_search(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,m,L)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    results['germain_bound']=res\n",
    "    print(\"Germain bound\"+str(res))\n",
    "    print(\"[a, omega]= \"+str(bestparam))\n",
    "    results['boundpart1_germain']=boundparts[0]\n",
    "    results['boundpart2_germain']=boundparts[1]\n",
    "    results['boundpart3_germain']=boundparts[2]\n",
    "    results['boundpart4_germain']=boundparts[3]\n",
    "    results['boundpart5_germain']=boundparts[4]\n",
    "   \n",
    "    with open(path_to_root_file+'mnist_transfer/'+result_path+\"_results.pkl\",'wb') as f:\n",
    "        pickle.dump(results,f)\n",
    "    f.close()\n",
    "    return results\n",
    "\n",
    "def grid_search(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,m,L):\n",
    "    #### here we want to do a coarse grid search over a and omega to get the smallest bound \n",
    "    print(\"Starting gridsearch....\")\n",
    "    avec=[0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000,50000,100000]\n",
    "    omegas=[0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,5000,10000,50000,100000]\n",
    "    tmp= sys.maxsize\n",
    "    res=[]\n",
    "    bestparam=[0,0]\n",
    "    for a in avec:\n",
    "        for omega in omegas:\n",
    "            germain_bound,a1,a2,a3,a4,a5=calculate_germain_bound(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,a,omega,m,L)\n",
    "            if min(germain_bound)<tmp:\n",
    "                tmp=min(germain_bound)\n",
    "                #print(\"Best bound thus far:\"+str(tmp))\n",
    "                res=germain_bound\n",
    "                bestparam=[a,omega]\n",
    "                \n",
    "    ### do a finer sweep around the best parameters\n",
    "    if bestparam[0]!=0:\n",
    "        avec=np.arange(bestparam[0]-bestparam[0]/2,bestparam[0]+bestparam[0]*4,0.1*bestparam[0])\n",
    "    else:## no bound better than the max int was found, if that is even possible\n",
    "        avec=np.arange(-1,1,0.1)\n",
    "    if bestparam[1]!=0:\n",
    "        omegas=np.arange(bestparam[1]-bestparam[1]/2,bestparam[1]+bestparam[1]*4,0.1*bestparam[1])\n",
    "    else:## no bound better than the max int was found\n",
    "        avec=np.arange(-1,1,0.1)\n",
    "    boundparts=[0, 0,0,0,0]\n",
    "    for a in avec:\n",
    "        for omega in omegas:\n",
    "            germain_bound,a1,a2,a3,a4,a5=calculate_germain_bound(train_germain,e_s,e_t,d_tx,d_sx,KL,delta,a,omega,m,L)\n",
    "            if min(germain_bound)<tmp:\n",
    "                tmp=min(germain_bound)\n",
    "                #print(\"Best finer bound thus far:\"+str(tmp))\n",
    "                res=germain_bound\n",
    "                bestparam=[a,omega]\n",
    "                boundparts=[a1,a2,a3,a4,a5]\n",
    "    return [res,bestparam, boundparts]\n",
    "\n",
    "def germain_bound(x_bound,y_bound,x_target,y_target,alpha,sigma,epsilon,task,Binary=False):\n",
    "    TASK=task\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "        ## read params.txt for the desired alpha and get the parameters\n",
    " \n",
    "    if Binary:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "    else:\n",
    "        with open('posteriors/'+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+'/params.txt', 'rb+') as f:\n",
    "            params=f.readlines()\n",
    "        f.close()\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"\n",
    "\n",
    "    epsilon=float(params[1])\n",
    "    epochs_trained=int(params[2])\n",
    "    if Binary:\n",
    "        M=init_MNIST_model_binary()\n",
    "    else:\n",
    "        M=init_MNIST_model()\n",
    "                \n",
    "    M.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=keras.optimizers.SGD(learning_rate=0.003, momentum=0.95),\n",
    "                      metrics=['accuracy'],)\n",
    "      ### load the prior weights if there are any\n",
    "    if(Binary and alpha != 0):\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "    elif(alpha != 0):\n",
    "        prior_path=\"priors/\"+\"task\"+str(TASK)+\"/\"+str(int(100*alpha))+\"/prior.ckpt\"\n",
    "    if alpha==0:\n",
    "        ### do nothing, just take the random initialisation\n",
    "        w_a=M.get_weights()\n",
    "    else:\n",
    "        M.load_weights(prior_path).expect_partial()\n",
    "        w_a=M.get_weights()\n",
    "    \n",
    " \n",
    "    ## get the prior weights for the KL and pass into read_weights\n",
    "    results=read_weights_germain(M,w_a,x_bound,y_bound,x_target,y_target,epochs_trained,sigma_tmp,epsilon,alpha,Binary=Binary,Task=TASK)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:0\n",
      "epsilon:0.03\n",
      "sigma:[3, 2]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735]\n",
      "Time spent drawing the classifiers: 0.014040470123291016\n",
      "\n",
      "Time spent drawing the classifiers: 0.014549970626831055\n",
      "\n",
      "Time spent drawing the classifiers: 0.014130115509033203\n",
      "\n",
      "Time spent drawing the classifiers: 0.014111995697021484\n",
      "\n",
      "Time spent drawing the classifiers: 0.014656305313110352\n",
      "\n",
      "Time spent drawing the classifiers: 0.014613866806030273\n",
      "\n",
      "Time spent drawing the classifiers: 0.01475977897644043\n",
      "\n",
      "Time spent drawing the classifiers: 0.014621496200561523\n",
      "\n",
      "Time spent drawing the classifiers: 0.014639854431152344\n",
      "\n",
      "Time spent drawing the classifiers: 0.014748573303222656\n",
      "\n",
      "Time spent drawing the classifiers: 0.014056205749511719\n",
      "\n",
      "Time spent drawing the classifiers: 0.014092206954956055\n",
      "\n",
      "Time spent drawing the classifiers: 0.01463937759399414\n",
      "\n",
      "Time spent drawing the classifiers: 0.014776945114135742\n",
      "\n",
      "Time spent drawing the classifiers: 0.01476430892944336\n",
      "\n",
      "Time spent drawing the classifiers: 0.014764070510864258\n",
      "\n",
      "Time spent drawing the classifiers: 0.014777660369873047\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[3.3575303028446912, 3.1493991966692403, 2.871270251544766, 2.942408015383659, 2.690268207213052, 2.6347677645632146, 2.5459027312439346, 2.6274556817827563, 2.5886334027746534, 2.560090725688177, 2.4177911624157002, 2.4263651657419496, 2.4372130322668357, 2.3487975574666566, 2.259358033323498, 2.289186460780443, 2.2985804945512607]\n",
      "[a, omega]= [0.7, 2.5]\n",
      "sigma:[3, 3]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735]\n",
      "Time spent drawing the classifiers: 0.014112472534179688\n",
      "\n",
      "Time spent drawing the classifiers: 0.01406717300415039\n",
      "\n",
      "Time spent drawing the classifiers: 0.014102458953857422\n",
      "\n",
      "Time spent drawing the classifiers: 0.014052391052246094\n",
      "\n",
      "Time spent drawing the classifiers: 0.014679908752441406\n",
      "\n",
      "Time spent drawing the classifiers: 0.014611482620239258\n",
      "\n",
      "Time spent drawing the classifiers: 0.014768362045288086\n",
      "\n",
      "Time spent drawing the classifiers: 0.01462554931640625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014645814895629883\n",
      "\n",
      "Time spent drawing the classifiers: 0.014569997787475586\n",
      "\n",
      "Time spent drawing the classifiers: 0.01416325569152832\n",
      "\n",
      "Time spent drawing the classifiers: 0.014824867248535156\n",
      "\n",
      "Time spent drawing the classifiers: 0.01408243179321289\n",
      "\n",
      "Time spent drawing the classifiers: 0.014801979064941406\n",
      "\n",
      "Time spent drawing the classifiers: 0.014759063720703125\n",
      "\n",
      "Time spent drawing the classifiers: 0.014088153839111328\n",
      "\n",
      "Time spent drawing the classifiers: 0.013775110244750977\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[12.950435303960383, 12.297925667721216, 11.891473323959811, 11.696433295766191, 11.526788584560423, 11.50609714322268, 11.490174701680052, 11.545407154338154, 11.400894989434146, 11.43103523018681, 11.401458184682552, 11.346404394210822, 11.42398798394485, 11.327476141330221, 11.350685143415088, 11.377328168141736, 11.40737990688986]\n",
      "[a, omega]= [1.4, 4.5]\n",
      "sigma:[1, 6]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735]\n",
      "Time spent drawing the classifiers: 0.014672279357910156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014590740203857422\n",
      "\n",
      "Time spent drawing the classifiers: 0.014668941497802734\n",
      "\n",
      "Time spent drawing the classifiers: 0.0146636962890625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014156103134155273\n",
      "\n",
      "Time spent drawing the classifiers: 0.014664173126220703\n",
      "\n",
      "Time spent drawing the classifiers: 0.014734745025634766\n",
      "\n",
      "Time spent drawing the classifiers: 0.014756441116333008\n",
      "\n",
      "Time spent drawing the classifiers: 0.014811277389526367\n",
      "\n",
      "Time spent drawing the classifiers: 0.014778852462768555\n",
      "\n",
      "Time spent drawing the classifiers: 0.01383066177368164\n",
      "\n",
      "Time spent drawing the classifiers: 0.014852285385131836\n",
      "\n",
      "Time spent drawing the classifiers: 0.014800310134887695\n",
      "\n",
      "Time spent drawing the classifiers: 0.01476597785949707\n",
      "\n",
      "Time spent drawing the classifiers: 0.01375126838684082\n",
      "\n",
      "Time spent drawing the classifiers: 0.013782024383544922\n",
      "\n",
      "Time spent drawing the classifiers: 0.013763666152954102\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[27944.657737281086, 27970.484687672273, 28042.867446071785, 28109.727693981346, 28165.871496812888, 28219.68711300098, 28258.66412069539, 28307.91866209833, 28338.38671847922, 28371.417179371943, 28405.877393272258, 28435.11198932293, 28472.496657601663, 28791.726089960954, 29040.471589155022, 29242.460510808636, 29417.56511690109]\n",
      "[a, omega]= [5.5, 10.0]\n",
      "epsilon:0.01\n",
      "sigma:[3, 2]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299]\n",
      "Time spent drawing the classifiers: 0.014873266220092773\n",
      "\n",
      "Time spent drawing the classifiers: 0.014113664627075195\n",
      "\n",
      "Time spent drawing the classifiers: 0.014020442962646484\n",
      "\n",
      "Time spent drawing the classifiers: 0.014140605926513672\n",
      "\n",
      "Time spent drawing the classifiers: 0.014150142669677734\n",
      "\n",
      "Time spent drawing the classifiers: 0.014707565307617188\n",
      "\n",
      "Time spent drawing the classifiers: 0.014559507369995117\n",
      "\n",
      "Time spent drawing the classifiers: 0.01472163200378418\n",
      "\n",
      "Time spent drawing the classifiers: 0.014634847640991211\n",
      "\n",
      "Time spent drawing the classifiers: 0.0137939453125\n",
      "\n",
      "Time spent drawing the classifiers: 0.014627218246459961\n",
      "\n",
      "Time spent drawing the classifiers: 0.01472616195678711\n",
      "\n",
      "Time spent drawing the classifiers: 0.014825820922851562\n",
      "\n",
      "Time spent drawing the classifiers: 0.013808488845825195\n",
      "\n",
      "Time spent drawing the classifiers: 0.013801097869873047\n",
      "\n",
      "Time spent drawing the classifiers: 0.01466679573059082\n",
      "\n",
      "Time spent drawing the classifiers: 0.014801979064941406\n",
      "\n",
      "Time spent drawing the classifiers: 0.014150381088256836\n",
      "\n",
      "Time spent drawing the classifiers: 0.014068841934204102\n",
      "\n",
      "Time spent drawing the classifiers: 0.01410675048828125\n",
      "\n",
      "Time spent drawing the classifiers: 0.014238357543945312\n",
      "\n",
      "Time spent drawing the classifiers: 0.014824867248535156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014615297317504883\n",
      "\n",
      "Time spent drawing the classifiers: 0.0146484375\n",
      "\n",
      "Time spent drawing the classifiers: 0.014571189880371094\n",
      "\n",
      "Time spent drawing the classifiers: 0.014736652374267578\n",
      "\n",
      "Time spent drawing the classifiers: 0.014584779739379883\n",
      "\n",
      "Time spent drawing the classifiers: 0.014694452285766602\n",
      "\n",
      "Time spent drawing the classifiers: 0.014663219451904297\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[3.40130281972065, 3.0145843974072064, 2.9388207338209407, 2.835605576208192, 2.7481155995769413, 2.6662961666735474, 2.543641886483263, 2.5769535855166463, 2.4480110948878613, 2.516603425743333, 2.617746574252749, 2.5036254085441754, 2.4308645043049153, 2.3410131433494237, 2.2938353862975545, 2.2519572538022627, 2.2888987379579526, 2.2354997662745935, 2.2818228738196895, 2.2583451266687753, 2.2994848368369443, 2.293140002507637, 2.2598326364301973, 2.2449751667090223, 2.3321116821240873, 2.2956577450418783, 2.2599787732507157, 2.312659596970733, 2.2938322852297786]\n",
      "[a, omega]= [0.7, 2.5]\n",
      "sigma:[3, 3]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299]\n",
      "Time spent drawing the classifiers: 0.014772653579711914\n",
      "\n",
      "Time spent drawing the classifiers: 0.014604806900024414\n",
      "\n",
      "Time spent drawing the classifiers: 0.01467585563659668\n",
      "\n",
      "Time spent drawing the classifiers: 0.014670372009277344\n",
      "\n",
      "Time spent drawing the classifiers: 0.014613628387451172\n",
      "\n",
      "Time spent drawing the classifiers: 0.01471853256225586\n",
      "\n",
      "Time spent drawing the classifiers: 0.01456451416015625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014677286148071289\n",
      "\n",
      "Time spent drawing the classifiers: 0.014730691909790039\n",
      "\n",
      "Time spent drawing the classifiers: 0.014610528945922852\n",
      "\n",
      "Time spent drawing the classifiers: 0.014596700668334961\n",
      "\n",
      "Time spent drawing the classifiers: 0.01467442512512207\n",
      "\n",
      "Time spent drawing the classifiers: 0.014626026153564453\n",
      "\n",
      "Time spent drawing the classifiers: 0.01373434066772461\n",
      "\n",
      "Time spent drawing the classifiers: 0.013714313507080078\n",
      "\n",
      "Time spent drawing the classifiers: 0.014102458953857422\n",
      "\n",
      "Time spent drawing the classifiers: 0.014200925827026367\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent drawing the classifiers: 0.014044046401977539\n",
      "\n",
      "Time spent drawing the classifiers: 0.014136314392089844\n",
      "\n",
      "Time spent drawing the classifiers: 0.014153003692626953\n",
      "\n",
      "Time spent drawing the classifiers: 0.014833211898803711\n",
      "\n",
      "Time spent drawing the classifiers: 0.014628410339355469\n",
      "\n",
      "Time spent drawing the classifiers: 0.01416158676147461\n",
      "\n",
      "Time spent drawing the classifiers: 0.014115333557128906\n",
      "\n",
      "Time spent drawing the classifiers: 0.014763355255126953\n",
      "\n",
      "Time spent drawing the classifiers: 0.014781713485717773\n",
      "\n",
      "Time spent drawing the classifiers: 0.014336585998535156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014700889587402344\n",
      "\n",
      "Time spent drawing the classifiers: 0.014099359512329102\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[13.120673759633096, 12.218263034297522, 11.932244558312501, 11.657421947802785, 11.676567613660467, 11.505915819067665, 11.468280578710223, 11.40992770866843, 11.46867960570742, 11.4415064249813, 11.50129755636447, 11.442366340757534, 11.439510291113125, 11.323693354802655, 11.348719464202217, 11.39534053068135, 11.423550923147372, 11.486137391434045, 11.528485545456062, 11.578882497707724, 11.633830888554625, 11.659978865600442, 11.706467093442603, 11.73229530082823, 11.79202374797267, 11.834434000722394, 11.865982442378948, 11.917449944493148, 11.956527339347462]\n",
      "[a, omega]= [1.4, 4.5]\n",
      "sigma:[1, 6]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299]\n",
      "Time spent drawing the classifiers: 0.014770984649658203\n",
      "\n",
      "Time spent drawing the classifiers: 0.014713287353515625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014145374298095703\n",
      "\n",
      "Time spent drawing the classifiers: 0.014588594436645508\n",
      "\n",
      "Time spent drawing the classifiers: 0.014644145965576172\n",
      "\n",
      "Time spent drawing the classifiers: 0.014591455459594727\n",
      "\n",
      "Time spent drawing the classifiers: 0.014739036560058594\n",
      "\n",
      "Time spent drawing the classifiers: 0.01379704475402832\n",
      "\n",
      "Time spent drawing the classifiers: 0.014718055725097656\n",
      "\n",
      "Time spent drawing the classifiers: 0.014678001403808594\n",
      "\n",
      "Time spent drawing the classifiers: 0.014033317565917969\n",
      "\n",
      "Time spent drawing the classifiers: 0.014004945755004883\n",
      "\n",
      "Time spent drawing the classifiers: 0.014105081558227539\n",
      "\n",
      "Time spent drawing the classifiers: 0.014118671417236328\n",
      "\n",
      "Time spent drawing the classifiers: 0.014154911041259766\n",
      "\n",
      "Time spent drawing the classifiers: 0.01465916633605957\n",
      "\n",
      "Time spent drawing the classifiers: 0.01470327377319336\n",
      "\n",
      "Time spent drawing the classifiers: 0.014622688293457031\n",
      "\n",
      "Time spent drawing the classifiers: 0.014595985412597656\n",
      "\n",
      "Time spent drawing the classifiers: 0.014597892761230469\n",
      "\n",
      "Time spent drawing the classifiers: 0.014649391174316406\n",
      "\n",
      "Time spent drawing the classifiers: 0.01470947265625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014096736907958984\n",
      "\n",
      "Time spent drawing the classifiers: 0.014104843139648438\n",
      "\n",
      "Time spent drawing the classifiers: 0.014171838760375977\n",
      "\n",
      "Time spent drawing the classifiers: 0.014698266983032227\n",
      "\n",
      "Time spent drawing the classifiers: 0.014684677124023438\n",
      "\n",
      "Time spent drawing the classifiers: 0.014197111129760742\n",
      "\n",
      "Time spent drawing the classifiers: 0.014139175415039062\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[27829.134298975732, 27843.9582692522, 27912.17915108394, 27988.97807705244, 28047.10798024093, 28098.08732513206, 28136.419476972602, 28165.683367541587, 28207.234086642522, 28251.120773172846, 28286.75266568626, 28322.33807385591, 28351.584609629535, 28654.73954164714, 28888.12942711646, 29100.663001247623, 29290.821416647253, 29470.282911087008, 29636.780352693913, 29793.402825435976, 29937.139196894423, 30088.646183819943, 30227.56182295783, 30367.116297173983, 30498.111074959284, 30633.240975943212, 30767.949753702083, 30896.837683700673, 31026.17198756007]\n",
      "[a, omega]= [5.5, 10.0]\n",
      "epsilon:0.001\n",
      "sigma:[3, 2]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299, 9846, 10393, 10940, 11487, 12034, 12581, 13128, 13675, 14222, 14769, 15316, 15863, 16410, 16957, 17504, 18051, 18598, 19145, 19692, 20239, 20786, 21333, 21880, 22427]\n",
      "Time spent drawing the classifiers: 0.01385807991027832\n",
      "\n",
      "Time spent drawing the classifiers: 0.01376032829284668\n",
      "\n",
      "Time spent drawing the classifiers: 0.01473546028137207\n",
      "\n",
      "Time spent drawing the classifiers: 0.014873981475830078\n",
      "\n",
      "Time spent drawing the classifiers: 0.014748811721801758\n",
      "\n",
      "Time spent drawing the classifiers: 0.014777421951293945\n",
      "\n",
      "Time spent drawing the classifiers: 0.014723777770996094\n",
      "\n",
      "Time spent drawing the classifiers: 0.014650106430053711\n",
      "\n",
      "Time spent drawing the classifiers: 0.014678716659545898\n",
      "\n",
      "Time spent drawing the classifiers: 0.01466989517211914\n",
      "\n",
      "Time spent drawing the classifiers: 0.014658212661743164\n",
      "\n",
      "Time spent drawing the classifiers: 0.014119625091552734\n",
      "\n",
      "Time spent drawing the classifiers: 0.01478719711303711\n",
      "\n",
      "Time spent drawing the classifiers: 0.014789104461669922\n",
      "\n",
      "Time spent drawing the classifiers: 0.014764547348022461\n",
      "\n",
      "Time spent drawing the classifiers: 0.014687061309814453\n",
      "\n",
      "Time spent drawing the classifiers: 0.01413416862487793\n",
      "\n",
      "Time spent drawing the classifiers: 0.014809370040893555\n",
      "\n",
      "Time spent drawing the classifiers: 0.014036178588867188\n",
      "\n",
      "Time spent drawing the classifiers: 0.014112234115600586\n",
      "\n",
      "Time spent drawing the classifiers: 0.014116287231445312\n",
      "\n",
      "Time spent drawing the classifiers: 0.014133453369140625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014140129089355469\n",
      "\n",
      "Time spent drawing the classifiers: 0.014150142669677734\n",
      "\n",
      "Time spent drawing the classifiers: 0.014165878295898438\n",
      "\n",
      "Time spent drawing the classifiers: 0.014650821685791016\n",
      "\n",
      "Time spent drawing the classifiers: 0.014725208282470703\n",
      "\n",
      "Time spent drawing the classifiers: 0.014784812927246094\n",
      "\n",
      "Time spent drawing the classifiers: 0.01465153694152832\n",
      "\n",
      "Time spent drawing the classifiers: 0.014760017395019531\n",
      "\n",
      "Time spent drawing the classifiers: 0.014933586120605469\n",
      "\n",
      "Time spent drawing the classifiers: 0.014634132385253906\n",
      "\n",
      "Time spent drawing the classifiers: 0.014608621597290039\n",
      "\n",
      "Time spent drawing the classifiers: 0.014057397842407227\n",
      "\n",
      "Time spent drawing the classifiers: 0.014793872833251953\n",
      "\n",
      "Time spent drawing the classifiers: 0.013810396194458008\n",
      "\n",
      "Time spent drawing the classifiers: 0.014733314514160156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014822006225585938\n",
      "\n",
      "Time spent drawing the classifiers: 0.014758825302124023\n",
      "\n",
      "Time spent drawing the classifiers: 0.014668703079223633\n",
      "\n",
      "Time spent drawing the classifiers: 0.014726877212524414\n",
      "\n",
      "Time spent drawing the classifiers: 0.014071941375732422\n",
      "\n",
      "Time spent drawing the classifiers: 0.013742685317993164\n",
      "\n",
      "Time spent drawing the classifiers: 0.013781070709228516\n",
      "\n",
      "Time spent drawing the classifiers: 0.014126300811767578\n",
      "\n",
      "Time spent drawing the classifiers: 0.014637947082519531\n",
      "\n",
      "Time spent drawing the classifiers: 0.014687061309814453\n",
      "\n",
      "Time spent drawing the classifiers: 0.01429438591003418\n",
      "\n",
      "Time spent drawing the classifiers: 0.014864206314086914\n",
      "\n",
      "Time spent drawing the classifiers: 0.014721393585205078\n",
      "\n",
      "Time spent drawing the classifiers: 0.014165878295898438\n",
      "\n",
      "Time spent drawing the classifiers: 0.014102935791015625\n",
      "\n",
      "Time spent drawing the classifiers: 0.013998985290527344\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[3.6392454980058044, 3.3621642963204788, 3.1536634107442385, 2.8696073949314838, 2.6318177034891415, 2.6387942827680897, 2.7645597700472884, 2.6266539552919497, 2.4989443745812077, 2.5762957138871454, 2.5787920638942974, 2.583812484986147, 2.4622394999260004, 2.374270282047043, 2.3025460411686964, 2.3013908772437404, 2.307400892389146, 2.260331837038641, 2.405037901063097, 2.290650978749251, 2.2415032465637736, 2.2465820597009225, 2.3008656659448192, 2.2740745763148347, 2.255948796164331, 2.2358456728887885, 2.28406996667347, 2.2521161332003836, 2.316388914147822, 2.2657642396110056, 2.259662964121857, 2.310130108431214, 2.2596829576171684, 2.299104959450352, 2.2644405927738527, 2.305435057873292, 2.2726003341289074, 2.25922105471307, 2.3247083554597925, 2.286756686953286, 2.298430923350765, 2.297982366787485, 2.307586420430855, 2.2974667890765423, 2.320141022943055, 2.314089299190451, 2.3328153832387835, 2.308643836120498, 2.3092100656520955, 2.3007477370435625, 2.3354930168414025, 2.3325187110389334, 2.369278797541182]\n",
      "[a, omega]= [0.7, 3.0]\n",
      "sigma:[3, 3]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299, 9846, 10393, 10940, 11487, 12034, 12581, 13128, 13675, 14222, 14769, 15316, 15863, 16410, 16957, 17504, 18051, 18598, 19145, 19692, 20239, 20786, 21333, 21880, 22427]\n",
      "Time spent drawing the classifiers: 0.014078617095947266\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent drawing the classifiers: 0.013798952102661133\n",
      "\n",
      "Time spent drawing the classifiers: 0.014077901840209961\n",
      "\n",
      "Time spent drawing the classifiers: 0.014044523239135742\n",
      "\n",
      "Time spent drawing the classifiers: 0.013757467269897461\n",
      "\n",
      "Time spent drawing the classifiers: 0.014824867248535156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014119148254394531\n",
      "\n",
      "Time spent drawing the classifiers: 0.014662027359008789\n",
      "\n",
      "Time spent drawing the classifiers: 0.015004158020019531\n",
      "\n",
      "Time spent drawing the classifiers: 0.01489114761352539\n",
      "\n",
      "Time spent drawing the classifiers: 0.014917850494384766\n",
      "\n",
      "Time spent drawing the classifiers: 0.014406919479370117\n",
      "\n",
      "Time spent drawing the classifiers: 0.015162467956542969\n",
      "\n",
      "Time spent drawing the classifiers: 0.014930486679077148\n",
      "\n",
      "Time spent drawing the classifiers: 0.015063047409057617\n",
      "\n",
      "Time spent drawing the classifiers: 0.014986991882324219\n",
      "\n",
      "Time spent drawing the classifiers: 0.015379905700683594\n",
      "\n",
      "Time spent drawing the classifiers: 0.014619588851928711\n",
      "\n",
      "Time spent drawing the classifiers: 0.014860391616821289\n",
      "\n",
      "Time spent drawing the classifiers: 0.014821290969848633\n",
      "\n",
      "Time spent drawing the classifiers: 0.014854907989501953\n",
      "\n",
      "Time spent drawing the classifiers: 0.014716148376464844\n",
      "\n",
      "Time spent drawing the classifiers: 0.014852762222290039\n",
      "\n",
      "Time spent drawing the classifiers: 0.014793634414672852\n",
      "\n",
      "Time spent drawing the classifiers: 0.014732122421264648\n",
      "\n",
      "Time spent drawing the classifiers: 0.014797687530517578\n",
      "\n",
      "Time spent drawing the classifiers: 0.015067815780639648\n",
      "\n",
      "Time spent drawing the classifiers: 0.014948129653930664\n",
      "\n",
      "Time spent drawing the classifiers: 0.013968229293823242\n",
      "\n",
      "Time spent drawing the classifiers: 0.014786958694458008\n",
      "\n",
      "Time spent drawing the classifiers: 0.014528036117553711\n",
      "\n",
      "Time spent drawing the classifiers: 0.014590263366699219\n",
      "\n",
      "Time spent drawing the classifiers: 0.0150909423828125\n",
      "\n",
      "Time spent drawing the classifiers: 0.014973163604736328\n",
      "\n",
      "Time spent drawing the classifiers: 0.014947652816772461\n",
      "\n",
      "Time spent drawing the classifiers: 0.014983177185058594\n",
      "\n",
      "Time spent drawing the classifiers: 0.015198469161987305\n",
      "\n",
      "Time spent drawing the classifiers: 0.014887094497680664\n",
      "\n",
      "Time spent drawing the classifiers: 0.01434016227722168\n",
      "\n",
      "Time spent drawing the classifiers: 0.014751672744750977\n",
      "\n",
      "Time spent drawing the classifiers: 0.014719724655151367\n",
      "\n",
      "Time spent drawing the classifiers: 0.014709949493408203\n",
      "\n",
      "Time spent drawing the classifiers: 0.014834165573120117\n",
      "\n",
      "Time spent drawing the classifiers: 0.014782190322875977\n",
      "\n",
      "Time spent drawing the classifiers: 0.01461935043334961\n",
      "\n",
      "Time spent drawing the classifiers: 0.014356374740600586\n",
      "\n",
      "Time spent drawing the classifiers: 0.014955520629882812\n",
      "\n",
      "Time spent drawing the classifiers: 0.01479196548461914\n",
      "\n",
      "Time spent drawing the classifiers: 0.014776468276977539\n",
      "\n",
      "Time spent drawing the classifiers: 0.014794588088989258\n",
      "\n",
      "Time spent drawing the classifiers: 0.017263412475585938\n",
      "\n",
      "Time spent drawing the classifiers: 0.014848709106445312\n",
      "\n",
      "Time spent drawing the classifiers: 0.014403820037841797\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[12.9697877382362, 12.312980742109836, 11.920074345737147, 11.659988953430435, 11.562660271186097, 11.468223233031974, 11.537100701474532, 11.423630724335693, 11.369850524459535, 11.380570772808918, 11.34771087960748, 11.360593223692282, 11.332095477411318, 11.351159183741434, 11.35505312199961, 11.426288448239196, 11.474331189322667, 11.504608980158222, 11.564815557774839, 11.598392480851965, 11.643194812863024, 11.686593743005774, 11.746323637685073, 11.792189415485, 11.83243509579466, 11.858828757821936, 11.905051750495597, 11.949202848041615, 11.985045611080388, 12.02208656031697, 12.075243019646711, 12.115777170702247, 12.145340654690342, 12.19017276314956, 12.222761302369157, 12.296439119050005, 12.307037159122252, 12.33603790579515, 12.378061388325788, 12.421362774620265, 12.446852130970825, 12.477759585847036, 12.500086026337666, 12.535803083024428, 12.566040965174842, 12.593379882614945, 12.62614495084671, 12.657149502131485, 12.672461171220519, 12.695984890296037, 12.727254369417578, 12.757389952005282, 12.76917571956999]\n",
      "[a, omega]= [1.4, 4.0]\n",
      "sigma:[1, 6]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299, 9846, 10393, 10940, 11487, 12034, 12581, 13128, 13675, 14222, 14769, 15316, 15863, 16410, 16957, 17504, 18051, 18598, 19145, 19692, 20239, 20786, 21333, 21880, 22427]\n",
      "Time spent drawing the classifiers: 0.014431238174438477\n",
      "\n",
      "Time spent drawing the classifiers: 0.014821052551269531\n",
      "\n",
      "Time spent drawing the classifiers: 0.014161348342895508\n",
      "\n",
      "Time spent drawing the classifiers: 0.01518869400024414\n",
      "\n",
      "Time spent drawing the classifiers: 0.014732837677001953\n",
      "\n",
      "Time spent drawing the classifiers: 0.014924287796020508\n",
      "\n",
      "Time spent drawing the classifiers: 0.014096975326538086\n",
      "\n",
      "Time spent drawing the classifiers: 0.01427769660949707\n",
      "\n",
      "Time spent drawing the classifiers: 0.014857053756713867\n",
      "\n",
      "Time spent drawing the classifiers: 0.014793634414672852\n",
      "\n",
      "Time spent drawing the classifiers: 0.01500701904296875\n",
      "\n",
      "Time spent drawing the classifiers: 0.015347480773925781\n",
      "\n",
      "Time spent drawing the classifiers: 0.014519214630126953\n",
      "\n",
      "Time spent drawing the classifiers: 0.014881372451782227\n",
      "\n",
      "Time spent drawing the classifiers: 0.014570236206054688\n",
      "\n",
      "Time spent drawing the classifiers: 0.014878511428833008\n",
      "\n",
      "Time spent drawing the classifiers: 0.014889001846313477\n",
      "\n",
      "Time spent drawing the classifiers: 0.014657258987426758\n",
      "\n",
      "Time spent drawing the classifiers: 0.014380216598510742\n",
      "\n",
      "Time spent drawing the classifiers: 0.01439976692199707\n",
      "\n",
      "Time spent drawing the classifiers: 0.014772891998291016\n",
      "\n",
      "Time spent drawing the classifiers: 0.015009880065917969\n",
      "\n",
      "Time spent drawing the classifiers: 0.015585184097290039\n",
      "\n",
      "Time spent drawing the classifiers: 0.014499664306640625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014805793762207031\n",
      "\n",
      "Time spent drawing the classifiers: 0.014648914337158203\n",
      "\n",
      "Time spent drawing the classifiers: 0.014386177062988281\n",
      "\n",
      "Time spent drawing the classifiers: 0.014862298965454102\n",
      "\n",
      "Time spent drawing the classifiers: 0.01495051383972168\n",
      "\n",
      "Time spent drawing the classifiers: 0.014903068542480469\n",
      "\n",
      "Time spent drawing the classifiers: 0.014189958572387695\n",
      "\n",
      "Time spent drawing the classifiers: 0.014984607696533203\n",
      "\n",
      "Time spent drawing the classifiers: 0.014389991760253906\n",
      "\n",
      "Time spent drawing the classifiers: 0.014638900756835938\n",
      "\n",
      "Time spent drawing the classifiers: 0.015374422073364258\n",
      "\n",
      "Time spent drawing the classifiers: 0.014831304550170898\n",
      "\n",
      "Time spent drawing the classifiers: 0.014583110809326172\n",
      "\n",
      "Time spent drawing the classifiers: 0.014883756637573242\n",
      "\n",
      "Time spent drawing the classifiers: 0.014821529388427734\n",
      "\n",
      "Time spent drawing the classifiers: 0.014692068099975586\n",
      "\n",
      "Time spent drawing the classifiers: 0.01443624496459961\n",
      "\n",
      "Time spent drawing the classifiers: 0.01417088508605957\n",
      "\n",
      "Time spent drawing the classifiers: 0.014789819717407227\n",
      "\n",
      "Time spent drawing the classifiers: 0.014559745788574219\n",
      "\n",
      "Time spent drawing the classifiers: 0.01487874984741211\n",
      "\n",
      "Time spent drawing the classifiers: 0.01446676254272461\n",
      "\n",
      "Time spent drawing the classifiers: 0.015002250671386719\n",
      "\n",
      "Time spent drawing the classifiers: 0.01495504379272461\n",
      "\n",
      "Time spent drawing the classifiers: 0.014845848083496094\n",
      "\n",
      "Time spent drawing the classifiers: 0.01468968391418457\n",
      "\n",
      "Time spent drawing the classifiers: 0.014917135238647461\n",
      "\n",
      "Time spent drawing the classifiers: 0.01532888412475586\n",
      "\n",
      "Time spent drawing the classifiers: 0.01485586166381836\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[27805.371014004566, 27821.22985771224, 27891.756788969866, 27960.446235623313, 28029.750549866814, 28080.882146873242, 28121.627331261825, 28151.31206996724, 28177.053348527945, 28208.627902913802, 28230.291280096997, 28261.442068294124, 28290.03525994794, 28584.158355804975, 28827.294288594494, 29028.220265471657, 29202.65435272547, 29377.61265641273, 29529.720371285155, 29684.261169209734, 29834.07584799405, 29977.198849027172, 30109.94071324123, 30239.467912287706, 30371.784783755676, 30502.445923178515, 30627.04404122267, 30757.780336491593, 30877.571732959084, 30996.798953869504, 31116.320862598375, 31230.0914478438, 31341.48633927369, 31459.208192709528, 31564.086187180656, 31669.791541264996, 31775.69663978886, 31877.036672487648, 31974.97777414198, 32074.42426110603, 32172.564239702617, 32264.635209567623, 32352.522419889196, 32436.16226525891, 32526.169023980263, 32606.617487805608, 32681.60096122947, 32749.230898884787, 32837.16264336327, 32911.56679131635, 32973.8503372151, 33042.68676120926, 33104.64348255367]\n",
      "[a, omega]= [5.5, 10.0]\n",
      "alpha:0.3\n",
      "epsilon:0.03\n",
      "sigma:[3, 2]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094]\n",
      "Time spent drawing the classifiers: 0.014885902404785156\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent drawing the classifiers: 0.01493382453918457\n",
      "\n",
      "Time spent drawing the classifiers: 0.014458179473876953\n",
      "\n",
      "Time spent drawing the classifiers: 0.014531135559082031\n",
      "\n",
      "Time spent drawing the classifiers: 0.01554560661315918\n",
      "\n",
      "Time spent drawing the classifiers: 0.014876842498779297\n",
      "\n",
      "Time spent drawing the classifiers: 0.014865398406982422\n",
      "\n",
      "Time spent drawing the classifiers: 0.014881372451782227\n",
      "\n",
      "Time spent drawing the classifiers: 0.015071630477905273\n",
      "\n",
      "Time spent drawing the classifiers: 0.014900684356689453\n",
      "\n",
      "Time spent drawing the classifiers: 0.014809846878051758\n",
      "\n",
      "Time spent drawing the classifiers: 0.014220237731933594\n",
      "\n",
      "Time spent drawing the classifiers: 0.01524043083190918\n",
      "\n",
      "Time spent drawing the classifiers: 0.014928102493286133\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[2.3572360777094143, 2.372990491589828, 2.4401364384260096, 2.3702659443212637, 2.3429094858205284, 2.342799122745534, 2.464199185418117, 2.344202416538727, 2.3382693490725406, 2.315680380562368, 2.332630433724022, 2.3454896344872074, 2.3183014882228057, 2.331017222352338]\n",
      "[a, omega]= [0.7, 3.0]\n",
      "sigma:[3, 3]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094]\n",
      "Time spent drawing the classifiers: 0.014925718307495117\n",
      "\n",
      "Time spent drawing the classifiers: 0.014454841613769531\n",
      "\n",
      "Time spent drawing the classifiers: 0.015017271041870117\n",
      "\n",
      "Time spent drawing the classifiers: 0.014529705047607422\n",
      "\n",
      "Time spent drawing the classifiers: 0.014316082000732422\n",
      "\n",
      "Time spent drawing the classifiers: 0.014636754989624023\n",
      "\n",
      "Time spent drawing the classifiers: 0.014569520950317383\n",
      "\n",
      "Time spent drawing the classifiers: 0.014198064804077148\n",
      "\n",
      "Time spent drawing the classifiers: 0.014086008071899414\n",
      "\n",
      "Time spent drawing the classifiers: 0.014342546463012695\n",
      "\n",
      "Time spent drawing the classifiers: 0.014288663864135742\n",
      "\n",
      "Time spent drawing the classifiers: 0.014066934585571289\n",
      "\n",
      "Time spent drawing the classifiers: 0.014017343521118164\n",
      "\n",
      "Time spent drawing the classifiers: 0.014045476913452148\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[12.391817251576269, 12.414797420528567, 12.414846293712364, 12.368066144638567, 12.350932875877822, 12.37710670642432, 12.382232737159008, 12.342035030872047, 12.343480274298573, 12.323189519762915, 12.316266993084534, 12.33021823216135, 12.322017785405691, 12.358304914026476]\n",
      "[a, omega]= [1.4, 5.0]\n",
      "sigma:[1, 6]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094]\n",
      "Time spent drawing the classifiers: 0.014185667037963867\n",
      "\n",
      "Time spent drawing the classifiers: 0.014790773391723633\n",
      "\n",
      "Time spent drawing the classifiers: 0.01413273811340332\n",
      "\n",
      "Time spent drawing the classifiers: 0.013749837875366211\n",
      "\n",
      "Time spent drawing the classifiers: 0.014130353927612305\n",
      "\n",
      "Time spent drawing the classifiers: 0.01414179801940918\n",
      "\n",
      "Time spent drawing the classifiers: 0.014795541763305664\n",
      "\n",
      "Time spent drawing the classifiers: 0.014749288558959961\n",
      "\n",
      "Time spent drawing the classifiers: 0.014947175979614258\n",
      "\n",
      "Time spent drawing the classifiers: 0.014075517654418945\n",
      "\n",
      "Time spent drawing the classifiers: 0.014563322067260742\n",
      "\n",
      "Time spent drawing the classifiers: 0.014723539352416992\n",
      "\n",
      "Time spent drawing the classifiers: 0.01405191421508789\n",
      "\n",
      "Time spent drawing the classifiers: 0.014077425003051758\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[32124.932662951178, 32078.079468013042, 32045.361938453818, 32035.09061735373, 32026.631513238233, 32014.102849367202, 32010.190126818456, 32010.530127873568, 32009.727183731975, 32011.23095606813, 32013.907376416464, 32019.036884774418, 32024.544626526902, 32076.43743073708]\n",
      "[a, omega]= [5.5, 13.0]\n",
      "epsilon:0.01\n",
      "sigma:[3, 2]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282]\n",
      "Time spent drawing the classifiers: 0.014076948165893555\n",
      "\n",
      "Time spent drawing the classifiers: 0.014150857925415039\n",
      "\n",
      "Time spent drawing the classifiers: 0.014174222946166992\n",
      "\n",
      "Time spent drawing the classifiers: 0.014712333679199219\n",
      "\n",
      "Time spent drawing the classifiers: 0.014333248138427734\n",
      "\n",
      "Time spent drawing the classifiers: 0.014606952667236328\n",
      "\n",
      "Time spent drawing the classifiers: 0.014099597930908203\n",
      "\n",
      "Time spent drawing the classifiers: 0.014129638671875\n",
      "\n",
      "Time spent drawing the classifiers: 0.014705419540405273\n",
      "\n",
      "Time spent drawing the classifiers: 0.0148162841796875\n",
      "\n",
      "Time spent drawing the classifiers: 0.014080524444580078\n",
      "\n",
      "Time spent drawing the classifiers: 0.014008283615112305\n",
      "\n",
      "Time spent drawing the classifiers: 0.014091014862060547\n",
      "\n",
      "Time spent drawing the classifiers: 0.014180183410644531\n",
      "\n",
      "Time spent drawing the classifiers: 0.014853954315185547\n",
      "\n",
      "Time spent drawing the classifiers: 0.014065027236938477\n",
      "\n",
      "Time spent drawing the classifiers: 0.014603853225708008\n",
      "\n",
      "Time spent drawing the classifiers: 0.014644384384155273\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[2.3659825228705182, 2.387577519947004, 2.3857081428501288, 2.3519938180388067, 2.376856338192983, 2.340882304672397, 2.3319999632968393, 2.319064062723064, 2.3362646551960644, 2.322825951190046, 2.340868998111555, 2.3158627131102962, 2.3223853657357294, 2.302946391856676, 2.322470411401703, 2.3364997866083357, 2.3075581430473706, 2.3340385287195327]\n",
      "[a, omega]= [0.7, 3.0]\n",
      "sigma:[3, 3]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282]\n",
      "Time spent drawing the classifiers: 0.014287948608398438\n",
      "\n",
      "Time spent drawing the classifiers: 0.014601469039916992\n",
      "\n",
      "Time spent drawing the classifiers: 0.014066934585571289\n",
      "\n",
      "Time spent drawing the classifiers: 0.01407480239868164\n",
      "\n",
      "Time spent drawing the classifiers: 0.014204025268554688\n",
      "\n",
      "Time spent drawing the classifiers: 0.014053821563720703\n",
      "\n",
      "Time spent drawing the classifiers: 0.014499425888061523\n",
      "\n",
      "Time spent drawing the classifiers: 0.014437437057495117\n",
      "\n",
      "Time spent drawing the classifiers: 0.014222383499145508\n",
      "\n",
      "Time spent drawing the classifiers: 0.014861583709716797\n",
      "\n",
      "Time spent drawing the classifiers: 0.014444589614868164\n",
      "\n",
      "Time spent drawing the classifiers: 0.015432119369506836\n",
      "\n",
      "Time spent drawing the classifiers: 0.015020132064819336\n",
      "\n",
      "Time spent drawing the classifiers: 0.014974594116210938\n",
      "\n",
      "Time spent drawing the classifiers: 0.014535665512084961\n",
      "\n",
      "Time spent drawing the classifiers: 0.014767646789550781\n",
      "\n",
      "Time spent drawing the classifiers: 0.014895439147949219\n",
      "\n",
      "Time spent drawing the classifiers: 0.014937877655029297\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[12.398674704099317, 12.453987262028823, 12.402958311224495, 12.388701406148476, 12.36268870168566, 12.354279064451676, 12.333765242073108, 12.323580203584724, 12.317879506318778, 12.339817835703728, 12.321430616410073, 12.32175465863733, 12.317989902788852, 12.314927397667999, 12.339526520690738, 12.360318348027473, 12.377876190534739, 12.401751748671758]\n",
      "[a, omega]= [1.4, 5.5]\n",
      "sigma:[1, 6]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282]\n",
      "Time spent drawing the classifiers: 0.015061616897583008\n",
      "\n",
      "Time spent drawing the classifiers: 0.014890432357788086\n",
      "\n",
      "Time spent drawing the classifiers: 0.014935970306396484\n",
      "\n",
      "Time spent drawing the classifiers: 0.014561176300048828\n",
      "\n",
      "Time spent drawing the classifiers: 0.013737201690673828\n",
      "\n",
      "Time spent drawing the classifiers: 0.014075994491577148\n",
      "\n",
      "Time spent drawing the classifiers: 0.01462864875793457\n",
      "\n",
      "Time spent drawing the classifiers: 0.014896392822265625\n",
      "\n",
      "Time spent drawing the classifiers: 0.014825820922851562\n",
      "\n",
      "Time spent drawing the classifiers: 0.014611005783081055\n",
      "\n",
      "Time spent drawing the classifiers: 0.013710260391235352\n",
      "\n",
      "Time spent drawing the classifiers: 0.014553546905517578\n",
      "\n",
      "Time spent drawing the classifiers: 0.014754772186279297\n",
      "\n",
      "Time spent drawing the classifiers: 0.014801263809204102\n",
      "\n",
      "Time spent drawing the classifiers: 0.015290021896362305\n",
      "\n",
      "Time spent drawing the classifiers: 0.014477729797363281\n",
      "\n",
      "Time spent drawing the classifiers: 0.015268325805664062\n",
      "\n",
      "Time spent drawing the classifiers: 0.01481485366821289\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[32124.97322155523, 32074.083712697524, 32033.352604152875, 32022.152537926748, 32011.46747257051, 32009.042038378717, 32003.149512608466, 32002.04186248579, 31999.35184940294, 32002.698916134505, 32002.199042090833, 32002.444437937975, 32008.41352312284, 32052.258403596494, 32131.147612472967, 32214.39872069264, 32304.533784039624, 32406.65152560926]\n",
      "[a, omega]= [5.5, 13.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon:0.001\n",
      "sigma:[3, 2]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299, 9846, 10393, 10940, 11487, 12034, 12581, 13128, 13675]\n",
      "Time spent drawing the classifiers: 0.014852046966552734\n",
      "\n",
      "Time spent drawing the classifiers: 0.014862060546875\n",
      "\n",
      "Time spent drawing the classifiers: 0.014855384826660156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014494180679321289\n",
      "\n",
      "Time spent drawing the classifiers: 0.014722347259521484\n",
      "\n",
      "Time spent drawing the classifiers: 0.01473689079284668\n",
      "\n",
      "Time spent drawing the classifiers: 0.014816999435424805\n",
      "\n",
      "Time spent drawing the classifiers: 0.015004873275756836\n",
      "\n",
      "Time spent drawing the classifiers: 0.014085054397583008\n",
      "\n",
      "Time spent drawing the classifiers: 0.01396942138671875\n",
      "\n",
      "Time spent drawing the classifiers: 0.015001058578491211\n",
      "\n",
      "Time spent drawing the classifiers: 0.014842987060546875\n",
      "\n",
      "Time spent drawing the classifiers: 0.014510631561279297\n",
      "\n",
      "Time spent drawing the classifiers: 0.014990568161010742\n",
      "\n",
      "Time spent drawing the classifiers: 0.014733314514160156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014804601669311523\n",
      "\n",
      "Time spent drawing the classifiers: 0.014454126358032227\n",
      "\n",
      "Time spent drawing the classifiers: 0.01486063003540039\n",
      "\n",
      "Time spent drawing the classifiers: 0.014931678771972656\n",
      "\n",
      "Time spent drawing the classifiers: 0.014481782913208008\n",
      "\n",
      "Time spent drawing the classifiers: 0.014364957809448242\n",
      "\n",
      "Time spent drawing the classifiers: 0.014023542404174805\n",
      "\n",
      "Time spent drawing the classifiers: 0.014094114303588867\n",
      "\n",
      "Time spent drawing the classifiers: 0.017205476760864258\n",
      "\n",
      "Time spent drawing the classifiers: 0.015069007873535156\n",
      "\n",
      "Time spent drawing the classifiers: 0.014252424240112305\n",
      "\n",
      "Time spent drawing the classifiers: 0.014633417129516602\n",
      "\n",
      "Time spent drawing the classifiers: 0.014662027359008789\n",
      "\n",
      "Time spent drawing the classifiers: 0.01506185531616211\n",
      "\n",
      "Time spent drawing the classifiers: 0.0149993896484375\n",
      "\n",
      "Time spent drawing the classifiers: 0.014861345291137695\n",
      "\n",
      "Time spent drawing the classifiers: 0.014728307723999023\n",
      "\n",
      "Time spent drawing the classifiers: 0.014787673950195312\n",
      "\n",
      "Time spent drawing the classifiers: 0.014672517776489258\n",
      "\n",
      "Time spent drawing the classifiers: 0.014693498611450195\n",
      "\n",
      "Time spent drawing the classifiers: 0.014878034591674805\n",
      "\n",
      "Time spent drawing the classifiers: 0.014822959899902344\n",
      "\n",
      "Finished calculation of bound parts\n",
      "Starting gridsearch....\n",
      "Germain bound[2.3983526261705763, 2.50150762303694, 2.4178945832297893, 2.359705254195711, 2.3574740720680727, 2.3602728860600264, 2.3370903857969667, 2.326297087108209, 2.3437152129996606, 2.344200506871047, 2.3322395085906313, 2.348175842144217, 2.321832666028653, 2.3255377300099074, 2.3136921617105974, 2.309867313888747, 2.3406023373490727, 2.303430681340356, 2.3140235778998006, 2.3434811512531786, 2.331676212737684, 2.3568244645422265, 2.358429658182133, 2.3377190908506416, 2.351668800244574, 2.339262237866587, 2.336776186292131, 2.352019629458942, 2.357079194294695, 2.3488332251086312, 2.3759117660535995, 2.3544171523453667, 2.3413912234119088, 2.4050445680621584, 2.372011666417767, 2.3612458497085655, 2.351188628078591]\n",
      "[a, omega]= [0.7, 3.0]\n",
      "sigma:[3, 3]\n",
      "[0, 45, 90, 135, 180, 225, 270, 315, 360, 405, 450, 495, 540, 1094, 1641, 2188, 2735, 3282, 3829, 4376, 4923, 5470, 6017, 6564, 7111, 7658, 8205, 8752, 9299, 9846, 10393, 10940, 11487, 12034, 12581, 13128, 13675]\n",
      "Time spent drawing the classifiers: 0.014723777770996094\n",
      "\n",
      "Time spent drawing the classifiers: 0.014661788940429688\n",
      "\n",
      "Time spent drawing the classifiers: 0.014365673065185547\n",
      "\n",
      "Time spent drawing the classifiers: 0.013881206512451172\n",
      "\n",
      "Time spent drawing the classifiers: 0.013735294342041016\n",
      "\n",
      "Time spent drawing the classifiers: 0.014410734176635742\n",
      "\n",
      "Time spent drawing the classifiers: 0.014691591262817383\n",
      "\n",
      "Time spent drawing the classifiers: 0.014105796813964844\n",
      "\n",
      "Time spent drawing the classifiers: 0.014761686325073242\n",
      "\n",
      "Time spent drawing the classifiers: 0.014693975448608398\n",
      "\n",
      "Time spent drawing the classifiers: 0.015036344528198242\n",
      "\n",
      "Time spent drawing the classifiers: 0.014938831329345703\n",
      "\n",
      "Time spent drawing the classifiers: 0.014719009399414062\n",
      "\n",
      "Time spent drawing the classifiers: 0.014626741409301758\n",
      "\n",
      "Time spent drawing the classifiers: 0.0139007568359375\n",
      "\n",
      "Time spent drawing the classifiers: 0.014778375625610352\n",
      "\n",
      "Time spent drawing the classifiers: 0.014083385467529297\n",
      "\n",
      "Time spent drawing the classifiers: 0.01419377326965332\n",
      "\n",
      "Time spent drawing the classifiers: 0.014076709747314453\n",
      "\n",
      "Time spent drawing the classifiers: 0.014731884002685547\n",
      "\n",
      "Time spent drawing the classifiers: 0.014978170394897461\n",
      "\n",
      "Time spent drawing the classifiers: 0.014750480651855469\n",
      "\n",
      "Time spent drawing the classifiers: 0.015192270278930664\n",
      "\n",
      "Time spent drawing the classifiers: 0.013826370239257812\n",
      "\n",
      "Time spent drawing the classifiers: 0.014835119247436523\n",
      "\n",
      "Time spent drawing the classifiers: 0.014715909957885742\n",
      "\n",
      "Time spent drawing the classifiers: 0.014824151992797852\n",
      "\n",
      "Time spent drawing the classifiers: 0.014735698699951172\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-96a39cd29033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigmas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sigma:\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m               \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgermain_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_target_bin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTASK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-126-d0456c06a057>\u001b[0m in \u001b[0;36mgermain_bound\u001b[0;34m(x_bound, y_bound, x_target, y_target, alpha, sigma, epsilon, task, Binary)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m## get the prior weights for the KL and pass into read_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_weights_germain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs_trained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma_tmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBinary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTASK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-126-d0456c06a057>\u001b[0m in \u001b[0;36mread_weights_germain\u001b[0;34m(model, w_a, x_bound, y_bound, x_target, y_target, epochs_trained, sigma, epsilon, alpha, Binary, Task)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_s_draws\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0merrorsum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_bound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0merrorsum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mtarget_errorsum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtarget_errorsum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "delta=0.05\n",
    "Binary=True\n",
    "if alpha==0:\n",
    "    x_bound=x_source\n",
    "    y_bound=y_source\n",
    "    if Binary:\n",
    "        y_bound=make_mnist_binary(y_bound)\n",
    "        #x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source_bin,test_size=alpha,random_state=69105)\n",
    "else:\n",
    "    if Binary:\n",
    "        y_source_bin=make_mnist_binary(y_source)\n",
    "        x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source_bin,test_size=alpha,random_state=69105)\n",
    "    else:\n",
    "        x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source,test_size=alpha,random_state=69105)\n",
    "    \n",
    "epsilons=[0.03,0.01,0.001]#,0.01,0.001]\n",
    "#epsilons=[0.01,0.001]\n",
    "#sigmas=[0.003]\n",
    "#sigmas=[0.00001,0.0003,0.000001,0.00003]\n",
    "alphas=[0,0.3,0.5]#,0.3]#,0.3]#0.3,0.4,0.6]\n",
    "#alphas=[0]\n",
    "sigmas=[[3,2],[3,3],[1,6]]\n",
    "\n",
    "#for i in range(2,9):  \n",
    "#    sigmas.append([3,i])#3*10**(-i))\n",
    "#    if(i==8):\n",
    "#        break\n",
    "#    sigmas.append([1,i])#10**(-i))\n",
    "\n",
    "#errors=[428, 468, 1247, 1256, 2235, 2348, 2539, 2723, 2797, 3058, 3075, 3717, 3902, 3998, 4210, 4703, 4714, 4801, 5086, 5090, 5276, 5323, 5335, 5392, 5559, 5779, 6082, 6304, 6308, 6351, 6354, 6363, 6388, 6510, 6584, 6615, 6624, 6632, 6703, 6766, 6838, 6839, 6926, 7061, 7089, 7224, 7331, 7334, 7338, 7369, 7429, 7627, 7726, 7731, 7764, 7847, 7872, 7954, 8122, 8259, 8290, 8307, 8547, 8577, 8803, 8842, 8846, 8860, 8972, 9201, 9303, 9427, 9566, 9570, 9642, 9723, 9917, 10272, 10316, 10609, 10621, 10715, 10735, 10751, 10878, 10897, 11006, 11203, 11206, 11256, 11267, 11362, 11372, 11450, 11544, 11632, 11701, 12033, 12135, 12141, 12874, 13101, 13194, 13380, 14147, 14501, 14683, 15246, 15297, 15569, 15589, 15604, 15632, 15659, 15750, 15926, 16045, 16224, 16237, 16246, 16291, 16341, 16426, 16520, 16525, 16549, 16554, 16686, 16763, 16780, 16792, 16803, 16814, 16820, 16891, 16907, 16912, 17015, 17048, 17053, 17183, 17216, 17230, 17272, 17286, 17310, 17418, 17432, 17441, 17663, 17875, 17881, 17904, 17941, 17971, 18031, 18230, 18270, 18339, 18370, 18440, 18471, 18547, 18643, 18660, 18694, 18708, 18777, 18805, 18811, 18818, 18963, 19082, 19101, 19114, 19124, 19194, 19248, 19319, 19357, 19369, 19383, 19464, 19510, 19521, 19554, 19582, 19694, 19841, 19845, 19905, 19935, 19974, 19998, 20002, 20268, 20276, 20302, 20339, 20343, 20386, 20395, 20454, 20473, 20595, 20814, 20817, 20858, 21059, 21445, 21449, 21516, 21518, 21527, 21557, 21559, 21566, 21614, 21645, 21801, 21826, 21868, 21883, 21941, 21947, 22002, 22008, 22160, 22167, 22179, 22274, 22411, 22452, 22536, 22649, 22650, 22662, 22672, 22700, 22704, 22718, 22839, 22872, 22883, 22892, 23001, 23035, 23152, 23162, 23169, 23210, 23227, 23259, 23277, 23418, 23578, 23584, 23688, 23741, 23760, 23777, 23790, 23829, 23957, 24056, 24059, 24089, 24150, 24157, 24182, 24295, 24339, 24387, 24429, 24695, 24753, 24873, 24907, 24943, 25004, 25036, 25084, 25287, 25316, 25317, 25329, 25376, 25412, 25492, 25544, 25612, 25618, 25636, 25854, 26071, 26084, 26151, 26177, 26479, 26493, 26523, 26539, 26641, 26667, 26713, 26737, 27030, 27222, 27239, 27326, 27429, 27502, 27511, 27548, 27567, 27675, 27817, 27832, 27890, 27932, 27947, 28193, 28341, 28364, 28377, 28411, 28453, 28528, 28564, 28885, 28896, 28912, 28943, 28991, 29029, 29119, 29185, 29225, 29233, 29289, 29339, 29468, 29551, 29561, 29584, 29623, 29705, 29740, 29749, 29887, 29893, 29897, 29924, 30014, 30048, 30193, 30194, 30228, 30354, 30390, 30403, 30450, 30494, 30647, 30655, 30697, 30757, 31068, 31078, 31126, 31152, 31160, 31161, 31190, 31255, 31273, 31325, 31373, 31389, 31731, 31803, 31824, 31827, 31829, 31837, 31841, 31845, 31850, 31865, 31868, 31893, 31921, 31939, 31950, 31957, 31977, 31985, 32008, 32010, 32019, 32023, 32045, 32054, 32071, 32075, 32083, 32087, 32097, 32101, 32111, 32112, 32143, 32152, 32161, 32176, 32216, 32226, 32229, 32241, 32245, 32249, 32251, 32252, 32267, 32281, 32286, 32305, 32306, 32311, 32321, 32337, 32346, 32348, 32358, 32370, 32391, 32396, 32417, 32419, 32443, 32446, 32478, 32480, 32486, 32488, 32491, 32500, 32526, 32527, 32529, 32530, 32555, 32572, 32587, 32591, 32595, 32597, 32612, 32617, 32646, 32650, 32652, 32658, 32667, 32687, 32692, 32702, 32703, 32710, 32728, 32729, 32751, 32752, 32770, 32789, 32804, 32805, 32814, 32817, 32826, 32834, 32842, 32849, 32856, 32859, 32862, 32874, 32878, 32886, 32890, 32897, 32922, 32929, 32946, 32959, 32974, 32993, 33005, 33015, 33017, 33027, 33040, 33043, 33088, 33101, 33115, 33117, 33127, 33145, 33150, 33154, 33156, 33159, 33162, 33193, 33206, 33214, 33221, 33230, 33234, 33260, 33261, 33266, 33310, 33322, 33356, 33363, 33364, 33367, 33377, 33390, 33404, 33407, 33410, 33412, 33431, 33437, 33438, 33441, 33447, 33452, 33463, 33477, 33480, 33553, 33573, 33578, 33592, 33603, 33634, 33639, 33640, 33650, 33668, 33673, 33678, 33700, 33717, 33733, 33766, 33781, 33784, 33802, 33834, 33835, 33842, 33844, 33850, 33861, 33868, 33904, 33919, 33925, 33930, 33931, 33968, 33995, 34006, 34012, 34014, 34026, 34030, 34031, 34037, 34039, 34087, 34094, 34101, 34120, 34153, 34163, 34185, 34200, 34217, 34220, 34237, 34239, 34263, 34265, 34271, 34295, 34297, 34298, 34300, 34301, 34302, 34311, 34315, 34318, 34324, 34346, 34351, 34359, 34376, 34378, 34384, 34400, 34436, 34447, 34459, 34482, 34493, 34494, 34500, 34525, 34543, 34555, 34584, 34585, 34588, 34598, 34599, 34602, 34610, 34655, 34666, 34673, 34678, 34683, 34687, 34699, 34705, 34706, 34712, 34713, 34714, 34724, 34728, 34729, 34732, 34738, 34747, 34752, 34756, 34773, 34789, 34795, 34806, 34807, 34808, 34815, 34823, 34840, 34850, 34865, 34872, 34881, 34884, 34916, 34935, 34946, 34963, 35021, 35039, 35041, 35043, 35046, 35048, 35049, 35086, 35094, 35108, 35110, 35118, 35122, 35124, 35125, 35158, 35179, 35196, 35210, 35214, 35225, 35233, 35253, 35260, 35277, 35278, 35279, 35318, 35325, 35339, 35341, 35343, 35347, 35358, 35365, 35371, 35373, 35374, 35377, 35383, 35419, 35430, 35435, 35445, 35452, 35491, 35495, 35503, 35533, 35550, 35557, 35559, 35565, 35578, 35580, 35590, 35597, 35606, 35619, 35633, 35634, 35639, 35642, 35660, 35662, 35663, 35673, 35691, 35702, 35708, 35709, 35718, 35761, 35775, 35776, 35777, 35792, 35809, 35866, 35892, 35910, 35912, 35928, 35951, 35954, 35966, 35998, 36001, 36002, 36008, 36018, 36020, 36031, 36038, 36049, 36053, 36055, 36088, 36095, 36108, 36123, 36162, 36165, 36170, 36178, 36228, 36229, 36235, 36236, 36257, 36260, 36261, 36268, 36285, 36286, 36289, 36304, 36306, 36307, 36313, 36321, 36323, 36340, 36349, 36357, 36360, 36361, 36362, 36364, 36369, 36392, 36414, 36419, 36434, 36435, 36438, 36442, 36443, 36451, 36470, 36477, 36479, 36480, 36486, 36501, 36518, 36532, 36538, 36539, 36544, 36571, 36577, 36579, 36588, 36590, 36620, 36628, 36629, 36645, 36659, 36660, 36686, 36703, 36715, 36719, 36734, 36736, 36737, 36761, 36771, 36781, 36824, 36826, 36832, 36844, 36848, 36917, 36937, 36942, 36945, 36951, 36977, 37020, 37031, 37040, 37041, 37046, 37061, 37071, 37111, 37112, 37125, 37163, 37171, 37207, 37223, 37228, 37240, 37246, 37251, 37252, 37265, 37271, 37277, 37281, 37295, 37296, 37314, 37315, 37346, 37350, 37377, 37380, 37390, 37391, 37403, 37423, 37428, 37432, 37438, 37443, 37452, 37453, 37457, 37466, 37495, 37535, 37539, 37579, 37612, 37623, 37625, 37654, 37657, 37675, 37676, 37699, 37708, 37711, 37729, 37736, 37787, 37797, 37805, 37832, 37836, 37856, 37865, 37870, 37875, 37880, 37889, 37905, 37939, 37951, 37953, 37966, 37967, 37971, 37985, 38038, 38043, 38066, 38081, 38101, 38113, 38118, 38136, 38138, 38145, 38151, 38181, 38236, 38253, 38257, 38263, 38293, 38327, 38332, 38337, 38340, 38357, 38385, 38409, 38413, 38416, 38452, 38455, 38471, 38507, 38516, 38521, 38532, 38536, 38545, 38548, 38550, 38554, 38562, 38571, 38584, 38585, 38590, 38593, 38603, 38609, 38611, 38632, 38653, 38671, 38692, 38694, 38753, 38756, 38775, 38777, 38778, 38813, 38820, 38854, 38858, 38860, 38879, 38881, 38889, 38893, 38928, 38930, 38983, 38988, 39054, 39084, 39103, 39108, 39126, 39129, 39139, 39167, 39190, 39231, 39257, 39277, 39284, 39318, 39328, 39344, 39350, 39401, 39440, 39447, 39464, 39485, 39489, 39515, 39528, 39535, 39549, 39550, 39566, 39600, 39602, 39604, 39635, 39639, 39643, 39657, 39662, 39717, 39726, 39747, 39776, 39777, 39778, 39781, 39826, 39828, 39830, 39842, 39843, 39848, 39861, 39866, 39894, 39902, 39905, 39912, 39955, 39962, 39978, 39985, 39986, 39994, 40013, 40053, 40072, 40112, 40115, 40138, 40173, 40188, 40195, 40209, 40214, 40218, 40224, 40229, 40241, 40256, 40288, 40300, 40315, 40329, 40349, 40355, 40358, 40393, 40423, 40442, 40458, 40463, 40465, 40469, 40482, 40510, 40515, 40520, 40529, 40530, 40541, 40577, 40584, 40591, 40595, 40607, 40656, 40668, 40685, 40687, 40692, 40693, 40699, 40729, 40739, 40747, 40800, 40838, 40898, 40904, 40922, 40933, 40938, 40941, 40942, 40968, 40991, 41002, 41010, 41030, 41040, 41074, 41176, 41187, 41193, 41204, 41217, 41233, 41236, 41249, 41300, 41322, 41331, 41337, 41340, 41343, 41379, 41383, 41445, 41483, 41490, 41517, 41536, 41547, 41569, 41573, 41575, 41580, 41583, 41596, 41612, 41613, 41619, 41624, 41651, 41656, 41661, 41663, 41664, 41696, 41697, 41704, 41712, 41714, 41726, 41730, 41735, 41745, 41747, 41754, 41756, 41758, 41766, 41767, 41792, 41801, 41805, 41816, 41821, 41834, 41848, 41856, 41876, 41879, 41908, 41927, 41957, 41973, 42017, 42038, 42047, 42049, 42061, 42089, 42096, 42099, 42117, 42123, 42133, 42140, 42157, 42177, 42179, 42182, 42199, 42201, 42255, 42274, 42292, 42314, 42316, 42317, 42319, 42327, 42347, 42348, 42353, 42410, 42426, 42443, 42453, 42501, 42504, 42508, 42520, 42531, 42556, 42561, 42565, 42575, 42605, 42623, 42634, 42636, 42641, 42661, 42663, 42690, 42731, 42742, 42744, 42751, 42755, 42767, 42772, 42804, 42806, 42809, 42814, 42898, 42924, 42928, 42942, 42948, 42966, 43008, 43021, 43081, 43083, 43103, 43106, 43142, 43160, 43191, 43212, 43233, 43243, 43248, 43278, 43296, 43341, 43350, 43364, 43382, 43384, 43403, 43427, 43457, 43477, 43488, 43494, 43508, 43515, 43583, 43593, 43598, 43608, 43611, 43635, 43676, 43677, 43694, 43722, 43775, 43777, 43779, 43787, 43793, 43801, 43802, 43822, 43827, 43829, 43833, 43858, 43859, 43873, 43874, 43880, 43896, 43897, 43931, 43950, 43961, 43965, 43977, 43990, 44025, 44066, 44115, 44126, 44174, 44198, 44269, 44304, 44305, 44321, 44326, 44342, 44364, 44377, 44436, 44471, 44486, 44489, 44491, 44505, 44543, 44554, 44566, 44577, 44584, 44600, 44602, 44640, 44650, 44656, 44662, 44673, 44710, 44736, 44743, 44759, 44773, 44816, 44859, 44905, 44910, 44932, 44974, 44997, 45015, 45057, 45076, 45100, 45106, 45134, 45159, 45193, 45215, 45232, 45259, 45277, 45338, 45457, 45496, 45497, 45560, 45590, 45607, 45608, 45614, 45631, 45656, 45683, 45709, 45732, 45736, 45740, 45754, 45818, 45925, 45935, 45948, 45955, 45986, 45998, 46017, 46036, 46065, 46079, 46103, 46110, 46165, 46230, 46266, 46292, 46294, 46301, 46307, 46315, 46321, 46382, 46386, 46394, 46417, 46443, 46485, 46517, 46564, 46600, 46628, 46644, 46651, 46673, 46684, 46737, 46776, 46785, 46855, 46942, 47040, 47084, 47162, 47232, 47237, 47286, 47292, 47346, 47355, 47396, 47458, 47482, 47491, 47579, 47597, 47602, 47682, 47703, 47741, 47823, 47835, 47839, 47840, 47894, 47928, 47964, 47966, 47977, 48004, 48029, 48075, 48090, 48101, 48108, 48141, 48144, 48157, 48159, 48166, 48176, 48212, 48222, 48256, 48264, 48322, 48329, 48341, 48344, 48346, 48349, 48377, 48380, 48384, 48416, 48460, 48470, 48491, 48502, 48512, 48521, 48528, 48539, 48558, 48582, 48599, 48618, 48624, 48631, 48664, 48729, 48800, 48810, 48835, 48897, 48907, 48921, 48922, 48960, 48982, 49003, 49019, 49032, 49050, 49063, 49077, 49167, 49205, 49211, 49238, 49259, 49267, 49270, 49272, 49310, 49328, 49415, 49430, 49443, 49524, 49558, 49605, 49712, 49747, 49753, 49797, 49884, 49897, 49916, 49940, 49966, 49973, 49974, 49981, 50002, 50005, 50015, 50096, 50098, 50115, 50126, 50158, 50208, 50218, 50227, 50244, 50247, 50265, 50296, 50331, 50333, 50336, 50353, 50367, 50370, 50371, 50388, 50421, 50450, 50463, 50473, 50494, 50517, 50525, 50539, 50547, 50548, 50581, 50669, 50672, 50708, 50730, 50763, 50821, 50832, 50856, 50876, 50907, 50913, 50919, 50953, 50961, 50969, 51025, 51033, 51041, 51047, 51096, 51104, 51118, 51178, 51179, 51207, 51218, 51224, 51251, 51271, 51278, 51298, 51300, 51327, 51337, 51339, 51343, 51391, 51394, 51396, 51404, 51405, 51416, 51465, 51470, 51471, 51481, 51544, 51564, 51577, 51594, 51602, 51638, 51646, 51688, 51695, 51712, 51739, 51745, 51832, 51842, 51907, 51911, 51919, 51935, 51944, 51951, 51967, 51972, 51975, 52020, 52026, 52041, 52043, 52045, 52060, 52088, 52098, 52100, 52130, 52138, 52151, 52198, 52279, 52280, 52318, 52340, 52343, 52353, 52356, 52375, 52382, 52389, 52457, 52459, 52486, 52492, 52495, 52497, 52583, 52619, 52758, 52759, 52777, 52784, 52786, 52819, 52843, 52860, 52861, 52911, 52914, 52919, 52922, 52930, 52942, 52943, 52958, 52995, 53006, 53025, 53034, 53044, 53055, 53076, 53082, 53088, 53095, 53107, 53109, 53120, 53128, 53135, 53143, 53144, 53189, 53192, 53204, 53212, 53215, 53216, 53230, 53234, 53241, 53343, 53363, 53398, 53399, 53440, 53443, 53454, 53513, 53568, 53593, 53608, 53618, 53629, 53649, 53679, 53690, 53716, 53720, 53769, 53784, 53786, 53787, 53805, 53818, 53862, 53888, 53908, 53923, 53961, 54013, 54028, 54035, 54036, 54109, 54287, 54335, 54340, 54386, 54387, 54409, 54419, 54431, 54447, 54469, 54581, 54586, 54611, 54677, 54682, 54727, 54756, 54782, 54809, 54818, 54820, 54890, 54903, 54904, 54907, 54914, 54920, 54930, 54960, 54977, 54991, 54992, 54994, 54997, 55026, 55048, 55060, 55087, 55099, 55101, 55102, 55117, 55137, 55146, 55164, 55170, 55175, 55181, 55204, 55207, 55209, 55222, 55238, 55256, 55268, 55278, 55283, 55302, 55303, 55328, 55337, 55360, 55366, 55381, 55385, 55387, 55408, 55433, 55435, 55441, 55465, 55466, 55480, 55486, 55491, 55496, 55521, 55526, 55535, 55537, 55538, 55560, 55570, 55574, 55619, 55622, 55625, 55654, 55657, 55670, 55691, 55693, 55702, 55721, 55722, 55736, 55743, 55762, 55788, 55821, 55851, 55854, 55865, 55869, 55887, 55895, 55921, 55953, 55964, 55968, 55976, 55977, 55981, 55985, 55986, 56005, 56016, 56023, 56040, 56042, 56055, 56072, 56081, 56086, 56100, 56110, 56140, 56150, 56201, 56215, 56221, 56234, 56241, 56249, 56262, 56266, 56267, 56272, 56293, 56312, 56313, 56353, 56361, 56382, 56396, 56398, 56403, 56433, 56436, 56465, 56468, 56491, 56503, 56522, 56543, 56548, 56549, 56555, 56559, 56571, 56584, 56590, 56618, 56627, 56649, 56661, 56692, 56740, 56746, 56747, 56749, 56762, 56776, 56797, 56809, 56810, 56823, 56827, 56833, 56834, 56840, 56849, 56851, 56858, 56861, 56864, 56894, 56905, 56907, 56918, 56929, 56931, 56961, 56974, 56977, 56985, 56996, 57015, 57028, 57125, 57167, 57179, 57191, 57211, 57214, 57253, 57255, 57259, 57281, 57296, 57303, 57314, 57330, 57351, 57384, 57390, 57402, 57418, 57432, 57479, 57494, 57508, 57536, 57554, 57585, 57587, 57594, 57623, 57629, 57632, 57652, 57661, 57663, 57673, 57675, 57680, 57692, 57704, 57742, 57745, 57759, 57760, 57764, 57765, 57774, 57801, 57821, 57827, 57860, 57872, 57885, 57895, 57927, 57943, 57964, 57965, 57977, 57984, 57997, 58038, 58100, 58117, 58156, 58196, 58203, 58208, 58219, 58233, 58236, 58237, 58240, 58246, 58248, 58253, 58296, 58331, 58345, 58354, 58380, 58390, 58401, 58402, 58405, 58407, 58466, 58576, 58588, 58603, 58656, 58705, 58717, 58725, 58758, 58789, 58800, 58809, 58832, 58833, 58845, 58990, 59009, 59017, 59018, 59044, 59094, 59142, 59203, 59212, 59244, 59256, 59383, 59400, 59540, 59544, 59720, 59733, 59734, 59771, 59793, 59809, 59882, 59906, 59928, 60008, 60081, 60142, 60151, 60183, 60194, 60223, 60262, 60316, 60400, 60474, 60475, 60484, 60532, 60536, 60537, 60550, 60553, 60598, 60619, 60630, 60645, 60675, 60695, 60713, 60714, 60767, 60780, 60847, 60893, 60962, 61053, 61061, 61084, 61094, 61152, 61158, 61189, 61209, 61277, 61331, 61333, 61343, 61347, 61351, 61366, 61378, 61382, 61384, 61480, 61501, 61505, 61506, 61518, 61536, 61546, 61561, 61568, 61575, 61647, 61654, 61657, 61701, 61715, 61726, 61805, 61806, 61815, 61851, 61864, 61865, 62120, 62204, 62247, 62432, 62451, 62509, 62614, 62664, 62843, 62925, 62950, 63113, 63117, 63119, 63162, 63218, 63227, 63351, 63819, 63834, 63948, 63984, 64062, 64185, 64188, 64214, 64387, 64414, 64476, 64478, 64503, 64508, 64620, 64687, 64741, 64761, 64786, 64791, 64835, 64839, 64869, 64888, 64913, 64959, 65020, 65038, 65045, 65051, 65103, 65201, 65204, 65209, 65295, 65326, 65371, 65400, 65429, 65536, 65565, 65635, 65682, 65780, 65795, 65844, 65884, 65928, 65934, 65963, 65997, 66002, 66007, 66123, 66128, 66129, 66184, 66201, 66218, 66232, 66234, 66262, 66277, 66282, 66335, 66349, 66422, 66424, 66509, 66512, 66536, 66543, 66551, 66572, 66600, 66611, 66617, 66633, 66638, 66652, 66745, 66828, 66838, 66845, 66853, 66862, 66869, 66880, 66902, 66915, 66938, 66945, 66962, 67040, 67154, 67162, 67173, 67183, 67189, 67192, 67205, 67215, 67222, 67230, 67247, 67264, 67268, 67329, 67331, 67341, 67346, 67360, 67386, 67396, 67418, 67436, 67442, 67446, 67450, 67472, 67491, 67503, 67526, 67567, 67658, 67661, 67668, 67670, 67678, 67690, 67707, 67709, 67713, 67728, 67742, 67766, 67782, 67809, 67821, 67826, 67848, 67867, 67909, 67942, 67949, 67952, 67992, 67999, 68021, 68035, 68061, 68091, 68096, 68107, 68126, 68130, 68137, 68146, 68150, 68195, 68213, 68242, 68245, 68248, 68272, 68349, 68375, 68382, 68412, 68422, 68423, 68508, 68519, 68525, 68574, 68610, 68627, 68629, 68682, 68695, 68737, 68743, 68776, 68797, 68810, 68820, 68837, 68844, 68848, 68878, 68888, 68916, 68935, 68966, 68970, 69008, 69045, 69046, 69079, 69130, 69200, 69243, 69267, 69326, 69353, 69471, 69495, 69535, 69547, 69555, 69565, 69575, 69592, 69632, 69669, 69766, 69772, 69851, 69852, 69861, 69862, 69869, 69888, 69928, 69953]\n",
    "#args=0\n",
    "#for i in errors:\n",
    " #   args+=y_target[i]\n",
    "#print(args)\n",
    "#sys.exit(-1)\n",
    "for alpha in alphas:\n",
    "    print(\"alpha:\"+str(alpha))\n",
    "    for epsilon in epsilons:\n",
    "        print(\"epsilon:\"+str(epsilon))\n",
    "        for sigma in sigmas:    \n",
    "              print(\"sigma:\"+str(sigma))\n",
    "              results=germain_bound(x_bound,y_bound,x_target,y_target_bin,alpha,sigma,epsilon,TASK,Binary=Binary)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Weightupdates  train_germain  target_germain            KL       e_s  \\\n",
      "0               0       0.513384        0.510502  14686.542660  0.513384   \n",
      "1              45       0.320011        0.456872  14687.162710  0.225739   \n",
      "2              90       0.276696        0.453054  14708.297332  0.132424   \n",
      "3             135       0.260034        0.372478  14692.459087  0.158185   \n",
      "4             180       0.220283        0.357933  14789.742257  0.154999   \n",
      "5             225       0.182852        0.308719  14780.651274  0.079224   \n",
      "6             270       0.138430        0.267835  14765.152136  0.058492   \n",
      "7             315       0.157685        0.272843  14814.895834  0.069169   \n",
      "8             360       0.107263        0.229683  14889.034749  0.071883   \n",
      "9             405       0.120119        0.258315  14863.228077  0.058213   \n",
      "10            450       0.172054        0.304022  14881.463619  0.112241   \n",
      "11            495       0.117726        0.260269  14836.315188  0.062048   \n",
      "12            540       0.101414        0.221228  14845.388809  0.060791   \n",
      "13           1094       0.080246        0.154104  15010.541890  0.038802   \n",
      "14           1641       0.073004        0.111473  15058.559336  0.031153   \n",
      "15           2188       0.057006        0.091420  15144.291149  0.024297   \n",
      "16           2735       0.066748        0.099886  15224.570076  0.025825   \n",
      "17           3282       0.049443        0.072918  15300.821091  0.016869   \n",
      "18           3829       0.055371        0.098278  15327.530338  0.016862   \n",
      "19           4376       0.049850        0.083605  15383.274662  0.017190   \n",
      "20           4923       0.054049        0.108255  15441.912386  0.020704   \n",
      "21           5470       0.057806        0.090570  15507.252620  0.018005   \n",
      "22           6017       0.044222        0.074057  15594.930643  0.013448   \n",
      "23           6564       0.034481        0.069728  15638.095727  0.012227   \n",
      "24           7111       0.052807        0.116124  15662.794540  0.020219   \n",
      "25           7658       0.042373        0.085966  15801.139533  0.013377   \n",
      "26           8205       0.040301        0.064402  15787.871739  0.012734   \n",
      "27           8752       0.043037        0.094060  15834.548115  0.013805   \n",
      "28           9299       0.041587        0.080708  15880.226847  0.012284   \n",
      "\n",
      "         e_t      d_tx      d_sx  germain_bound  boundpart1_germain  \\\n",
      "0   0.510502  0.000000  0.000000       3.401303            1.398234   \n",
      "1   0.367856  0.178033  0.188544       3.014584            0.871572   \n",
      "2   0.291370  0.323368  0.288544       2.938821            0.753600   \n",
      "3   0.250189  0.244578  0.203699       2.835606            0.708220   \n",
      "4   0.295667  0.124532  0.130567       2.748116            0.599954   \n",
      "5   0.166913  0.283612  0.207256       2.666296            0.498010   \n",
      "6   0.152797  0.230076  0.159877       2.543642            0.377024   \n",
      "7   0.159698  0.226289  0.177032       2.576954            0.429464   \n",
      "8   0.175550  0.108265  0.070761       2.448011            0.292138   \n",
      "9   0.157412  0.201807  0.123811       2.516603            0.327151   \n",
      "10  0.239266  0.129511  0.119626       2.617747            0.468600   \n",
      "11  0.172710  0.175118  0.111356       2.503625            0.320634   \n",
      "12  0.156369  0.129719  0.081246       2.430865            0.276208   \n",
      "13  0.095114  0.117981  0.082888       2.341013            0.218554   \n",
      "14  0.051804  0.119338  0.083702       2.293835            0.198831   \n",
      "15  0.044356  0.094128  0.065419       2.251957            0.155260   \n",
      "16  0.041799  0.116174  0.081845       2.288899            0.181791   \n",
      "17  0.028265  0.089306  0.065148       2.235500            0.134661   \n",
      "18  0.039038  0.118481  0.077018       2.281823            0.150806   \n",
      "19  0.035723  0.095764  0.065319       2.258345            0.135770   \n",
      "20  0.055551  0.105408  0.066690       2.299485            0.147207   \n",
      "21  0.034812  0.111516  0.079603       2.293140            0.157438   \n",
      "22  0.030097  0.087920  0.061548       2.259833            0.120442   \n",
      "23  0.032394  0.074668  0.044508       2.244975            0.093911   \n",
      "24  0.060516  0.111216  0.065176       2.332112            0.143823   \n",
      "25  0.038159  0.095614  0.057992       2.295658            0.115404   \n",
      "26  0.027836  0.073132  0.055135       2.259979            0.109763   \n",
      "27  0.041613  0.104894  0.058463       2.312660            0.117213   \n",
      "28  0.036319  0.088777  0.058606       2.293832            0.113265   \n",
      "\n",
      "    boundpart2_germain  boundpart3_germain  boundpart4_germain  \\\n",
      "0             0.002678            1.571274            0.000000   \n",
      "1             0.132043            1.571340            0.010512   \n",
      "2             0.147680            1.573601            0.034823   \n",
      "3             0.085483            1.571907            0.040878   \n",
      "4             0.130697            1.582312            0.006035   \n",
      "5             0.081473            1.581339            0.076356   \n",
      "6             0.087621            1.579682            0.070199   \n",
      "7             0.084112            1.585002            0.049258   \n",
      "8             0.096319            1.592932            0.037504   \n",
      "9             0.092167            1.590172            0.077997   \n",
      "10            0.118021            1.592122            0.009886   \n",
      "11            0.102818            1.587293            0.063762   \n",
      "12            0.088803            1.588264            0.048473   \n",
      "13            0.052320            1.605928            0.035093   \n",
      "14            0.019187            1.611064            0.035636   \n",
      "15            0.018638            1.620233            0.028709   \n",
      "16            0.014842            1.628820            0.034328   \n",
      "17            0.010588            1.636975            0.024158   \n",
      "18            0.020604            1.639832            0.041464   \n",
      "19            0.017219            1.645794            0.030444   \n",
      "20            0.032377            1.652066            0.038717   \n",
      "21            0.015616            1.659055            0.031913   \n",
      "22            0.015469            1.668433            0.026371   \n",
      "23            0.018738            1.673049            0.030160   \n",
      "24            0.037441            1.675691            0.046039   \n",
      "25            0.023026            1.690488            0.037622   \n",
      "26            0.014032            1.689069            0.017997   \n",
      "27            0.025837            1.694062            0.046430   \n",
      "28            0.022332            1.698947            0.030171   \n",
      "\n",
      "    boundpart5_germain  \n",
      "0             0.429118  \n",
      "1             0.429118  \n",
      "2             0.429118  \n",
      "3             0.429118  \n",
      "4             0.429118  \n",
      "5             0.429118  \n",
      "6             0.429118  \n",
      "7             0.429118  \n",
      "8             0.429118  \n",
      "9             0.429118  \n",
      "10            0.429118  \n",
      "11            0.429118  \n",
      "12            0.429118  \n",
      "13            0.429118  \n",
      "14            0.429118  \n",
      "15            0.429118  \n",
      "16            0.429118  \n",
      "17            0.429118  \n",
      "18            0.429118  \n",
      "19            0.429118  \n",
      "20            0.429118  \n",
      "21            0.429118  \n",
      "22            0.429118  \n",
      "23            0.429118  \n",
      "24            0.429118  \n",
      "25            0.429118  \n",
      "26            0.429118  \n",
      "27            0.429118  \n",
      "28            0.429118  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Weightupdates  train_germain  target_germain            KL       e_s  \\\n",
      "0               0       0.045993        0.090588  16328.642878  0.022025   \n",
      "1              45       0.063977        0.085930  16296.182484  0.030781   \n",
      "2              90       0.057935        0.092531  16295.213463  0.023361   \n",
      "3             135       0.049479        0.080161  16270.493917  0.021447   \n",
      "4             180       0.054992        0.092292  16242.338492  0.022882   \n",
      "5             225       0.044544        0.079979  16259.301508  0.019047   \n",
      "6             270       0.042108        0.073718  16303.065724  0.019640   \n",
      "7             315       0.037895        0.072525  16275.775498  0.016805   \n",
      "8             360       0.045236        0.072768  16305.679011  0.019511   \n",
      "9             405       0.040423        0.070689  16275.298899  0.019533   \n",
      "10            450       0.044058        0.076229  16292.182674  0.017769   \n",
      "11            495       0.037538        0.069163  16274.637703  0.016419   \n",
      "12            540       0.042530        0.067735  16279.992371  0.019176   \n",
      "13           1094       0.030738        0.065888  16324.613852  0.014298   \n",
      "14           1641       0.033345        0.074493  16354.287937  0.015455   \n",
      "15           2188       0.044265        0.070917  16335.317257  0.016840   \n",
      "16           2735       0.033795        0.057247  16420.710503  0.011384   \n",
      "17           3282       0.036266        0.072321  16440.244862  0.011191   \n",
      "\n",
      "         e_t      d_tx      d_sx  germain_bound  boundpart1_germain  \\\n",
      "0   0.047392  0.086391  0.047936       2.365983            0.145210   \n",
      "1   0.043506  0.084848  0.066391       2.387578            0.201986   \n",
      "2   0.043535  0.097993  0.069147       2.385708            0.182910   \n",
      "3   0.038420  0.083483  0.056063       2.351994            0.156213   \n",
      "4   0.042467  0.099650  0.064219       2.376856            0.173620   \n",
      "5   0.039616  0.080726  0.050993       2.340882            0.140633   \n",
      "6   0.038506  0.070424  0.044936       2.332000            0.132944   \n",
      "7   0.038270  0.068510  0.042180       2.319064            0.119640   \n",
      "8   0.036259  0.073018  0.051450       2.336265            0.142820   \n",
      "9   0.036741  0.067895  0.041780       2.322826            0.127622   \n",
      "10  0.034073  0.084312  0.052578       2.340869            0.139099   \n",
      "11  0.034098  0.070131  0.042237       2.315863            0.118513   \n",
      "12  0.034019  0.067431  0.046708       2.322385            0.134274   \n",
      "13  0.035516  0.060744  0.032881       2.302946            0.097047   \n",
      "14  0.040263  0.068460  0.035781       2.322470            0.105277   \n",
      "15  0.031794  0.078247  0.054849       2.336500            0.139753   \n",
      "16  0.024964  0.064566  0.044822       2.307558            0.106698   \n",
      "17  0.032798  0.079047  0.050150       2.334039            0.114499   \n",
      "\n",
      "    boundpart2_germain  boundpart3_germain  boundpart4_germain  \\\n",
      "0             0.023569            1.729631            0.038455   \n",
      "1             0.011823            1.726194            0.018457   \n",
      "2             0.018744            1.726091            0.028845   \n",
      "3             0.015770            1.723473            0.027420   \n",
      "4             0.018196            1.720492            0.035431   \n",
      "5             0.019111            1.722288            0.029733   \n",
      "6             0.017528            1.726923            0.025488   \n",
      "7             0.019944            1.724033            0.026330   \n",
      "8             0.015560            1.727199            0.021568   \n",
      "9             0.015988            1.723982            0.026116   \n",
      "10            0.015148            1.725770            0.031734   \n",
      "11            0.016426            1.723912            0.027895   \n",
      "12            0.013791            1.724479            0.020723   \n",
      "13            0.019714            1.729205            0.027863   \n",
      "14            0.023050            1.732347            0.032679   \n",
      "15            0.013893            1.730338            0.023398   \n",
      "16            0.012618            1.739381            0.019744   \n",
      "17            0.020075            1.741450            0.028897   \n",
      "\n",
      "    boundpart5_germain  \n",
      "0             0.429118  \n",
      "1             0.429118  \n",
      "2             0.429118  \n",
      "3             0.429118  \n",
      "4             0.429118  \n",
      "5             0.429118  \n",
      "6             0.429118  \n",
      "7             0.429118  \n",
      "8             0.429118  \n",
      "9             0.429118  \n",
      "10            0.429118  \n",
      "11            0.429118  \n",
      "12            0.429118  \n",
      "13            0.429118  \n",
      "14            0.429118  \n",
      "15            0.429118  \n",
      "16            0.429118  \n",
      "17            0.429118  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_germain_res(alpha,epsilon,sigma,Binary=False):\n",
    "    sigma_tmp=sigma\n",
    "    sigma=sigma[0]*10**(-1*sigma[1])\n",
    "    import pandas as pd\n",
    "    if Binary:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/Binary/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(\"Binary: \"+r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    else:\n",
    "        result_path=\"results/\"+\"task\"+str(TASK)+\"/\"+str(int(1000*epsilon))+\"_\"+str(int(100*alpha))+\"_\"+str(sigma_tmp[0])+str(sigma_tmp[1])\n",
    "        plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "    results=pd.read_pickle(result_path+\"_results.pkl\") #\n",
    "    print(results)\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"train_germain\"],'k^-')\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"target_germain\"],'m^-')\n",
    "    #print(results[\"KL\"])\n",
    "    '''\n",
    "    print(\"Target error is\")\n",
    "    print(results[\"target_germain\"])\n",
    "    print(\"Target disagreement is\")\n",
    "    print(results[\"d_tx\"])\n",
    "    print(\"source disagreement is\")\n",
    "    print(results[\"d_sx\"])\n",
    "    '''\n",
    "    plt.xlabel(\"Weight updates\")\n",
    "    plt.ylabel(\"Error\")\n",
    "\n",
    "    plt.plot(results[\"Weightupdates\"],results['boundpart1_germain'],'*')\n",
    "    plt.plot(results[\"Weightupdates\"],results['boundpart2_germain'],'+-')\n",
    "    plt.plot(results[\"Weightupdates\"],results['boundpart3_germain'],'X')\n",
    "    plt.plot(results[\"Weightupdates\"],results['boundpart4_germain'],'D')\n",
    "    plt.plot(results[\"Weightupdates\"],results['boundpart5_germain'],'o-')\n",
    "\n",
    "\n",
    "    #plt.plot(results[\"Epochs\"],results[\"e_s\"])\n",
    "    #plt.plot(results[\"Epochs\"],results[\"e_t\"])\n",
    "    #plt.plot(results[\"Epochs\"],results[\"d_tx\"])\n",
    "    #plt.plot(results[\"Epochs\"],results[\"d_sx\"])\n",
    "    plt.plot(results[\"Weightupdates\"],results[\"germain_bound\"],'r*-')\n",
    "    plt.legend([\"Sample error\",\"Target error\",\"sample error part\",\"dis_rho part\",\"KL part\",\"lambda_rho\",\"extra constant\",\"Bound\"], loc = 0)#,\"e_s\",\"e_t\",\"d_tx\",\"d_sx\"])#,\"Bound\"\n",
    "    plt.title(r\"$\\alpha$=\"+str(alpha)+r\" $\\epsilon$=\"+str(epsilon)+r\" $\\sigma$=\"+str(sigma))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "sigma=[3,2]\n",
    "plot_germain_res(0,0.01,sigma,True)\n",
    "plot_germain_res(0.3,0.01,sigma,True)\n",
    "\n",
    "#plot_germain_res(0.3,0.001,sigma,True)\n",
    "#plot_germain_res(0.3,0.01,sigma,True)\n",
    "#plot_germain_res(0.1,0.001,sigma,True)\n",
    "#plot_germain_res(0.1,0.01,sigma,True)\n",
    "#plot_germain_res(0.3,0.03,sigma,True)\n",
    "#plot_germain_res(0.1,0.03,sigma,True)\n",
    "#plot_germain_res(0.3,0.03,sigma,True)\n",
    "#plot_germain_res(0.3,0.01,sigma,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load module\n",
    "#mymodule = SourceFileLoader('train', path_to_root_file+'mnist_transfer/experiments/training.py').load_module()\n",
    "#mymodule2 = SourceFileLoader('plotting', path_to_root_file+'mnist_transfer/results/plotting.py').load_module()\n",
    "#from plotting import * \n",
    "#from train import *\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#test for MNIST-> MNIST-M\n",
    "total_epochs=20 #\n",
    "\n",
    "iterations=1\n",
    "histories=[]\n",
    "\n",
    "#histories=train_model(model=\"2MNIST-M\",total_epochs=total_epochs,x_train=x_train,y_train=y_train_new,x_test=x_test,y_test=y_test_new)#,x_target=x_test_m,y_target=y_test_m)\n",
    "                      \n",
    "##### Aggregating over all the training runs                    \n",
    "K=histories[0].keys()\n",
    "                \n",
    "result={}\n",
    "for key in K:\n",
    "    tmp=[]\n",
    "    for epoch in range(len(histories)):\n",
    "        tmp.append(histories[epoch][key])\n",
    "    result[key]=tmp\n",
    "\n",
    "for key in K:\n",
    "    result[key]=np.mean(result[key],axis=0)\n",
    "\n",
    "    \n",
    "## plotting and saving to disk\n",
    "plot_results(model=\"2MNIST-M\",result=result,xlabel=\"Epoch\",total_epochs=total_epochs,save=False)\n",
    "\n",
    "\"\"\"\n",
    "##### load the splits from the file and make the split on the data\n",
    "\n",
    "##  This is if we need to divide this up into a train and test set\n",
    "'''\n",
    "import sys\n",
    "import pickle\n",
    "pkl_file=open('splits_task1.pkl','rb')\n",
    "split1=pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "traindata=[]\n",
    "train_y=[]\n",
    "testdata=[]\n",
    "test_y=[]\n",
    "print(np.max(split1[0]))\n",
    "for i in split1[0]:\n",
    "    train_y.append(y_shift[i])\n",
    "    traindata.append(x_shift[i])\n",
    "for i in split1[1]:\n",
    "    test_y.append(y_shift[i])\n",
    "    testdata.append(x_shift[i])\n",
    "print(np.sum(train_y,axis=1))\n",
    "print(np.sum(test_y,axis=1))\n",
    "'''\n",
    "### load SVHN\n",
    "#from importlib.machinery import SourceFileLoader\n",
    "#mymodule = SourceFileLoader('svhn', path_to_root_file+'mnist_transfer/data/svhn.py').load_module()\n",
    "#import svhn \n",
    "#X_train, Y_train, X_test, Y_test=svhn.load_svhn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
