{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.layers import deserialize, serialize\n",
    "from tensorflow.python.keras.saving import saving_utils\n",
    "\n",
    "# Project imports \n",
    "from data import mnist,mnist_m\n",
    "from data.tasks import *\n",
    "from data.xray import * # temporary\n",
    "from data.label_shift import *\n",
    "from experiments.models import *\n",
    "from experiments.training import *\n",
    "from util.kl import *\n",
    "from util.misc import *\n",
    "\n",
    "\n",
    "#reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "    sess.close()\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
    "    \n",
    "reset_keras()\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU\n",
    "#   try:\n",
    "#     tf.config.experimental.set_virtual_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*4))])\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Virtual devices must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.019297905352987\n",
      "3.9835700132100396\n",
      "length of chestxray in source 22424\n",
      "amount of chest in source and target 4.0\n",
      "mean of weights in source, should be 1:  1.0000000000000002\n",
      "4.039824732229795\n",
      "3.9663485272338326\n",
      "length of chestxray in source 22424\n",
      "amount of chest in source and target 4.0\n",
      "mean of weights in source, should be 1:  1.0\n",
      "172250\n",
      "89696\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/Arch/software/IPython/7.18.1-GCCcore-10.2.0/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3425: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#alphas=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "alphas=[0.3]#,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]#,0.3,0.5,0.7,0.9]\n",
    "#epsilons=[0,0.1]#,0.01,0.001]\n",
    "architectures=[\"resnet\"]\n",
    "tasks=[7]\n",
    "seeds=[1]\n",
    "image_size=64\n",
    "batch_size=32\n",
    "num_priors=1\n",
    "from data.xray import *\n",
    "import time\n",
    "for t in tasks:\n",
    "    for arch in architectures:\n",
    "        for alpha in alphas:\n",
    "            for seed in seeds:\n",
    "                if t==7:\n",
    "                        source_generator, target_generator=load_task(t,architecture=arch,binary=True,image_size=image_size,batch_size=batch_size)\n",
    "                else:\n",
    "                        x_source,y_source,x_target,y_target,_, _=load_task(task=t,architecture=arch,binary=True)\n",
    "\n",
    "                        \n",
    "                        sys.exit(-1)\n",
    "\n",
    "                if alpha==0:\n",
    "                    pass\n",
    "                else:\n",
    "                    if t==7:\n",
    "                        prior_generator, bound_generator, target_generator=load_task(task=t,alpha=alpha,architecture=arch,binary=True,image_size=image_size,seed=seed) ## create bound/prior split here as own generators\n",
    "                        print(len(bound_generator.y))\n",
    "                        print(len(target_generator.y))\n",
    "                        sys.exit(-1)\n",
    "                        w_a=train_prior(alpha,num_priors,generator=prior_generator,val_generator=target_generator,save=True,task=t,binary=True,batch_size=batch_size,architecture=arch,seed=seed,image_size=image_size)\n",
    "                    else:\n",
    "                        print(\"Alpha is:\"+str(alpha))\n",
    "                        #x_bound, x_prior, y_bound , y_prior = train_test_split(x_source,y_source,test_size=alpha,random_state=seed)\n",
    "                        w_a=train_prior(alpha,num_priors,x_train=x_source,y_train=y_source,x_target=x_target,y_target=y_target,save=True,task=t,binary=True,batch_size=batch_size,architecture=arch,seed=seed,image_size=image_size)\n",
    "#                         project_folder=\"/cephyr/NOBACKUP/groups/snic2021-23-538/mnist_transfer/\"\n",
    "#                         result_path=project_folder+\"results/\"+\"task\"+str(t)+\"/Binary/\"+str(arch)\n",
    "                #for epsilon in epsilons:\n",
    "                if t==7:\n",
    "                    if alpha!=0:\n",
    "                        source_generator, target_generator=load_task(t,architecture=arch,binary=True,image_size=image_size)\n",
    "                    print(len(source_generator))\n",
    "                    w_s=train_posterior(alpha,generator=source_generator,val_generator=target_generator,prior_weights=None,save=True,task=t,binary=True,batch_size=batch_size,architecture=arch,seed=seed,image_size=image_size)\n",
    "                else:\n",
    "                    w_s=train_posterior(alpha,x_train=x_source,y_train=y_source,prior_weights=None,x_test=x_source,y_test=y_source,save=True,task=t,binary=True,batch_size=batch_size,architecture=arch,seed=seed,image_size=image_size)\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(target_generator,steps=target_generator.steps, workers=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
